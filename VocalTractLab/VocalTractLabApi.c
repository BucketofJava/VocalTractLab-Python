/* Generated by Cython 0.29.24 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "depends": [
            "C:\\Users\\Locke\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h",
            "C:\\Users\\Locke\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h",
            "C:\\Users\\Locke\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h",
            "C:\\Users\\Locke\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h",
            "C:\\Users\\Locke\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h"
        ],
        "include_dirs": [
            "C:\\Users\\Locke\\anaconda3\\lib\\site-packages\\numpy\\core\\include"
        ],
        "language": "c",
        "libraries": [
            "VocalTractLab/VocalTractLabApi"
        ],
        "library_dirs": [
            "."
        ],
        "name": "VocalTractLab.VocalTractLabApi",
        "sources": [
            "VocalTractLab/VocalTractLabApi.pyx"
        ]
    },
    "module_name": "VocalTractLab.VocalTractLabApi"
}
END: Cython Metadata */

#ifndef PY_SSIZE_T_CLEAN
#define PY_SSIZE_T_CLEAN
#endif /* PY_SSIZE_T_CLEAN */
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_29_24"
#define CYTHON_HEX_VERSION 0x001D18F0
#define CYTHON_FUTURE_DIVISION 0
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
  #ifndef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS (PY_VERSION_HEX >= 0x030600B1)
  #endif
  #ifndef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK (PY_VERSION_HEX >= 0x030700A3)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
  #ifdef SIZEOF_VOID_P
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
  #endif
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #elif defined(__GNUC__)
    #define CYTHON_INLINE __inline__
  #elif defined(_MSC_VER)
    #define CYTHON_INLINE __inline
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_INLINE inline
  #else
    #define CYTHON_INLINE
  #endif
#endif

#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#else
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#endif
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#if PY_VERSION_HEX <= 0x030700A3 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
  #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
  #define PyMem_RawRealloc(p, n)       PyMem_Realloc(p, n)
  #define PyMem_RawFree(p)             PyMem_Free(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
#include "pythread.h"
#define Py_tss_NEEDS_INIT 0
typedef int Py_tss_t;
static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
  *key = PyThread_create_key();
  return 0;
}
static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
  Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
  *key = Py_tss_NEEDS_INIT;
  return key;
}
static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
  PyObject_Free(key);
}
static CYTHON_INLINE int PyThread_tss_is_created(Py_tss_t *key) {
  return *key != Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE void PyThread_tss_delete(Py_tss_t *key) {
  PyThread_delete_key(*key);
  *key = Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
  return PyThread_set_key_value(*key, value);
}
static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
  return PyThread_get_key_value(*key);
}
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1 && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStr(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
#else
#define __Pyx_PyDict_GetItemStr(dict, name)  PyDict_GetItem(dict, name)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #if defined(PyUnicode_IS_READY)
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #else
  #define __Pyx_PyUnicode_READY(op)       (0)
  #endif
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #if defined(PyUnicode_IS_READY) && defined(PyUnicode_GET_SIZE)
  #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
  #else
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
  #endif
  #else
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
  #endif
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None || (PyString_Check(b) && !PyString_CheckExact(b)))) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#ifndef PyObject_Unicode
  #define PyObject_Unicode             PyObject_Str
#endif
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#if PY_VERSION_HEX >= 0x030900A4
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_SET_REFCNT(obj, refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SET_SIZE(obj, size)
#else
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_REFCNT(obj) = (refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SIZE(obj) = (size)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
#else
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? ((void)(klass), PyMethod_New(func, self)) : __Pyx_NewRef(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif

#define __PYX_MARK_ERR_POS(f_index, lineno) \
    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__; (void)__pyx_clineno; }
#define __PYX_ERR(f_index, lineno, Ln_error) \
    { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__VocalTractLab__VocalTractLabApi
#define __PYX_HAVE_API__VocalTractLab__VocalTractLabApi
/* Early includes */
#include <string.h>
#include <stdio.h>
#include "numpy/arrayobject.h"
#include "numpy/ndarrayobject.h"
#include "numpy/ndarraytypes.h"
#include "numpy/arrayscalars.h"
#include "numpy/ufuncobject.h"

    /* NumPy API declarations from "numpy/__init__.pxd" */
    
#include "VocalTractLabApi.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c) + 1);
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime = NULL;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;

/* Header.proto */
#if !defined(CYTHON_CCOMPLEX)
  #if defined(__cplusplus)
    #define CYTHON_CCOMPLEX 1
  #elif defined(_Complex_I)
    #define CYTHON_CCOMPLEX 1
  #else
    #define CYTHON_CCOMPLEX 0
  #endif
#endif
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #include <complex>
  #else
    #include <complex.h>
  #endif
#endif
#if CYTHON_CCOMPLEX && !defined(__cplusplus) && defined(__sun__) && defined(__GNUC__)
  #undef _Complex_I
  #define _Complex_I 1.0fj
#endif


static const char *__pyx_f[] = {
  "VocalTractLab\\VocalTractLabApi.pyx",
  "__init__.pxd",
  "type.pxd",
};
/* BufferFormatStructs.proto */
#define IS_UNSIGNED(type) (((type) -1) > 0)
struct __Pyx_StructField_;
#define __PYX_BUF_FLAGS_PACKED_STRUCT (1 << 0)
typedef struct {
  const char* name;
  struct __Pyx_StructField_* fields;
  size_t size;
  size_t arraysize[8];
  int ndim;
  char typegroup;
  char is_unsigned;
  int flags;
} __Pyx_TypeInfo;
typedef struct __Pyx_StructField_ {
  __Pyx_TypeInfo* type;
  const char* name;
  size_t offset;
} __Pyx_StructField;
typedef struct {
  __Pyx_StructField* field;
  size_t parent_offset;
} __Pyx_BufFmt_StackElem;
typedef struct {
  __Pyx_StructField root;
  __Pyx_BufFmt_StackElem* head;
  size_t fmt_offset;
  size_t new_count, enc_count;
  size_t struct_alignment;
  int is_complex;
  char enc_type;
  char new_packmode;
  char enc_packmode;
  char is_valid_array;
} __Pyx_BufFmt_Context;


/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":690
 * # in Cython to enable them only on the right systems.
 * 
 * ctypedef npy_int8       int8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 */
typedef npy_int8 __pyx_t_5numpy_int8_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":691
 * 
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t
 */
typedef npy_int16 __pyx_t_5numpy_int16_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":692
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int64      int64_t
 * #ctypedef npy_int96      int96_t
 */
typedef npy_int32 __pyx_t_5numpy_int32_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":693
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_int96      int96_t
 * #ctypedef npy_int128     int128_t
 */
typedef npy_int64 __pyx_t_5numpy_int64_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":697
 * #ctypedef npy_int128     int128_t
 * 
 * ctypedef npy_uint8      uint8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 */
typedef npy_uint8 __pyx_t_5numpy_uint8_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":698
 * 
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t
 */
typedef npy_uint16 __pyx_t_5numpy_uint16_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":699
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint64     uint64_t
 * #ctypedef npy_uint96     uint96_t
 */
typedef npy_uint32 __pyx_t_5numpy_uint32_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":700
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_uint96     uint96_t
 * #ctypedef npy_uint128    uint128_t
 */
typedef npy_uint64 __pyx_t_5numpy_uint64_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":704
 * #ctypedef npy_uint128    uint128_t
 * 
 * ctypedef npy_float32    float32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_float64    float64_t
 * #ctypedef npy_float80    float80_t
 */
typedef npy_float32 __pyx_t_5numpy_float32_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":705
 * 
 * ctypedef npy_float32    float32_t
 * ctypedef npy_float64    float64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_float80    float80_t
 * #ctypedef npy_float128   float128_t
 */
typedef npy_float64 __pyx_t_5numpy_float64_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":714
 * # The int types are mapped a bit surprising --
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longlong   long_t
 * ctypedef npy_longlong   longlong_t
 */
typedef npy_long __pyx_t_5numpy_int_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":715
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t
 * ctypedef npy_longlong   long_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longlong   longlong_t
 * 
 */
typedef npy_longlong __pyx_t_5numpy_long_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":716
 * ctypedef npy_long       int_t
 * ctypedef npy_longlong   long_t
 * ctypedef npy_longlong   longlong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_ulong      uint_t
 */
typedef npy_longlong __pyx_t_5numpy_longlong_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":718
 * ctypedef npy_longlong   longlong_t
 * 
 * ctypedef npy_ulong      uint_t             # <<<<<<<<<<<<<<
 * ctypedef npy_ulonglong  ulong_t
 * ctypedef npy_ulonglong  ulonglong_t
 */
typedef npy_ulong __pyx_t_5numpy_uint_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":719
 * 
 * ctypedef npy_ulong      uint_t
 * ctypedef npy_ulonglong  ulong_t             # <<<<<<<<<<<<<<
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 */
typedef npy_ulonglong __pyx_t_5numpy_ulong_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":720
 * ctypedef npy_ulong      uint_t
 * ctypedef npy_ulonglong  ulong_t
 * ctypedef npy_ulonglong  ulonglong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_intp       intp_t
 */
typedef npy_ulonglong __pyx_t_5numpy_ulonglong_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":722
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 * ctypedef npy_intp       intp_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uintp      uintp_t
 * 
 */
typedef npy_intp __pyx_t_5numpy_intp_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":723
 * 
 * ctypedef npy_intp       intp_t
 * ctypedef npy_uintp      uintp_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_double     float_t
 */
typedef npy_uintp __pyx_t_5numpy_uintp_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":725
 * ctypedef npy_uintp      uintp_t
 * 
 * ctypedef npy_double     float_t             # <<<<<<<<<<<<<<
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t
 */
typedef npy_double __pyx_t_5numpy_float_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":726
 * 
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longdouble longdouble_t
 * 
 */
typedef npy_double __pyx_t_5numpy_double_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":727
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cfloat      cfloat_t
 */
typedef npy_longdouble __pyx_t_5numpy_longdouble_t;
/* Declarations.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    typedef ::std::complex< float > __pyx_t_float_complex;
  #else
    typedef float _Complex __pyx_t_float_complex;
  #endif
#else
    typedef struct { float real, imag; } __pyx_t_float_complex;
#endif
static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float, float);

/* Declarations.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    typedef ::std::complex< double > __pyx_t_double_complex;
  #else
    typedef double _Complex __pyx_t_double_complex;
  #endif
#else
    typedef struct { double real, imag; } __pyx_t_double_complex;
#endif
static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double, double);


/*--- Type declarations ---*/
struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing;
struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":729
 * ctypedef npy_longdouble longdouble_t
 * 
 * ctypedef npy_cfloat      cfloat_t             # <<<<<<<<<<<<<<
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t
 */
typedef npy_cfloat __pyx_t_5numpy_cfloat_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":730
 * 
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t             # <<<<<<<<<<<<<<
 * ctypedef npy_clongdouble clongdouble_t
 * 
 */
typedef npy_cdouble __pyx_t_5numpy_cdouble_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":731
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cdouble     complex_t
 */
typedef npy_clongdouble __pyx_t_5numpy_clongdouble_t;

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":733
 * ctypedef npy_clongdouble clongdouble_t
 * 
 * ctypedef npy_cdouble     complex_t             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 */
typedef npy_cdouble __pyx_t_5numpy_complex_t;

/* "VocalTractLab/VocalTractLabApi.pyx":1001
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):             # <<<<<<<<<<<<<<
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 */
struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing {
  PyObject_HEAD
  PyObject *__pyx_v_args;
  PyObject *__pyx_v_function;
};


/* "VocalTractLab/VocalTractLabApi.pyx":1005
 * 		workers = mp.cpu_count()
 * 	pool = mp.Pool( workers )
 * 	tasks = ( ( function, x ) for x in args)             # <<<<<<<<<<<<<<
 * 	data = None
 * 	if return_data:
 */
struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr {
  PyObject_HEAD
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *__pyx_outer_scope;
  PyObject *__pyx_v_x;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
  PyObject *(*__pyx_t_2)(PyObject *);
};


/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* PyDictVersioning.proto */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
        (VAR) = __pyx_dict_cached_value;\
    } else {\
        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
    }\
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif

/* GetModuleGlobalName.proto */
#if CYTHON_USE_DICT_VERSIONS
#define __Pyx_GetModuleGlobalName(var, name)  {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
        (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
        __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
}
#define __Pyx_GetModuleGlobalNameUncached(var, name)  {\
    PY_UINT64_T __pyx_dict_version;\
    PyObject *__pyx_dict_cached_value;\
    (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
}
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
#else
#define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
#endif

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif

/* PyObjectCall2Args.proto */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2);

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* IncludeStringH.proto */
#include <string.h>

/* decode_c_string_utf16.proto */
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 0;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16LE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = -1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16BE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}

/* decode_c_string.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely((Py_TYPE(obj) == type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* StrEquals.proto */
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyString_Equals __Pyx_PyUnicode_Equals
#else
#define __Pyx_PyString_Equals __Pyx_PyBytes_Equals
#endif

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* ObjectGetItem.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject* key);
#else
#define __Pyx_PyObject_GetItem(obj, key)  PyObject_GetItem(obj, key)
#endif

/* ExtTypeTest.proto */
static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type);

/* IsLittleEndian.proto */
static CYTHON_INLINE int __Pyx_Is_Little_Endian(void);

/* BufferFormatCheck.proto */
static const char* __Pyx_BufFmt_CheckString(__Pyx_BufFmt_Context* ctx, const char* ts);
static void __Pyx_BufFmt_Init(__Pyx_BufFmt_Context* ctx,
                              __Pyx_BufFmt_StackElem* stack,
                              __Pyx_TypeInfo* type);

/* BufferGetAndValidate.proto */
#define __Pyx_GetBufferAndValidate(buf, obj, dtype, flags, nd, cast, stack)\
    ((obj == Py_None || obj == NULL) ?\
    (__Pyx_ZeroBuffer(buf), 0) :\
    __Pyx__GetBufferAndValidate(buf, obj, dtype, flags, nd, cast, stack))
static int  __Pyx__GetBufferAndValidate(Py_buffer* buf, PyObject* obj,
    __Pyx_TypeInfo* dtype, int flags, int nd, int cast, __Pyx_BufFmt_StackElem* stack);
static void __Pyx_ZeroBuffer(Py_buffer* buf);
static CYTHON_INLINE void __Pyx_SafeReleaseBuffer(Py_buffer* info);
static Py_ssize_t __Pyx_minusones[] = { -1, -1, -1, -1, -1, -1, -1, -1 };
static Py_ssize_t __Pyx_zeros[] = { 0, 0, 0, 0, 0, 0, 0, 0 };

/* BufferIndexError.proto */
static void __Pyx_RaiseBufferIndexError(int axis);

#define __Pyx_BufPtrStrided1d(type, buf, i0, s0) (type)((char*)buf + i0 * s0)
/* PyObjectSetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_DelAttrStr(o,n) __Pyx_PyObject_SetAttrStr(o, n, NULL)
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value);
#else
#define __Pyx_PyObject_DelAttrStr(o,n)   PyObject_DelAttr(o,n)
#define __Pyx_PyObject_SetAttrStr(o,n,v) PyObject_SetAttr(o,n,v)
#endif

/* DictGetItem.proto */
#if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key);
#define __Pyx_PyObject_Dict_GetItem(obj, name)\
    (likely(PyDict_CheckExact(obj)) ?\
     __Pyx_PyDict_GetItem(obj, name) : PyObject_GetItem(obj, name))
#else
#define __Pyx_PyDict_GetItem(d, key) PyObject_GetItem(d, key)
#define __Pyx_PyObject_Dict_GetItem(obj, name)  PyObject_GetItem(obj, name)
#endif

/* ListAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len) & likely(len > (L->allocated >> 1))) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        __Pyx_SET_SIZE(list, len + 1);
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_PyList_Append(L,x) PyList_Append(L,x)
#endif

/* StringJoin.proto */
#if PY_MAJOR_VERSION < 3
#define __Pyx_PyString_Join __Pyx_PyBytes_Join
#define __Pyx_PyBaseString_Join(s, v) (PyUnicode_CheckExact(s) ? PyUnicode_Join(s, v) : __Pyx_PyBytes_Join(s, v))
#else
#define __Pyx_PyString_Join PyUnicode_Join
#define __Pyx_PyBaseString_Join PyUnicode_Join
#endif
#if CYTHON_COMPILING_IN_CPYTHON
    #if PY_MAJOR_VERSION < 3
    #define __Pyx_PyBytes_Join _PyString_Join
    #else
    #define __Pyx_PyBytes_Join _PyBytes_Join
    #endif
#else
static CYTHON_INLINE PyObject* __Pyx_PyBytes_Join(PyObject* sep, PyObject* values);
#endif

/* UnpackUnboundCMethod.proto */
typedef struct {
    PyObject *type;
    PyObject **method_name;
    PyCFunction func;
    PyObject *method;
    int flag;
} __Pyx_CachedCFunction;

/* CallUnboundCMethod0.proto */
static PyObject* __Pyx__CallUnboundCMethod0(__Pyx_CachedCFunction* cfunc, PyObject* self);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_CallUnboundCMethod0(cfunc, self)\
    (likely((cfunc)->func) ?\
        (likely((cfunc)->flag == METH_NOARGS) ?  (*((cfunc)->func))(self, NULL) :\
         (PY_VERSION_HEX >= 0x030600B1 && likely((cfunc)->flag == METH_FASTCALL) ?\
            (PY_VERSION_HEX >= 0x030700A0 ?\
                (*(__Pyx_PyCFunctionFast)(void*)(PyCFunction)(cfunc)->func)(self, &__pyx_empty_tuple, 0) :\
                (*(__Pyx_PyCFunctionFastWithKeywords)(void*)(PyCFunction)(cfunc)->func)(self, &__pyx_empty_tuple, 0, NULL)) :\
          (PY_VERSION_HEX >= 0x030700A0 && (cfunc)->flag == (METH_FASTCALL | METH_KEYWORDS) ?\
            (*(__Pyx_PyCFunctionFastWithKeywords)(void*)(PyCFunction)(cfunc)->func)(self, &__pyx_empty_tuple, 0, NULL) :\
            (likely((cfunc)->flag == (METH_VARARGS | METH_KEYWORDS)) ?  ((*(PyCFunctionWithKeywords)(void*)(PyCFunction)(cfunc)->func)(self, __pyx_empty_tuple, NULL)) :\
               ((cfunc)->flag == METH_VARARGS ?  (*((cfunc)->func))(self, __pyx_empty_tuple) :\
               __Pyx__CallUnboundCMethod0(cfunc, self)))))) :\
        __Pyx__CallUnboundCMethod0(cfunc, self))
#else
#define __Pyx_CallUnboundCMethod0(cfunc, self)  __Pyx__CallUnboundCMethod0(cfunc, self)
#endif

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* ListCompAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_ListComp_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len)) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        __Pyx_SET_SIZE(list, len + 1);
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_ListComp_Append(L,x) PyList_Append(L,x)
#endif

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* BufferFallbackError.proto */
static void __Pyx_RaiseBufferFallbackError(void);

/* PyObjectGetMethod.proto */
static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method);

/* PyObjectCallMethod0.proto */
static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* UnpackTupleError.proto */
static void __Pyx_UnpackTupleError(PyObject *, Py_ssize_t index);

/* UnpackTuple2.proto */
#define __Pyx_unpack_tuple2(tuple, value1, value2, is_tuple, has_known_size, decref_tuple)\
    (likely(is_tuple || PyTuple_Check(tuple)) ?\
        (likely(has_known_size || PyTuple_GET_SIZE(tuple) == 2) ?\
            __Pyx_unpack_tuple2_exact(tuple, value1, value2, decref_tuple) :\
            (__Pyx_UnpackTupleError(tuple, 2), -1)) :\
        __Pyx_unpack_tuple2_generic(tuple, value1, value2, has_known_size, decref_tuple))
static CYTHON_INLINE int __Pyx_unpack_tuple2_exact(
    PyObject* tuple, PyObject** value1, PyObject** value2, int decref_tuple);
static int __Pyx_unpack_tuple2_generic(
    PyObject* tuple, PyObject** value1, PyObject** value2, int has_known_size, int decref_tuple);

/* dict_iter.proto */
static CYTHON_INLINE PyObject* __Pyx_dict_iterator(PyObject* dict, int is_dict, PyObject* method_name,
                                                   Py_ssize_t* p_orig_length, int* p_is_dict);
static CYTHON_INLINE int __Pyx_dict_iter_next(PyObject* dict_or_iter, Py_ssize_t orig_length, Py_ssize_t* ppos,
                                              PyObject** pkey, PyObject** pvalue, PyObject** pitem, int is_dict);

/* MergeKeywords.proto */
static int __Pyx_MergeKeywords(PyObject *kwdict, PyObject *source_mapping);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* PySequenceContains.proto */
static CYTHON_INLINE int __Pyx_PySequence_ContainsTF(PyObject* item, PyObject* seq, int eq) {
    int result = PySequence_Contains(seq, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname);

/* PyObject_GenericGetAttrNoDict.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttrNoDict PyObject_GenericGetAttr
#endif

/* TypeImport.proto */
#ifndef __PYX_HAVE_RT_ImportType_proto
#define __PYX_HAVE_RT_ImportType_proto
enum __Pyx_ImportType_CheckSize {
   __Pyx_ImportType_CheckSize_Error = 0,
   __Pyx_ImportType_CheckSize_Warn = 1,
   __Pyx_ImportType_CheckSize_Ignore = 2
};
static PyTypeObject *__Pyx_ImportType(PyObject* module, const char *module_name, const char *class_name, size_t size, enum __Pyx_ImportType_CheckSize check_size);
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* BufferStructDeclare.proto */
typedef struct {
  Py_ssize_t shape, strides, suboffsets;
} __Pyx_Buf_DimInfo;
typedef struct {
  size_t refcount;
  Py_buffer pybuffer;
} __Pyx_Buffer;
typedef struct {
  __Pyx_Buffer *rcbuffer;
  char *data;
  __Pyx_Buf_DimInfo diminfo[8];
} __Pyx_LocalBuf_ND;

#if PY_MAJOR_VERSION < 3
    static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags);
    static void __Pyx_ReleaseBuffer(Py_buffer *view);
#else
    #define __Pyx_GetBuffer PyObject_GetBuffer
    #define __Pyx_ReleaseBuffer PyBuffer_Release
#endif


/* GCCDiagnostics.proto */
#if defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))
#define __Pyx_HAS_GCC_DIAGNOSTIC
#endif

/* RealImag.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #define __Pyx_CREAL(z) ((z).real())
    #define __Pyx_CIMAG(z) ((z).imag())
  #else
    #define __Pyx_CREAL(z) (__real__(z))
    #define __Pyx_CIMAG(z) (__imag__(z))
  #endif
#else
    #define __Pyx_CREAL(z) ((z).real)
    #define __Pyx_CIMAG(z) ((z).imag)
#endif
#if defined(__cplusplus) && CYTHON_CCOMPLEX\
        && (defined(_WIN32) || defined(__clang__) || (defined(__GNUC__) && (__GNUC__ >= 5 || __GNUC__ == 4 && __GNUC_MINOR__ >= 4 )) || __cplusplus >= 201103)
    #define __Pyx_SET_CREAL(z,x) ((z).real(x))
    #define __Pyx_SET_CIMAG(z,y) ((z).imag(y))
#else
    #define __Pyx_SET_CREAL(z,x) __Pyx_CREAL(z) = (x)
    #define __Pyx_SET_CIMAG(z,y) __Pyx_CIMAG(z) = (y)
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX
    #define __Pyx_c_eq_float(a, b)   ((a)==(b))
    #define __Pyx_c_sum_float(a, b)  ((a)+(b))
    #define __Pyx_c_diff_float(a, b) ((a)-(b))
    #define __Pyx_c_prod_float(a, b) ((a)*(b))
    #define __Pyx_c_quot_float(a, b) ((a)/(b))
    #define __Pyx_c_neg_float(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_float(z) ((z)==(float)0)
    #define __Pyx_c_conj_float(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (::std::abs(z))
        #define __Pyx_c_pow_float(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_float(z) ((z)==0)
    #define __Pyx_c_conj_float(z)    (conjf(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (cabsf(z))
        #define __Pyx_c_pow_float(a, b)  (cpowf(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex);
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex);
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex, __pyx_t_float_complex);
    #endif
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX
    #define __Pyx_c_eq_double(a, b)   ((a)==(b))
    #define __Pyx_c_sum_double(a, b)  ((a)+(b))
    #define __Pyx_c_diff_double(a, b) ((a)-(b))
    #define __Pyx_c_prod_double(a, b) ((a)*(b))
    #define __Pyx_c_quot_double(a, b) ((a)/(b))
    #define __Pyx_c_neg_double(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_double(z) ((z)==(double)0)
    #define __Pyx_c_conj_double(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (::std::abs(z))
        #define __Pyx_c_pow_double(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_double(z) ((z)==0)
    #define __Pyx_c_conj_double(z)    (conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (cabs(z))
        #define __Pyx_c_pow_double(a, b)  (cpow(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex);
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex);
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex, __pyx_t_double_complex);
    #endif
#endif

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* PyObjectCallMethod1.proto */
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg);

/* CoroutineBase.proto */
typedef PyObject *(*__pyx_coroutine_body_t)(PyObject *, PyThreadState *, PyObject *);
#if CYTHON_USE_EXC_INFO_STACK
#define __Pyx_ExcInfoStruct  _PyErr_StackItem
#else
typedef struct {
    PyObject *exc_type;
    PyObject *exc_value;
    PyObject *exc_traceback;
} __Pyx_ExcInfoStruct;
#endif
typedef struct {
    PyObject_HEAD
    __pyx_coroutine_body_t body;
    PyObject *closure;
    __Pyx_ExcInfoStruct gi_exc_state;
    PyObject *gi_weakreflist;
    PyObject *classobj;
    PyObject *yieldfrom;
    PyObject *gi_name;
    PyObject *gi_qualname;
    PyObject *gi_modulename;
    PyObject *gi_code;
    PyObject *gi_frame;
    int resume_label;
    char is_running;
} __pyx_CoroutineObject;
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
    PyTypeObject *type, __pyx_coroutine_body_t body, PyObject *code, PyObject *closure,
    PyObject *name, PyObject *qualname, PyObject *module_name);
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *code, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name);
static CYTHON_INLINE void __Pyx_Coroutine_ExceptionClear(__Pyx_ExcInfoStruct *self);
static int __Pyx_Coroutine_clear(PyObject *self);
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value);
static PyObject *__Pyx_Coroutine_Close(PyObject *self);
static PyObject *__Pyx_Coroutine_Throw(PyObject *gen, PyObject *args);
#if CYTHON_USE_EXC_INFO_STACK
#define __Pyx_Coroutine_SwapException(self)
#define __Pyx_Coroutine_ResetAndClearException(self)  __Pyx_Coroutine_ExceptionClear(&(self)->gi_exc_state)
#else
#define __Pyx_Coroutine_SwapException(self) {\
    __Pyx_ExceptionSwap(&(self)->gi_exc_state.exc_type, &(self)->gi_exc_state.exc_value, &(self)->gi_exc_state.exc_traceback);\
    __Pyx_Coroutine_ResetFrameBackpointer(&(self)->gi_exc_state);\
    }
#define __Pyx_Coroutine_ResetAndClearException(self) {\
    __Pyx_ExceptionReset((self)->gi_exc_state.exc_type, (self)->gi_exc_state.exc_value, (self)->gi_exc_state.exc_traceback);\
    (self)->gi_exc_state.exc_type = (self)->gi_exc_state.exc_value = (self)->gi_exc_state.exc_traceback = NULL;\
    }
#endif
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__pyx_tstate, pvalue)
#else
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, pvalue)
#endif
static int __Pyx_PyGen__FetchStopIterationValue(PyThreadState *tstate, PyObject **pvalue);
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__Pyx_ExcInfoStruct *exc_state);

/* PatchModuleWithCoroutine.proto */
static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code);

/* PatchGeneratorABC.proto */
static int __Pyx_patch_abc(void);

/* Generator.proto */
#define __Pyx_Generator_USED
static PyTypeObject *__pyx_GeneratorType = 0;
#define __Pyx_Generator_CheckExact(obj) (Py_TYPE(obj) == __pyx_GeneratorType)
#define __Pyx_Generator_New(body, code, closure, name, qualname, module_name)\
    __Pyx__Coroutine_New(__pyx_GeneratorType, body, code, closure, name, qualname, module_name)
static PyObject *__Pyx_Generator_Next(PyObject *self);
static int __pyx_Generator_init(void);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);


/* Module declarations from 'cpython.buffer' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.type' */
static PyTypeObject *__pyx_ptype_7cpython_4type_type = 0;

/* Module declarations from 'cpython' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'cpython.ref' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'numpy' */

/* Module declarations from 'numpy' */
static PyTypeObject *__pyx_ptype_5numpy_dtype = 0;
static PyTypeObject *__pyx_ptype_5numpy_flatiter = 0;
static PyTypeObject *__pyx_ptype_5numpy_broadcast = 0;
static PyTypeObject *__pyx_ptype_5numpy_ndarray = 0;
static PyTypeObject *__pyx_ptype_5numpy_generic = 0;
static PyTypeObject *__pyx_ptype_5numpy_number = 0;
static PyTypeObject *__pyx_ptype_5numpy_integer = 0;
static PyTypeObject *__pyx_ptype_5numpy_signedinteger = 0;
static PyTypeObject *__pyx_ptype_5numpy_unsignedinteger = 0;
static PyTypeObject *__pyx_ptype_5numpy_inexact = 0;
static PyTypeObject *__pyx_ptype_5numpy_floating = 0;
static PyTypeObject *__pyx_ptype_5numpy_complexfloating = 0;
static PyTypeObject *__pyx_ptype_5numpy_flexible = 0;
static PyTypeObject *__pyx_ptype_5numpy_character = 0;
static PyTypeObject *__pyx_ptype_5numpy_ufunc = 0;

/* Module declarations from 'libcpp' */

/* Module declarations from 'cpython.pycapsule' */

/* Module declarations from 'VocalTractLab.VocalTractLabApi' */
static PyTypeObject *__pyx_ptype_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing = 0;
static PyTypeObject *__pyx_ptype_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr = 0;
static __Pyx_TypeInfo __Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t = { "float64_t", NULL, sizeof(__pyx_t_5numpy_float64_t), { 0 }, 0, 'R', 0, 0 };
static __Pyx_TypeInfo __Pyx_TypeInfo_int = { "int", NULL, sizeof(int), { 0 }, 0, IS_UNSIGNED(int) ? 'U' : 'I', IS_UNSIGNED(int), 0 };
#define __Pyx_MODULE_NAME "VocalTractLab.VocalTractLabApi"
extern int __pyx_module_is_main_VocalTractLab__VocalTractLabApi;
int __pyx_module_is_main_VocalTractLab__VocalTractLabApi = 0;

/* Implementation of 'VocalTractLab.VocalTractLabApi' */
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_open;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_round;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_ImportError;
static const char __pyx_k_S[] = "S";
static const char __pyx_k_T[] = "T";
static const char __pyx_k_f[] = "f";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_w[] = "w";
static const char __pyx_k_x[] = "x";
static const char __pyx_k_y[] = "y";
static const char __pyx_k_AT[] = "AT";
static const char __pyx_k_FT[] = "FT";
static const char __pyx_k__2[] = "          ";
static const char __pyx_k__3[] = "                                                                                                    ";
static const char __pyx_k__4[] = "\000";
static const char __pyx_k__5[] = "";
static const char __pyx_k__7[] = " ";
static const char __pyx_k__8[] = "\t";
static const char __pyx_k__9[] = ",";
static const char __pyx_k_df[] = "df";
static const char __pyx_k_mp[] = "mp";
static const char __pyx_k_np[] = "np";
static const char __pyx_k_os[] = "os";
static const char __pyx_k_pd[] = "pd";
static const char __pyx_k_sr[] = "sr";
static const char __pyx_k__13[] = ".";
static const char __pyx_k__16[] = "*";
static const char __pyx_k_abs[] = "abs";
static const char __pyx_k_arg[] = "arg";
static const char __pyx_k_bs4[] = "bs4";
static const char __pyx_k_fps[] = "fps";
static const char __pyx_k_ges[] = ".ges";
static const char __pyx_k_key[] = "key";
static const char __pyx_k_log[] = "log";
static const char __pyx_k_max[] = "max";
static const char __pyx_k_min[] = "min";
static const char __pyx_k_svg[] = "_svg";
static const char __pyx_k_wav[] = ".wav";
static const char __pyx_k_Pool[] = "Pool";
static const char __pyx_k_args[] = "args";
static const char __pyx_k_copy[] = "copy";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_file[] = "__file__";
static const char __pyx_k_find[] = "find";
static const char __pyx_k_imap[] = "imap";
static const char __pyx_k_info[] = "info";
static const char __pyx_k_join[] = "join";
static const char __pyx_k_load[] = "load";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_numS[] = "numS";
static const char __pyx_k_open[] = "open";
static const char __pyx_k_pair[] = "pair";
static const char __pyx_k_path[] = "path";
static const char __pyx_k_pool[] = "pool";
static const char __pyx_k_read[] = "read";
static const char __pyx_k_save[] = "save";
static const char __pyx_k_send[] = "send";
static const char __pyx_k_stft[] = "stft";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_time[] = "time";
static const char __pyx_k_tqdm[] = "tqdm";
static const char __pyx_k_type[] = "type";
static const char __pyx_k_unit[] = "unit";
static const char __pyx_k_warn[] = "warn";
static const char __pyx_k_array[] = "array";
static const char __pyx_k_audio[] = "audio";
static const char __pyx_k_close[] = "_close";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_empty[] = "empty";
static const char __pyx_k_index[] = "index";
static const char __pyx_k_items[] = "items";
static const char __pyx_k_names[] = "names";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_ravel[] = "ravel";
static const char __pyx_k_round[] = "round";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_split[] = "split";
static const char __pyx_k_state[] = "state";
static const char __pyx_k_strip[] = "strip";
static const char __pyx_k_tasks[] = "tasks";
static const char __pyx_k_throw[] = "throw";
static const char __pyx_k_total[] = "total";
static const char __pyx_k_tract[] = "tract";
static const char __pyx_k_units[] = "units";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_write[] = "write";
static const char __pyx_k_zeros[] = "zeros";
static const char __pyx_k_atexit[] = "atexit";
static const char __pyx_k_ctypes[] = "ctypes";
static const char __pyx_k_decode[] = "decode";
static const char __pyx_k_encode[] = "encode";
static const char __pyx_k_exists[] = "exists";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_length[] = "length";
static const char __pyx_k_name_2[] = "__name__";
static const char __pyx_k_pandas[] = "pandas";
static const char __pyx_k_params[] = "params";
static const char __pyx_k_rsplit[] = "rsplit";
static const char __pyx_k_states[] = "states";
static const char __pyx_k_worker[] = "_worker";
static const char __pyx_k_WARNING[] = "WARNING";
static const char __pyx_k_close_2[] = "close";
static const char __pyx_k_columns[] = "columns";
static const char __pyx_k_dirname[] = "dirname";
static const char __pyx_k_element[] = "element";
static const char __pyx_k_feature[] = "feature";
static const char __pyx_k_float64[] = "float64";
static const char __pyx_k_genexpr[] = "genexpr";
static const char __pyx_k_glottis[] = "glottis";
static const char __pyx_k_librosa[] = "librosa";
static const char __pyx_k_logging[] = "logging";
static const char __pyx_k_orig_sr[] = "orig_sr";
static const char __pyx_k_replace[] = "replace";
static const char __pyx_k_svg_dir[] = "svg_dir";
static const char __pyx_k_tract_2[] = ".tract";
static const char __pyx_k_verbose[] = "verbose";
static const char __pyx_k_version[] = "version";
static const char __pyx_k_warning[] = "warning";
static const char __pyx_k_workers[] = "workers";
static const char __pyx_k_fileName[] = "fileName";
static const char __pyx_k_function[] = "function";
static const char __pyx_k_ges_file[] = "ges_file";
static const char __pyx_k_ges_soup[] = "ges_soup";
static const char __pyx_k_paramMax[] = "paramMax";
static const char __pyx_k_paramMin[] = "paramMin";
static const char __pyx_k_prettify[] = "prettify";
static const char __pyx_k_register[] = "register";
static const char __pyx_k_resample[] = "resample";
static const char __pyx_k_setLevel[] = "setLevel";
static const char __pyx_k_standard[] = "standard";
static const char __pyx_k_time_end[] = "time_end";
static const char __pyx_k_to_numpy[] = "to_numpy";
static const char __pyx_k_warnings[] = "warnings";
static const char __pyx_k_DataFrame[] = "DataFrame";
static const char __pyx_k_constants[] = "constants";
static const char __pyx_k_cpu_count[] = "cpu_count";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_formatter[] = "formatter";
static const char __pyx_k_getLogger[] = "getLogger";
static const char __pyx_k_get_shape[] = "get_shape";
static const char __pyx_k_itertools[] = "itertools";
static const char __pyx_k_log_scale[] = "log_scale";
static const char __pyx_k_magnitude[] = "magnitude";
static const char __pyx_k_n_samples[] = "n_samples";
static const char __pyx_k_normalize[] = "normalize";
static const char __pyx_k_numFrames[] = "numFrames";
static const char __pyx_k_phase_rad[] = "phase_rad";
static const char __pyx_k_save_file[] = "save_file";
static const char __pyx_k_shapeName[] = "shapeName";
static const char __pyx_k_target_sr[] = "target_sr";
static const char __pyx_k_tube_area[] = "tube_area";
static const char __pyx_k_Tube_State[] = "Tube_State";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_audio_args[] = "audio_args";
static const char __pyx_k_get_shapes[] = "get_shapes";
static const char __pyx_k_initialize[] = "_initialize";
static const char __pyx_k_save_video[] = "save_video";
static const char __pyx_k_shape_list[] = "shape_list";
static const char __pyx_k_time_start[] = "time_start";
static const char __pyx_k_tract__svg[] = "/tract_{}.svg";
static const char __pyx_k_ImportError[] = "ImportError";
static const char __pyx_k_Motor_Score[] = "Motor_Score";
static const char __pyx_k_basicConfig[] = "basicConfig";
static const char __pyx_k_description[] = "description";
static const char __pyx_k_gesFileName[] = "gesFileName";
static const char __pyx_k_get_version[] = "get_version";
static const char __pyx_k_html_parser[] = "html.parser";
static const char __pyx_k_motor_score[] = "motor_score";
static const char __pyx_k_power_to_db[] = "power_to_db";
static const char __pyx_k_return_data[] = "return_data";
static const char __pyx_k_segFileName[] = "segFileName";
static const char __pyx_k_spectrogram[] = "spectrogram";
static const char __pyx_k_synth_block[] = "_synth_block";
static const char __pyx_k_tractParams[] = "tractParams";
static const char __pyx_k_tract_state[] = "tract_state";
static const char __pyx_k_tube_length[] = "tube_length";
static const char __pyx_k_tube_states[] = "tube_states";
static const char __pyx_k_wavFileName[] = "wavFileName";
static const char __pyx_k_zip_longest[] = "zip_longest";
static const char __pyx_k_descriptions[] = "descriptions";
static const char __pyx_k_return_audio[] = "return_audio";
static const char __pyx_k_svg_dir_list[] = "svg_dir_list";
static const char __pyx_k_tract_states[] = "tract_states";
static const char __pyx_k_tubeArea_cm2[] = "tubeArea_cm2";
static const char __pyx_k_BeautifulSoup[] = "BeautifulSoup";
static const char __pyx_k_ges_file_path[] = "ges_file_path";
static const char __pyx_k_get_constants[] = "get_constants";
static const char __pyx_k_glottisParams[] = "glottisParams";
static const char __pyx_k_inTractParams[] = "inTractParams";
static const char __pyx_k_incisorPos_cm[] = "incisorPos_cm";
static const char __pyx_k_paramStandard[] = "paramStandard";
static const char __pyx_k_seg_file_path[] = "seg_file_path";
static const char __pyx_k_state_samples[] = "state_samples";
static const char __pyx_k_tubeLength_cm[] = "tubeLength_cm";
static const char __pyx_k_velum_opening[] = "velum_opening";
static const char __pyx_k_Motor_Sequence[] = "Motor_Sequence";
static const char __pyx_k_gestural_score[] = "gestural_score";
static const char __pyx_k_get_param_info[] = "get_param_info";
static const char __pyx_k_glottis_states[] = "glottis_states";
static const char __pyx_k_melspectrogram[] = "melspectrogram";
static const char __pyx_k_motor_sequence[] = "motor_sequence";
static const char __pyx_k_n_tract_params[] = "n_tract_params";
static const char __pyx_k_outTractParams[] = "outTractParams";
static const char __pyx_k_phase_spectrum[] = "phase_spectrum";
static const char __pyx_k_return_samples[] = "return_samples";
static const char __pyx_k_save_tube_area[] = "save_tube_area";
static const char __pyx_k_time_synth_end[] = "time_synth_end";
static const char __pyx_k_audio_data_list[] = "audio_data_list";
static const char __pyx_k_audio_file_path[] = "audio_file_path";
static const char __pyx_k_from_tract_file[] = "from_tract_file";
static const char __pyx_k_make_output_dir[] = "make_output_dir";
static const char __pyx_k_multiprocessing[] = "multiprocessing";
static const char __pyx_k_n_tube_sections[] = "n_tube_sections";
static const char __pyx_k_normalize_audio[] = "normalize_audio";
static const char __pyx_k_numAudioSamples[] = "numAudioSamples";
static const char __pyx_k_numTubeSections[] = "numTubeSections";
static const char __pyx_k_resampled_index[] = "resampled_index";
static const char __pyx_k_return_sequence[] = "return_sequence";
static const char __pyx_k_speakerFileName[] = "speakerFileName";
static const char __pyx_k_tract_file_path[] = "tract_file_path";
static const char __pyx_k_tubeArticulator[] = "tubeArticulator";
static const char __pyx_k_gesture_sequence[] = "gesture_sequence";
static const char __pyx_k_in_ges_file_path[] = "in_ges_file_path";
static const char __pyx_k_incisor_position[] = "incisor_position";
static const char __pyx_k_make_output_path[] = "make_output_path";
static const char __pyx_k_n_glottis_params[] = "n_glottis_params";
static const char __pyx_k_numGlottisParams[] = "numGlottisParams";
static const char __pyx_k_samplerate_audio[] = "samplerate_audio";
static const char __pyx_k_save_tube_length[] = "save_tube_length";
static const char __pyx_k_time_synth_start[] = "time_synth_start";
static const char __pyx_k_tract_param_data[] = "tract_param_data";
static const char __pyx_k_tube_articulator[] = "tube_articulator";
static const char __pyx_k_velumOpening_cm2[] = "velumOpening_cm2";
static const char __pyx_k_Transfer_Function[] = "Transfer_Function";
static const char __pyx_k_audioSamplingRate[] = "audioSamplingRate";
static const char __pyx_k_frameStep_samples[] = "frameStep_samples";
static const char __pyx_k_load_speaker_file[] = "load_speaker_file";
static const char __pyx_k_numGestureSamples[] = "numGestureSamples";
static const char __pyx_k_out_ges_file_path[] = "out_ges_file_path";
static const char __pyx_k_speaker_file_path[] = "speaker_file_path";
static const char __pyx_k_to_motor_sequence[] = "to_motor_sequence";
static const char __pyx_k_voice_quality_new[] = "voice_quality_new";
static const char __pyx_k_voice_quality_old[] = "voice_quality_old";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_ges_file_path_list[] = "ges_file_path_list";
static const char __pyx_k_magnitude_spectrum[] = "magnitude_spectrum";
static const char __pyx_k_n_spectrum_samples[] = "n_spectrum_samples";
static const char __pyx_k_numSpectrumSamples[] = "numSpectrumSamples";
static const char __pyx_k_save_velum_opening[] = "save_velum_opening";
static const char __pyx_k_seg_file_path_list[] = "seg_file_path_list";
static const char __pyx_k_spectrogram_kwargs[] = "spectrogram_kwargs";
static const char __pyx_k_sub_glottal_shapes[] = "sub_glottal_shapes";
static const char __pyx_k_transfer_functions[] = "transfer_functions";
static const char __pyx_k_enableConsoleOutput[] = "enableConsoleOutput";
static const char __pyx_k_gestural_score_soup[] = "gestural_score_soup";
static const char __pyx_k_modification_kwargs[] = "modification_kwargs";
static const char __pyx_k_motor_sequence_data[] = "motor_sequence_data";
static const char __pyx_k_motor_sequence_list[] = "motor_sequence_list";
static const char __pyx_k_motor_sequence_name[] = "motor_sequence_name";
static const char __pyx_k_n_samples_per_state[] = "n_samples_per_state";
static const char __pyx_k_numVocalTractParams[] = "numVocalTractParams";
static const char __pyx_k_run_multiprocessing[] = "_run_multiprocessing";
static const char __pyx_k_samplerate_internal[] = "samplerate_internal";
static const char __pyx_k_save_phase_spectrum[] = "save_phase_spectrum";
static const char __pyx_k_speaker_JD3_speaker[] = "speaker/JD3.speaker";
static const char __pyx_k_tract_sequence_list[] = "tract_sequence_list";
static const char __pyx_k_Sub_Glottal_Sequence[] = "Sub_Glottal_Sequence";
static const char __pyx_k_audio_file_path_list[] = "audio_file_path_list";
static const char __pyx_k_automaticCalculation[] = "automaticCalculation";
static const char __pyx_k_internalSamplingRate[] = "internalSamplingRate";
static const char __pyx_k_spectrogram_pkl_gzip[] = "_spectrogram.pkl.gzip";
static const char __pyx_k_sub_glottal_sequence[] = "sub_glottal_sequence";
static const char __pyx_k_supra_glottal_shapes[] = "supra_glottal_shapes";
static const char __pyx_k_tract_file_path_list[] = "tract_file_path_list";
static const char __pyx_k_VocalTractLab_targets[] = "VocalTractLab.targets";
static const char __pyx_k_automatic_calculation[] = "automatic_calculation";
static const char __pyx_k_change_gestural_score[] = "change_gestural_score";
static const char __pyx_k_get_sub_glottal_state[] = "get_sub_glottal_state";
static const char __pyx_k_in_ges_file_path_list[] = "in_ges_file_path_list";
static const char __pyx_k_melspectrogram_kwargs[] = "melspectrogram_kwargs";
static const char __pyx_k_modify_gestural_score[] = "_modify_gestural_score";
static const char __pyx_k_return_motor_sequence[] = "return_motor_sequence";
static const char __pyx_k_save_incisor_position[] = "save_incisor_position";
static const char __pyx_k_save_tube_articulator[] = "save_tube_articulator";
static const char __pyx_k_spectrogram_file_path[] = "spectrogram_file_path";
static const char __pyx_k_to_sub_glottal_states[] = "to_sub_glottal_states";
static const char __pyx_k_tractSequenceFileName[] = "tractSequenceFileName";
static const char __pyx_k_tract_sequence_to_svg[] = "_tract_sequence_to_svg";
static const char __pyx_k_Supra_Glottal_Sequence[] = "Supra_Glottal_Sequence";
static const char __pyx_k_check_if_list_is_valid[] = "check_if_list_is_valid";
static const char __pyx_k_glottal_shape_gestures[] = "glottal-shape-gestures";
static const char __pyx_k_out_ges_file_path_list[] = "out_ges_file_path_list";
static const char __pyx_k_resampled_tract_states[] = "resampled_tract_states";
static const char __pyx_k_supra_glottal_sequence[] = "supra_glottal_sequence";
static const char __pyx_k_tongueTipSideElevation[] = "tongueTipSideElevation";
static const char __pyx_k_gestural_score_to_audio[] = "_gestural_score_to_audio";
static const char __pyx_k_get_supra_glottal_state[] = "get_supra_glottal_state";
static const char __pyx_k_save_magnitude_spectrum[] = "save_magnitude_spectrum";
static const char __pyx_k_sub_glottal_shape_names[] = "sub_glottal_shape_names";
static const char __pyx_k_to_sub_glottal_sequence[] = "to_sub_glottal_sequence";
static const char __pyx_k_to_supra_glottal_states[] = "to_supra_glottal_states";
static const char __pyx_k_tract_sequence_to_audio[] = "_tract_sequence_to_audio";
static const char __pyx_k_tract_sequence_to_svg_2[] = "tract_sequence_to_svg";
static const char __pyx_k_melspectrogram_file_path[] = "melspectrogram_file_path";
static const char __pyx_k_VocalTractLab_audio_tools[] = "VocalTractLab.audio_tools";
static const char __pyx_k_VocalTractLab_tube_states[] = "VocalTractLab.tube_states";
static const char __pyx_k_gestural_score_to_audio_2[] = "gestural_score_to_audio";
static const char __pyx_k_sub_glottal_sequence_name[] = "sub_glottal_sequence_name";
static const char __pyx_k_supra_glottal_shape_names[] = "supra_glottal_shape_names";
static const char __pyx_k_to_supra_glottal_sequence[] = "to_supra_glottal_sequence";
static const char __pyx_k_tongue_tip_side_elevation[] = "tongue_tip_side_elevation";
static const char __pyx_k_tract_sequence_to_audio_2[] = "tract_sequence_to_audio";
static const char __pyx_k_tract_state_to_tube_state[] = "_tract_state_to_tube_state";
static const char __pyx_k_spectrogram_file_path_list[] = "spectrogram_file_path_list";
static const char __pyx_k_Compile_date_of_the_library[] = "Compile date of the library: {}";
static const char __pyx_k_supra_glottal_sequence_name[] = "supra_glottal_sequence_name";
static const char __pyx_k_VocalTractLab_function_tools[] = "VocalTractLab.function_tools";
static const char __pyx_k_VocalTractLab_tract_sequence[] = "VocalTractLab.tract_sequence";
static const char __pyx_k_numAudioSamplesPerTractState[] = "numAudioSamplesPerTractState";
static const char __pyx_k_motor_sequence_to_spectrogram[] = "_motor_sequence_to_spectrogram";
static const char __pyx_k_tract_sequence_to_tube_states[] = "tract_sequence_to_tube_states";
static const char __pyx_k_VocalTractLab_VocalTractLabApi[] = "VocalTractLab.VocalTractLabApi";
static const char __pyx_k_VocalTractLab_frequency_domain[] = "VocalTractLab.frequency_domain";
static const char __pyx_k_check_if_input_lists_are_valid[] = "check_if_input_lists_are_valid";
static const char __pyx_k_gestural_score_change_duration[] = "_gestural_score_change_duration";
static const char __pyx_k_limited_supra_glottal_sequence[] = "limited_supra_glottal_sequence";
static const char __pyx_k_save_tongue_tip_side_elevation[] = "save_tongue_tip_side_elevation";
static const char __pyx_k_Created_tractsequence_file_from[] = "Created tractsequence file {} from gestural score file: {}";
static const char __pyx_k_gestural_score_change_voice_qua[] = "_gestural_score_change_voice_quality";
static const char __pyx_k_gestural_score_to_tract_sequenc[] = "_gestural_score_to_tract_sequence";
static const char __pyx_k_motor_sequence_argument_must_be[] = "motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}";
static const char __pyx_k_motor_sequence_to_melspectrogra[] = "_motor_sequence_to_melspectrogram";
static const char __pyx_k_motor_sequence_to_spectrogram_2[] = "motor_sequence_to_spectrogram";
static const char __pyx_k_numpy_core_multiarray_failed_to[] = "numpy.core.multiarray failed to import";
static const char __pyx_k_run_multiprocessing_locals_gene[] = "_run_multiprocessing.<locals>.genexpr";
static const char __pyx_k_segment_sequence_to_gestural_sc[] = "_segment_sequence_to_gestural_score";
static const char __pyx_k_tract_sequence_to_limited_tract[] = "tract_sequence_to_limited_tract_sequence";
static const char __pyx_k_tract_state_to_limited_tract_st[] = "_tract_state_to_limited_tract_state";
static const char __pyx_k_tract_state_to_transfer_functio[] = "_tract_state_to_transfer_function";
static const char __pyx_k_Audio_generated_from_gestural_sc[] = "Audio generated from gestural score file: {}";
static const char __pyx_k_Audio_generated_from_motor_seque[] = "Audio generated from motor_sequence: {}";
static const char __pyx_k_Automatic_calculation_of_the_Ton[] = "Automatic calculation of the Tongue Root parameters was set to {}.";
static const char __pyx_k_Created_gestural_score_from_segm[] = "Created gestural score from segment sequence file: {}";
static const char __pyx_k_Error_at_element_element_value_v[] = "Error at element: {}, element.value: {}, vq old: {}, vq new: {}";
static const char __pyx_k_Loaded_new_speakerfile_Overwriti[] = "Loaded new speakerfile: {}. Overwriting existing settings with the values from the new speaker file.";
static const char __pyx_k_Specified_shape_was_not_found_in[] = "Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.";
static const char __pyx_k_Unknown_key_in_get_param_info_Ke[] = "Unknown key in \"get_param_info\". Key must be \"tract\" or \"glottis\". Returning \"tract\" infos now.";
static const char __pyx_k_VTL_API_function_vtlCalcTongueRo[] = "VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)";
static const char __pyx_k_VTL_API_function_vtlClose_return[] = "VTL API function vtlClose returned the Errorcode: {}  (See API doc for info.)";
static const char __pyx_k_VTL_API_function_vtlGesturalScor[] = "VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \t\t\twhile processing gestural score file (input): {}, audio file (output): {}";
static const char __pyx_k_VTL_API_function_vtlGetConstants[] = "VTL API function vtlGetConstants returned the Errorcode: {}  (See API doc for info.)";
static const char __pyx_k_VTL_API_function_vtlGetTractPara[] = "VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)";
static const char __pyx_k_VTL_API_function_vtlInitialize_r[] = "VTL API function vtlInitialize returned the Errorcode: {}  (See API doc for info.)";
static const char __pyx_k_VTL_API_function_vtlSegmentSeque[] = "VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \t\t\twhile processing segment sequence file (input): {}, gestural score file (output): {}";
static const char __pyx_k_VTL_API_function_vtlSynthBlock_r[] = "VTL API function vtlSynthBlock returned the Errorcode: {}  (See API doc for info.)";
static const char __pyx_k_VocalTractLab_VocalTractLabApi_p[] = "VocalTractLab\\VocalTractLabApi.pyx";
static const char __pyx_k_automatic_calculation_of_TRX_and[] = "automatic_calculation_of_TRX_and_TRY";
static const char __pyx_k_gestural_score_to_tract_sequence[] = "gestural_score_to_tract_sequence";
static const char __pyx_k_get_gestural_score_audio_duratio[] = "get_gestural_score_audio_duration";
static const char __pyx_k_motor_sequence_to_melspectrogram[] = "motor_sequence_to_melspectrogram";
static const char __pyx_k_numpy_core_umath_failed_to_impor[] = "numpy.core.umath failed to import";
static const char __pyx_k_segment_sequence_to_gestural_sco[] = "segment_sequence_to_gestural_score";
static const char __pyx_k_standard_16kHz_melspectrogram_80[] = "standard_16kHz_melspectrogram_80_kwargs";
static const char __pyx_k_standard_16kHz_spectrogram_kwarg[] = "standard_16kHz_spectrogram_kwargs";
static const char __pyx_k_the_specified_gestural_score_fil[] = "the specified gestural score file path does not exist: {}. API call will be skipped.";
static const char __pyx_k_the_specified_segment_sequence_f[] = "the specified segment sequence file path does not exist: {}. API call will be skipped.";
static const char __pyx_k_the_specified_tract_sequence_fil[] = "the specified tract sequence file path does not exist: {}. API call will be skipped.";
static const char __pyx_k_tract_sequence_to_transfer_funct[] = "tract_sequence_to_transfer_functions";
static const char __pyx_k_VTL_API_function_vtlGesturalScor_2[] = "VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \t\t\twhile processing gestural score file (input): {}, tract sequence file (output): {}";
static const char __pyx_k_VTL_API_function_vtlGetTractPara_2[] = "VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)";
static PyObject *__pyx_n_s_AT;
static PyObject *__pyx_kp_s_Audio_generated_from_gestural_sc;
static PyObject *__pyx_kp_s_Audio_generated_from_motor_seque;
static PyObject *__pyx_kp_s_Automatic_calculation_of_the_Ton;
static PyObject *__pyx_n_s_BeautifulSoup;
static PyObject *__pyx_kp_s_Compile_date_of_the_library;
static PyObject *__pyx_kp_s_Created_gestural_score_from_segm;
static PyObject *__pyx_kp_s_Created_tractsequence_file_from;
static PyObject *__pyx_n_s_DataFrame;
static PyObject *__pyx_kp_s_Error_at_element_element_value_v;
static PyObject *__pyx_n_s_FT;
static PyObject *__pyx_n_s_ImportError;
static PyObject *__pyx_kp_s_Loaded_new_speakerfile_Overwriti;
static PyObject *__pyx_n_s_Motor_Score;
static PyObject *__pyx_n_s_Motor_Sequence;
static PyObject *__pyx_n_s_Pool;
static PyObject *__pyx_n_s_S;
static PyObject *__pyx_kp_s_Specified_shape_was_not_found_in;
static PyObject *__pyx_n_s_Sub_Glottal_Sequence;
static PyObject *__pyx_n_s_Supra_Glottal_Sequence;
static PyObject *__pyx_n_s_T;
static PyObject *__pyx_n_s_Transfer_Function;
static PyObject *__pyx_n_s_Tube_State;
static PyObject *__pyx_kp_s_Unknown_key_in_get_param_info_Ke;
static PyObject *__pyx_kp_s_VTL_API_function_vtlCalcTongueRo;
static PyObject *__pyx_kp_s_VTL_API_function_vtlClose_return;
static PyObject *__pyx_kp_s_VTL_API_function_vtlGesturalScor;
static PyObject *__pyx_kp_s_VTL_API_function_vtlGesturalScor_2;
static PyObject *__pyx_kp_s_VTL_API_function_vtlGetConstants;
static PyObject *__pyx_kp_s_VTL_API_function_vtlGetTractPara;
static PyObject *__pyx_kp_s_VTL_API_function_vtlGetTractPara_2;
static PyObject *__pyx_kp_s_VTL_API_function_vtlInitialize_r;
static PyObject *__pyx_kp_s_VTL_API_function_vtlSegmentSeque;
static PyObject *__pyx_kp_s_VTL_API_function_vtlSynthBlock_r;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_n_s_VocalTractLab_VocalTractLabApi;
static PyObject *__pyx_kp_s_VocalTractLab_VocalTractLabApi_p;
static PyObject *__pyx_n_s_VocalTractLab_audio_tools;
static PyObject *__pyx_n_s_VocalTractLab_frequency_domain;
static PyObject *__pyx_n_s_VocalTractLab_function_tools;
static PyObject *__pyx_n_s_VocalTractLab_targets;
static PyObject *__pyx_n_s_VocalTractLab_tract_sequence;
static PyObject *__pyx_n_s_VocalTractLab_tube_states;
static PyObject *__pyx_n_s_WARNING;
static PyObject *__pyx_kp_s__13;
static PyObject *__pyx_n_s__16;
static PyObject *__pyx_kp_s__2;
static PyObject *__pyx_kp_s__3;
static PyObject *__pyx_kp_s__4;
static PyObject *__pyx_kp_s__5;
static PyObject *__pyx_kp_s__7;
static PyObject *__pyx_kp_s__8;
static PyObject *__pyx_kp_s__9;
static PyObject *__pyx_n_s_abs;
static PyObject *__pyx_n_s_arg;
static PyObject *__pyx_n_s_args;
static PyObject *__pyx_n_s_array;
static PyObject *__pyx_n_s_atexit;
static PyObject *__pyx_n_s_audio;
static PyObject *__pyx_n_s_audioSamplingRate;
static PyObject *__pyx_n_s_audio_args;
static PyObject *__pyx_n_s_audio_data_list;
static PyObject *__pyx_n_s_audio_file_path;
static PyObject *__pyx_n_s_audio_file_path_list;
static PyObject *__pyx_n_s_automaticCalculation;
static PyObject *__pyx_n_s_automatic_calculation;
static PyObject *__pyx_n_s_automatic_calculation_of_TRX_and;
static PyObject *__pyx_n_s_basicConfig;
static PyObject *__pyx_n_s_bs4;
static PyObject *__pyx_n_s_change_gestural_score;
static PyObject *__pyx_n_s_check_if_input_lists_are_valid;
static PyObject *__pyx_n_s_check_if_list_is_valid;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_close;
static PyObject *__pyx_n_s_close_2;
static PyObject *__pyx_n_s_columns;
static PyObject *__pyx_n_s_constants;
static PyObject *__pyx_n_s_copy;
static PyObject *__pyx_n_s_cpu_count;
static PyObject *__pyx_n_s_ctypes;
static PyObject *__pyx_n_s_data;
static PyObject *__pyx_n_s_decode;
static PyObject *__pyx_n_s_description;
static PyObject *__pyx_n_s_descriptions;
static PyObject *__pyx_n_s_df;
static PyObject *__pyx_n_s_dirname;
static PyObject *__pyx_n_s_dtype;
static PyObject *__pyx_n_s_element;
static PyObject *__pyx_n_s_empty;
static PyObject *__pyx_n_s_enableConsoleOutput;
static PyObject *__pyx_n_s_encode;
static PyObject *__pyx_n_s_enumerate;
static PyObject *__pyx_n_s_exists;
static PyObject *__pyx_n_s_f;
static PyObject *__pyx_n_s_feature;
static PyObject *__pyx_n_s_file;
static PyObject *__pyx_n_s_fileName;
static PyObject *__pyx_n_s_find;
static PyObject *__pyx_n_s_float64;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_formatter;
static PyObject *__pyx_n_s_fps;
static PyObject *__pyx_n_s_frameStep_samples;
static PyObject *__pyx_n_s_from_tract_file;
static PyObject *__pyx_n_s_function;
static PyObject *__pyx_n_s_genexpr;
static PyObject *__pyx_kp_s_ges;
static PyObject *__pyx_n_s_gesFileName;
static PyObject *__pyx_n_s_ges_file;
static PyObject *__pyx_n_s_ges_file_path;
static PyObject *__pyx_n_s_ges_file_path_list;
static PyObject *__pyx_n_s_ges_soup;
static PyObject *__pyx_n_s_gestural_score;
static PyObject *__pyx_n_s_gestural_score_change_duration;
static PyObject *__pyx_n_s_gestural_score_change_voice_qua;
static PyObject *__pyx_n_s_gestural_score_soup;
static PyObject *__pyx_n_s_gestural_score_to_audio;
static PyObject *__pyx_n_s_gestural_score_to_audio_2;
static PyObject *__pyx_n_s_gestural_score_to_tract_sequenc;
static PyObject *__pyx_n_s_gestural_score_to_tract_sequence;
static PyObject *__pyx_n_s_gesture_sequence;
static PyObject *__pyx_n_s_getLogger;
static PyObject *__pyx_n_s_get_constants;
static PyObject *__pyx_n_s_get_gestural_score_audio_duratio;
static PyObject *__pyx_n_s_get_param_info;
static PyObject *__pyx_n_s_get_shape;
static PyObject *__pyx_n_s_get_shapes;
static PyObject *__pyx_n_s_get_sub_glottal_state;
static PyObject *__pyx_n_s_get_supra_glottal_state;
static PyObject *__pyx_n_s_get_version;
static PyObject *__pyx_kp_s_glottal_shape_gestures;
static PyObject *__pyx_n_s_glottis;
static PyObject *__pyx_n_s_glottisParams;
static PyObject *__pyx_n_s_glottis_states;
static PyObject *__pyx_kp_s_html_parser;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_imap;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_inTractParams;
static PyObject *__pyx_n_s_in_ges_file_path;
static PyObject *__pyx_n_s_in_ges_file_path_list;
static PyObject *__pyx_n_s_incisorPos_cm;
static PyObject *__pyx_n_s_incisor_position;
static PyObject *__pyx_n_s_index;
static PyObject *__pyx_n_s_info;
static PyObject *__pyx_n_s_initialize;
static PyObject *__pyx_n_s_internalSamplingRate;
static PyObject *__pyx_n_s_items;
static PyObject *__pyx_n_s_itertools;
static PyObject *__pyx_n_s_join;
static PyObject *__pyx_n_s_key;
static PyObject *__pyx_n_s_length;
static PyObject *__pyx_n_s_librosa;
static PyObject *__pyx_n_s_limited_supra_glottal_sequence;
static PyObject *__pyx_n_s_load;
static PyObject *__pyx_n_s_load_speaker_file;
static PyObject *__pyx_n_s_log;
static PyObject *__pyx_n_s_log_scale;
static PyObject *__pyx_n_s_logging;
static PyObject *__pyx_n_s_magnitude;
static PyObject *__pyx_n_s_magnitude_spectrum;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_make_output_dir;
static PyObject *__pyx_n_s_make_output_path;
static PyObject *__pyx_n_s_max;
static PyObject *__pyx_n_s_melspectrogram;
static PyObject *__pyx_n_s_melspectrogram_file_path;
static PyObject *__pyx_n_s_melspectrogram_kwargs;
static PyObject *__pyx_n_s_min;
static PyObject *__pyx_n_s_modification_kwargs;
static PyObject *__pyx_n_s_modify_gestural_score;
static PyObject *__pyx_n_s_motor_score;
static PyObject *__pyx_n_s_motor_sequence;
static PyObject *__pyx_kp_s_motor_sequence_argument_must_be;
static PyObject *__pyx_n_s_motor_sequence_data;
static PyObject *__pyx_n_s_motor_sequence_list;
static PyObject *__pyx_n_s_motor_sequence_name;
static PyObject *__pyx_n_s_motor_sequence_to_melspectrogra;
static PyObject *__pyx_n_s_motor_sequence_to_melspectrogram;
static PyObject *__pyx_n_s_motor_sequence_to_spectrogram;
static PyObject *__pyx_n_s_motor_sequence_to_spectrogram_2;
static PyObject *__pyx_n_s_mp;
static PyObject *__pyx_n_s_multiprocessing;
static PyObject *__pyx_n_s_n_glottis_params;
static PyObject *__pyx_n_s_n_samples;
static PyObject *__pyx_n_s_n_samples_per_state;
static PyObject *__pyx_n_s_n_spectrum_samples;
static PyObject *__pyx_n_s_n_tract_params;
static PyObject *__pyx_n_s_n_tube_sections;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_names;
static PyObject *__pyx_n_s_normalize;
static PyObject *__pyx_n_s_normalize_audio;
static PyObject *__pyx_n_s_np;
static PyObject *__pyx_n_s_numAudioSamples;
static PyObject *__pyx_n_s_numAudioSamplesPerTractState;
static PyObject *__pyx_n_s_numFrames;
static PyObject *__pyx_n_s_numGestureSamples;
static PyObject *__pyx_n_s_numGlottisParams;
static PyObject *__pyx_n_s_numS;
static PyObject *__pyx_n_s_numSpectrumSamples;
static PyObject *__pyx_n_s_numTubeSections;
static PyObject *__pyx_n_s_numVocalTractParams;
static PyObject *__pyx_n_s_numpy;
static PyObject *__pyx_kp_s_numpy_core_multiarray_failed_to;
static PyObject *__pyx_kp_s_numpy_core_umath_failed_to_impor;
static PyObject *__pyx_n_s_open;
static PyObject *__pyx_n_s_orig_sr;
static PyObject *__pyx_n_s_os;
static PyObject *__pyx_n_s_outTractParams;
static PyObject *__pyx_n_s_out_ges_file_path;
static PyObject *__pyx_n_s_out_ges_file_path_list;
static PyObject *__pyx_n_s_pair;
static PyObject *__pyx_n_s_pandas;
static PyObject *__pyx_n_s_paramMax;
static PyObject *__pyx_n_s_paramMin;
static PyObject *__pyx_n_s_paramStandard;
static PyObject *__pyx_n_s_params;
static PyObject *__pyx_n_s_path;
static PyObject *__pyx_n_s_pd;
static PyObject *__pyx_n_s_phase_rad;
static PyObject *__pyx_n_s_phase_spectrum;
static PyObject *__pyx_n_s_pool;
static PyObject *__pyx_n_s_power_to_db;
static PyObject *__pyx_n_s_prettify;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_ravel;
static PyObject *__pyx_n_s_read;
static PyObject *__pyx_n_s_register;
static PyObject *__pyx_n_s_replace;
static PyObject *__pyx_n_s_resample;
static PyObject *__pyx_n_s_resampled_index;
static PyObject *__pyx_n_s_resampled_tract_states;
static PyObject *__pyx_n_s_return_audio;
static PyObject *__pyx_n_s_return_data;
static PyObject *__pyx_n_s_return_motor_sequence;
static PyObject *__pyx_n_s_return_samples;
static PyObject *__pyx_n_s_return_sequence;
static PyObject *__pyx_n_s_round;
static PyObject *__pyx_n_s_rsplit;
static PyObject *__pyx_n_s_run_multiprocessing;
static PyObject *__pyx_n_s_run_multiprocessing_locals_gene;
static PyObject *__pyx_n_s_samplerate_audio;
static PyObject *__pyx_n_s_samplerate_internal;
static PyObject *__pyx_n_s_save;
static PyObject *__pyx_n_s_save_file;
static PyObject *__pyx_n_s_save_incisor_position;
static PyObject *__pyx_n_s_save_magnitude_spectrum;
static PyObject *__pyx_n_s_save_phase_spectrum;
static PyObject *__pyx_n_s_save_tongue_tip_side_elevation;
static PyObject *__pyx_n_s_save_tube_area;
static PyObject *__pyx_n_s_save_tube_articulator;
static PyObject *__pyx_n_s_save_tube_length;
static PyObject *__pyx_n_s_save_velum_opening;
static PyObject *__pyx_n_s_save_video;
static PyObject *__pyx_n_s_segFileName;
static PyObject *__pyx_n_s_seg_file_path;
static PyObject *__pyx_n_s_seg_file_path_list;
static PyObject *__pyx_n_s_segment_sequence_to_gestural_sc;
static PyObject *__pyx_n_s_segment_sequence_to_gestural_sco;
static PyObject *__pyx_n_s_send;
static PyObject *__pyx_n_s_setLevel;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_shapeName;
static PyObject *__pyx_n_s_shape_list;
static PyObject *__pyx_n_s_speakerFileName;
static PyObject *__pyx_kp_s_speaker_JD3_speaker;
static PyObject *__pyx_n_s_speaker_file_path;
static PyObject *__pyx_n_s_spectrogram;
static PyObject *__pyx_n_s_spectrogram_file_path;
static PyObject *__pyx_n_s_spectrogram_file_path_list;
static PyObject *__pyx_n_s_spectrogram_kwargs;
static PyObject *__pyx_kp_s_spectrogram_pkl_gzip;
static PyObject *__pyx_n_s_split;
static PyObject *__pyx_n_s_sr;
static PyObject *__pyx_n_s_standard;
static PyObject *__pyx_n_s_standard_16kHz_melspectrogram_80;
static PyObject *__pyx_n_s_standard_16kHz_spectrogram_kwarg;
static PyObject *__pyx_n_s_state;
static PyObject *__pyx_n_s_state_samples;
static PyObject *__pyx_n_s_states;
static PyObject *__pyx_n_s_stft;
static PyObject *__pyx_n_s_strip;
static PyObject *__pyx_n_s_sub_glottal_sequence;
static PyObject *__pyx_n_s_sub_glottal_sequence_name;
static PyObject *__pyx_n_s_sub_glottal_shape_names;
static PyObject *__pyx_n_s_sub_glottal_shapes;
static PyObject *__pyx_n_s_supra_glottal_sequence;
static PyObject *__pyx_n_s_supra_glottal_sequence_name;
static PyObject *__pyx_n_s_supra_glottal_shape_names;
static PyObject *__pyx_n_s_supra_glottal_shapes;
static PyObject *__pyx_n_s_svg;
static PyObject *__pyx_n_s_svg_dir;
static PyObject *__pyx_n_s_svg_dir_list;
static PyObject *__pyx_n_s_synth_block;
static PyObject *__pyx_n_s_target_sr;
static PyObject *__pyx_n_s_tasks;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_kp_s_the_specified_gestural_score_fil;
static PyObject *__pyx_kp_s_the_specified_segment_sequence_f;
static PyObject *__pyx_kp_s_the_specified_tract_sequence_fil;
static PyObject *__pyx_n_s_throw;
static PyObject *__pyx_n_s_time;
static PyObject *__pyx_n_s_time_end;
static PyObject *__pyx_n_s_time_start;
static PyObject *__pyx_n_s_time_synth_end;
static PyObject *__pyx_n_s_time_synth_start;
static PyObject *__pyx_n_s_to_motor_sequence;
static PyObject *__pyx_n_s_to_numpy;
static PyObject *__pyx_n_s_to_sub_glottal_sequence;
static PyObject *__pyx_n_s_to_sub_glottal_states;
static PyObject *__pyx_n_s_to_supra_glottal_sequence;
static PyObject *__pyx_n_s_to_supra_glottal_states;
static PyObject *__pyx_n_s_tongueTipSideElevation;
static PyObject *__pyx_n_s_tongue_tip_side_elevation;
static PyObject *__pyx_n_s_total;
static PyObject *__pyx_n_s_tqdm;
static PyObject *__pyx_n_s_tract;
static PyObject *__pyx_n_s_tractParams;
static PyObject *__pyx_n_s_tractSequenceFileName;
static PyObject *__pyx_kp_s_tract_2;
static PyObject *__pyx_kp_s_tract__svg;
static PyObject *__pyx_n_s_tract_file_path;
static PyObject *__pyx_n_s_tract_file_path_list;
static PyObject *__pyx_n_s_tract_param_data;
static PyObject *__pyx_n_s_tract_sequence_list;
static PyObject *__pyx_n_s_tract_sequence_to_audio;
static PyObject *__pyx_n_s_tract_sequence_to_audio_2;
static PyObject *__pyx_n_s_tract_sequence_to_limited_tract;
static PyObject *__pyx_n_s_tract_sequence_to_svg;
static PyObject *__pyx_n_s_tract_sequence_to_svg_2;
static PyObject *__pyx_n_s_tract_sequence_to_transfer_funct;
static PyObject *__pyx_n_s_tract_sequence_to_tube_states;
static PyObject *__pyx_n_s_tract_state;
static PyObject *__pyx_n_s_tract_state_to_limited_tract_st;
static PyObject *__pyx_n_s_tract_state_to_transfer_functio;
static PyObject *__pyx_n_s_tract_state_to_tube_state;
static PyObject *__pyx_n_s_tract_states;
static PyObject *__pyx_n_s_transfer_functions;
static PyObject *__pyx_n_s_tubeArea_cm2;
static PyObject *__pyx_n_s_tubeArticulator;
static PyObject *__pyx_n_s_tubeLength_cm;
static PyObject *__pyx_n_s_tube_area;
static PyObject *__pyx_n_s_tube_articulator;
static PyObject *__pyx_n_s_tube_length;
static PyObject *__pyx_n_s_tube_states;
static PyObject *__pyx_n_s_type;
static PyObject *__pyx_n_s_unit;
static PyObject *__pyx_n_s_units;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_velumOpening_cm2;
static PyObject *__pyx_n_s_velum_opening;
static PyObject *__pyx_n_s_verbose;
static PyObject *__pyx_n_s_version;
static PyObject *__pyx_n_s_voice_quality_new;
static PyObject *__pyx_n_s_voice_quality_old;
static PyObject *__pyx_n_s_w;
static PyObject *__pyx_n_s_warn;
static PyObject *__pyx_n_s_warning;
static PyObject *__pyx_n_s_warnings;
static PyObject *__pyx_kp_s_wav;
static PyObject *__pyx_n_s_wavFileName;
static PyObject *__pyx_n_s_worker;
static PyObject *__pyx_n_s_workers;
static PyObject *__pyx_n_s_write;
static PyObject *__pyx_n_s_x;
static PyObject *__pyx_n_s_y;
static PyObject *__pyx_n_s_zeros;
static PyObject *__pyx_n_s_zip_longest;
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_automatic_calculation_of_TRX_and_TRY(CYTHON_UNUSED PyObject *__pyx_self, bool __pyx_v_automatic_calculation); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_2get_version(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_4get_constants(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_6get_param_info(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_params); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_8get_shape(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape_list, PyObject *__pyx_v_params, PyObject *__pyx_v_return_motor_sequence); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_10get_shapes(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape_list, CYTHON_UNUSED PyObject *__pyx_v_params, PyObject *__pyx_v_return_motor_sequence); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_12get_supra_glottal_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_key); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_14get_sub_glottal_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_key); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_16load_speaker_file(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_18get_gestural_score_audio_duration(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ges_file_path, PyObject *__pyx_v_return_samples); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_20change_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, CYTHON_UNUSED PyObject *__pyx_v_in_ges_file_path_list, CYTHON_UNUSED PyObject *__pyx_v_out_ges_file_path_list, CYTHON_UNUSED PyObject *__pyx_v_modification_kwargs, CYTHON_UNUSED bool __pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_22gestural_score_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ges_file_path_list, PyObject *__pyx_v_audio_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_24gestural_score_to_tract_sequence(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ges_file_path_list, PyObject *__pyx_v_tract_file_path_list, bool __pyx_v_return_data, PyObject *__pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_26segment_sequence_to_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_seg_file_path_list, PyObject *__pyx_v_ges_file_path_list, PyObject *__pyx_v_workers, bool __pyx_v_verbose); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_28tract_sequence_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_audio_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_30motor_sequence_to_spectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_audio_file_path_list, PyObject *__pyx_v_spectrogram_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, PyObject *__pyx_v_spectrogram_kwargs, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_32motor_sequence_to_melspectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_audio_file_path_list, PyObject *__pyx_v_spectrogram_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, PyObject *__pyx_v_log_scale, PyObject *__pyx_v_spectrogram_kwargs, PyObject *__pyx_v_melspectrogram_kwargs, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_34tract_sequence_to_limited_tract_sequence(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence, PyObject *__pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_36tract_sequence_to_svg(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_svg_dir_list, PyObject *__pyx_v_fps, CYTHON_UNUSED PyObject *__pyx_v_save_video, PyObject *__pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_38tract_sequence_to_transfer_functions(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence, PyObject *__pyx_v_n_spectrum_samples, bool __pyx_v_save_magnitude_spectrum, bool __pyx_v_save_phase_spectrum, PyObject *__pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_40tract_sequence_to_tube_states(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence, bool __pyx_v_save_tube_length, bool __pyx_v_save_tube_area, bool __pyx_v_save_tube_articulator, bool __pyx_v_save_incisor_position, bool __pyx_v_save_tongue_tip_side_elevation, bool __pyx_v_save_velum_opening, PyObject *__pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_42_initialize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_44_close(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_46_modify_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_48_gestural_score_change_voice_quality(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_50_gestural_score_change_duration(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_52_gestural_score_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_54_gestural_score_to_tract_sequence(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_56_segment_sequence_to_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_58_synth_block(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_60_tract_sequence_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_62_motor_sequence_to_spectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_64_motor_sequence_to_melspectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_66_tract_state_to_limited_tract_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_68_tract_sequence_to_svg(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_70_tract_state_to_transfer_function(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_72_tract_state_to_tube_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_74_run_multiprocessing(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_function, PyObject *__pyx_v_args, PyObject *__pyx_v_return_data, PyObject *__pyx_v_workers); /* proto */
static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_76_worker(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static __Pyx_CachedCFunction __pyx_umethod_PyString_Type_encode = {0, &__pyx_n_s_encode, 0, 0, 0};
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_2;
static PyObject *__pyx_int_60;
static PyObject *__pyx_int_400;
static PyObject *__pyx_int_8192;
static PyObject *__pyx_int_16000;
static PyObject *__pyx_int_neg_1;
static PyObject *__pyx_k__10;
static PyObject *__pyx_k__11;
static PyObject *__pyx_k__12;
static PyObject *__pyx_tuple_;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__14;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__21;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__25;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__33;
static PyObject *__pyx_tuple__35;
static PyObject *__pyx_tuple__37;
static PyObject *__pyx_tuple__39;
static PyObject *__pyx_tuple__41;
static PyObject *__pyx_tuple__43;
static PyObject *__pyx_tuple__45;
static PyObject *__pyx_tuple__47;
static PyObject *__pyx_tuple__49;
static PyObject *__pyx_tuple__51;
static PyObject *__pyx_tuple__53;
static PyObject *__pyx_tuple__55;
static PyObject *__pyx_tuple__57;
static PyObject *__pyx_tuple__59;
static PyObject *__pyx_tuple__61;
static PyObject *__pyx_tuple__63;
static PyObject *__pyx_tuple__65;
static PyObject *__pyx_tuple__68;
static PyObject *__pyx_tuple__70;
static PyObject *__pyx_tuple__72;
static PyObject *__pyx_tuple__74;
static PyObject *__pyx_tuple__76;
static PyObject *__pyx_tuple__78;
static PyObject *__pyx_tuple__80;
static PyObject *__pyx_tuple__82;
static PyObject *__pyx_tuple__84;
static PyObject *__pyx_tuple__86;
static PyObject *__pyx_tuple__88;
static PyObject *__pyx_tuple__90;
static PyObject *__pyx_tuple__92;
static PyObject *__pyx_codeobj__18;
static PyObject *__pyx_codeobj__20;
static PyObject *__pyx_codeobj__22;
static PyObject *__pyx_codeobj__24;
static PyObject *__pyx_codeobj__26;
static PyObject *__pyx_codeobj__28;
static PyObject *__pyx_codeobj__30;
static PyObject *__pyx_codeobj__32;
static PyObject *__pyx_codeobj__34;
static PyObject *__pyx_codeobj__36;
static PyObject *__pyx_codeobj__38;
static PyObject *__pyx_codeobj__40;
static PyObject *__pyx_codeobj__42;
static PyObject *__pyx_codeobj__44;
static PyObject *__pyx_codeobj__46;
static PyObject *__pyx_codeobj__48;
static PyObject *__pyx_codeobj__50;
static PyObject *__pyx_codeobj__52;
static PyObject *__pyx_codeobj__54;
static PyObject *__pyx_codeobj__56;
static PyObject *__pyx_codeobj__58;
static PyObject *__pyx_codeobj__60;
static PyObject *__pyx_codeobj__62;
static PyObject *__pyx_codeobj__64;
static PyObject *__pyx_codeobj__66;
static PyObject *__pyx_codeobj__67;
static PyObject *__pyx_codeobj__69;
static PyObject *__pyx_codeobj__71;
static PyObject *__pyx_codeobj__73;
static PyObject *__pyx_codeobj__75;
static PyObject *__pyx_codeobj__77;
static PyObject *__pyx_codeobj__79;
static PyObject *__pyx_codeobj__81;
static PyObject *__pyx_codeobj__83;
static PyObject *__pyx_codeobj__85;
static PyObject *__pyx_codeobj__87;
static PyObject *__pyx_codeobj__89;
static PyObject *__pyx_codeobj__91;
static PyObject *__pyx_codeobj__93;
/* Late includes */

/* "VocalTractLab/VocalTractLabApi.pyx":234
 * # 		Single core functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def automatic_calculation_of_TRX_and_TRY( bool automatic_calculation = True ):             # <<<<<<<<<<<<<<
 * 	cdef bool automaticCalculation = automatic_calculation
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_1automatic_calculation_of_TRX_and_TRY(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_1automatic_calculation_of_TRX_and_TRY = {"automatic_calculation_of_TRX_and_TRY", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_1automatic_calculation_of_TRX_and_TRY, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_1automatic_calculation_of_TRX_and_TRY(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  bool __pyx_v_automatic_calculation;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("automatic_calculation_of_TRX_and_TRY (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_automatic_calculation,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_automatic_calculation);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "automatic_calculation_of_TRX_and_TRY") < 0)) __PYX_ERR(0, 234, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_automatic_calculation = __Pyx_PyObject_IsTrue(values[0]); if (unlikely((__pyx_v_automatic_calculation == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 234, __pyx_L3_error)
    } else {
      __pyx_v_automatic_calculation = ((bool)1);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("automatic_calculation_of_TRX_and_TRY", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 234, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.automatic_calculation_of_TRX_and_TRY", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_automatic_calculation_of_TRX_and_TRY(__pyx_self, __pyx_v_automatic_calculation);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_automatic_calculation_of_TRX_and_TRY(CYTHON_UNUSED PyObject *__pyx_self, bool __pyx_v_automatic_calculation) {
  bool __pyx_v_automaticCalculation;
  int __pyx_v_value;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("automatic_calculation_of_TRX_and_TRY", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":235
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def automatic_calculation_of_TRX_and_TRY( bool automatic_calculation = True ):
 * 	cdef bool automaticCalculation = automatic_calculation             # <<<<<<<<<<<<<<
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 * 	#print( value )
 */
  __pyx_v_automaticCalculation = __pyx_v_automatic_calculation;

  /* "VocalTractLab/VocalTractLabApi.pyx":236
 * def automatic_calculation_of_TRX_and_TRY( bool automatic_calculation = True ):
 * 	cdef bool automaticCalculation = automatic_calculation
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )             # <<<<<<<<<<<<<<
 * 	#print( value )
 * 	if value != 0:
 */
  __pyx_v_value = vtlCalcTongueRootAutomatically(__pyx_v_automaticCalculation);

  /* "VocalTractLab/VocalTractLabApi.pyx":238
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 * 	#print( value )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)' )
 * 	warnings.warn( 'Automatic calculation of the Tongue Root parameters was set to {}.'.format(automatic_calculation) )
 */
  __pyx_t_1 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":239
 * 	#print( value )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)' )             # <<<<<<<<<<<<<<
 * 	warnings.warn( 'Automatic calculation of the Tongue Root parameters was set to {}.'.format(automatic_calculation) )
 * 	return
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 239, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":238
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 * 	#print( value )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)' )
 * 	warnings.warn( 'Automatic calculation of the Tongue Root parameters was set to {}.'.format(automatic_calculation) )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":240
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)' )
 * 	warnings.warn( 'Automatic calculation of the Tongue Root parameters was set to {}.'.format(automatic_calculation) )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_warnings); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 240, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_warn); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 240, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Automatic_calculation_of_the_Ton, __pyx_n_s_format); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 240, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_automatic_calculation); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 240, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_3 = (__pyx_t_7) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 240, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_t_3) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 240, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":241
 * 		raise ValueError('VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)' )
 * 	warnings.warn( 'Automatic calculation of the Tongue Root parameters was set to {}.'.format(automatic_calculation) )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_version():
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":234
 * # 		Single core functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def automatic_calculation_of_TRX_and_TRY( bool automatic_calculation = True ):             # <<<<<<<<<<<<<<
 * 	cdef bool automaticCalculation = automatic_calculation
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.automatic_calculation_of_TRX_and_TRY", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":243
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_version():             # <<<<<<<<<<<<<<
 * 	cdef char version[32]
 * 	vtlGetVersion( version )
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_3get_version(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_3get_version = {"get_version", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_3get_version, METH_NOARGS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_3get_version(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_version (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_2get_version(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_2get_version(CYTHON_UNUSED PyObject *__pyx_self) {
  char __pyx_v_version[32];
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_version", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":245
 * def get_version():
 * 	cdef char version[32]
 * 	vtlGetVersion( version )             # <<<<<<<<<<<<<<
 * 	log.info( 'Compile date of the library: {}'.format( version.decode() ) )
 * 	#if self.params.verbose == True:
 */
  vtlGetVersion(__pyx_v_version);

  /* "VocalTractLab/VocalTractLabApi.pyx":246
 * 	cdef char version[32]
 * 	vtlGetVersion( version )
 * 	log.info( 'Compile date of the library: {}'.format( version.decode() ) )             # <<<<<<<<<<<<<<
 * 	#if self.params.verbose == True:
 * 	#	log.info( 'Compile date of the library: "%s"' % version.decode() )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_log); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_info); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Compile_date_of_the_library, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_decode_c_string(__pyx_v_version, 0, strlen(__pyx_v_version), NULL, NULL, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_2 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_6, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":249
 * 	#if self.params.verbose == True:
 * 	#	log.info( 'Compile date of the library: "%s"' % version.decode() )
 * 	return version.decode()             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_constants():
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_decode_c_string(__pyx_v_version, 0, strlen(__pyx_v_version), NULL, NULL, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 249, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":243
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_version():             # <<<<<<<<<<<<<<
 * 	cdef char version[32]
 * 	vtlGetVersion( version )
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_version", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":251
 * 	return version.decode()
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_constants():             # <<<<<<<<<<<<<<
 * 	cdef int audioSamplingRate = -1
 * 	cdef int numTubeSections = -1
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_5get_constants(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_5get_constants = {"get_constants", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_5get_constants, METH_NOARGS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_5get_constants(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_constants (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_4get_constants(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_4get_constants(CYTHON_UNUSED PyObject *__pyx_self) {
  int __pyx_v_audioSamplingRate;
  int __pyx_v_numTubeSections;
  int __pyx_v_numVocalTractParams;
  int __pyx_v_numGlottisParams;
  int __pyx_v_numAudioSamplesPerTractState;
  double __pyx_v_internalSamplingRate;
  int __pyx_v_value;
  PyObject *__pyx_v_constants = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_constants", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":252
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_constants():
 * 	cdef int audioSamplingRate = -1             # <<<<<<<<<<<<<<
 * 	cdef int numTubeSections = -1
 * 	cdef int numVocalTractParams = -1
 */
  __pyx_v_audioSamplingRate = -1;

  /* "VocalTractLab/VocalTractLabApi.pyx":253
 * def get_constants():
 * 	cdef int audioSamplingRate = -1
 * 	cdef int numTubeSections = -1             # <<<<<<<<<<<<<<
 * 	cdef int numVocalTractParams = -1
 * 	cdef int numGlottisParams = -1
 */
  __pyx_v_numTubeSections = -1;

  /* "VocalTractLab/VocalTractLabApi.pyx":254
 * 	cdef int audioSamplingRate = -1
 * 	cdef int numTubeSections = -1
 * 	cdef int numVocalTractParams = -1             # <<<<<<<<<<<<<<
 * 	cdef int numGlottisParams = -1
 * 	cdef int numAudioSamplesPerTractState = -1
 */
  __pyx_v_numVocalTractParams = -1;

  /* "VocalTractLab/VocalTractLabApi.pyx":255
 * 	cdef int numTubeSections = -1
 * 	cdef int numVocalTractParams = -1
 * 	cdef int numGlottisParams = -1             # <<<<<<<<<<<<<<
 * 	cdef int numAudioSamplesPerTractState = -1
 * 	cdef double internalSamplingRate = -1.0
 */
  __pyx_v_numGlottisParams = -1;

  /* "VocalTractLab/VocalTractLabApi.pyx":256
 * 	cdef int numVocalTractParams = -1
 * 	cdef int numGlottisParams = -1
 * 	cdef int numAudioSamplesPerTractState = -1             # <<<<<<<<<<<<<<
 * 	cdef double internalSamplingRate = -1.0
 * 	value = vtlGetConstants( &audioSamplingRate,
 */
  __pyx_v_numAudioSamplesPerTractState = -1;

  /* "VocalTractLab/VocalTractLabApi.pyx":257
 * 	cdef int numGlottisParams = -1
 * 	cdef int numAudioSamplesPerTractState = -1
 * 	cdef double internalSamplingRate = -1.0             # <<<<<<<<<<<<<<
 * 	value = vtlGetConstants( &audioSamplingRate,
 * 		                     &numTubeSections,
 */
  __pyx_v_internalSamplingRate = -1.0;

  /* "VocalTractLab/VocalTractLabApi.pyx":258
 * 	cdef int numAudioSamplesPerTractState = -1
 * 	cdef double internalSamplingRate = -1.0
 * 	value = vtlGetConstants( &audioSamplingRate,             # <<<<<<<<<<<<<<
 * 		                     &numTubeSections,
 * 		                     &numVocalTractParams,
 */
  __pyx_v_value = vtlGetConstants((&__pyx_v_audioSamplingRate), (&__pyx_v_numTubeSections), (&__pyx_v_numVocalTractParams), (&__pyx_v_numGlottisParams), (&__pyx_v_numAudioSamplesPerTractState), (&__pyx_v_internalSamplingRate));

  /* "VocalTractLab/VocalTractLabApi.pyx":265
 * 		                     &internalSamplingRate,
 * 	                         )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGetConstants returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	constants = {
 */
  __pyx_t_1 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":266
 * 	                         )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGetConstants returned the Errorcode: {}  (See API doc for info.)'.format( value ) )             # <<<<<<<<<<<<<<
 * 	constants = {
 * 		'samplerate_audio': int( audioSamplingRate ),
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlGetConstants, __pyx_n_s_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 266, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 266, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_5, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 266, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 266, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 266, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":265
 * 		                     &internalSamplingRate,
 * 	                         )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGetConstants returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	constants = {
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":268
 * 		raise ValueError('VTL API function vtlGetConstants returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	constants = {
 * 		'samplerate_audio': int( audioSamplingRate ),             # <<<<<<<<<<<<<<
 * 		'samplerate_internal': float( internalSamplingRate ),
 * 		'n_tube_sections': int( numTubeSections ),
 */
  __pyx_t_3 = __Pyx_PyDict_NewPresized(6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_audioSamplingRate); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyInt_Type)), __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_samplerate_audio, __pyx_t_4) < 0) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":269
 * 	constants = {
 * 		'samplerate_audio': int( audioSamplingRate ),
 * 		'samplerate_internal': float( internalSamplingRate ),             # <<<<<<<<<<<<<<
 * 		'n_tube_sections': int( numTubeSections ),
 * 		'n_tract_params': int( numVocalTractParams ),
 */
  __pyx_t_4 = PyFloat_FromDouble(__pyx_v_internalSamplingRate); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 269, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_samplerate_internal, __pyx_t_4) < 0) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":270
 * 		'samplerate_audio': int( audioSamplingRate ),
 * 		'samplerate_internal': float( internalSamplingRate ),
 * 		'n_tube_sections': int( numTubeSections ),             # <<<<<<<<<<<<<<
 * 		'n_tract_params': int( numVocalTractParams ),
 * 		'n_glottis_params': int( numGlottisParams ),
 */
  __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_numTubeSections); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyInt_Type)), __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_n_tube_sections, __pyx_t_2) < 0) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":271
 * 		'samplerate_internal': float( internalSamplingRate ),
 * 		'n_tube_sections': int( numTubeSections ),
 * 		'n_tract_params': int( numVocalTractParams ),             # <<<<<<<<<<<<<<
 * 		'n_glottis_params': int( numGlottisParams ),
 * 		'n_samples_per_state': int( numAudioSamplesPerTractState ),
 */
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_numVocalTractParams); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 271, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyInt_Type)), __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 271, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_n_tract_params, __pyx_t_4) < 0) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":272
 * 		'n_tube_sections': int( numTubeSections ),
 * 		'n_tract_params': int( numVocalTractParams ),
 * 		'n_glottis_params': int( numGlottisParams ),             # <<<<<<<<<<<<<<
 * 		'n_samples_per_state': int( numAudioSamplesPerTractState ),
 * 		}
 */
  __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_numGlottisParams); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 272, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyInt_Type)), __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 272, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_n_glottis_params, __pyx_t_2) < 0) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":273
 * 		'n_tract_params': int( numVocalTractParams ),
 * 		'n_glottis_params': int( numGlottisParams ),
 * 		'n_samples_per_state': int( numAudioSamplesPerTractState ),             # <<<<<<<<<<<<<<
 * 		}
 * 	return constants
 */
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_numAudioSamplesPerTractState); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyInt_Type)), __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_n_samples_per_state, __pyx_t_4) < 0) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_constants = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":275
 * 		'n_samples_per_state': int( numAudioSamplesPerTractState ),
 * 		}
 * 	return constants             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_constants);
  __pyx_r = __pyx_v_constants;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":251
 * 	return version.decode()
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_constants():             # <<<<<<<<<<<<<<
 * 	cdef int audioSamplingRate = -1
 * 	cdef int numTubeSections = -1
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_constants", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":277
 * 	return constants
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):             # <<<<<<<<<<<<<<
 * 	if params not in [ 'tract', 'glottis' ]:
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_7get_param_info(PyObject *__pyx_self, PyObject *__pyx_v_params); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_7get_param_info = {"get_param_info", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_7get_param_info, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_7get_param_info(PyObject *__pyx_self, PyObject *__pyx_v_params) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_param_info (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_params), (&PyString_Type), 1, "params", 1))) __PYX_ERR(0, 277, __pyx_L1_error)
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_6get_param_info(__pyx_self, ((PyObject*)__pyx_v_params));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_6get_param_info(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_params) {
  PyObject *__pyx_v_key = NULL;
  PyObject *__pyx_v_constants = NULL;
  PyObject *__pyx_v_names = NULL;
  PyObject *__pyx_v_descriptions = NULL;
  PyObject *__pyx_v_units = NULL;
  PyArrayObject *__pyx_v_paramMin = 0;
  PyArrayObject *__pyx_v_paramMax = 0;
  PyArrayObject *__pyx_v_paramStandard = 0;
  int __pyx_v_value;
  PyObject *__pyx_v_df = NULL;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_paramMax;
  __Pyx_Buffer __pyx_pybuffer_paramMax;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_paramMin;
  __Pyx_Buffer __pyx_pybuffer_paramMin;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_paramStandard;
  __Pyx_Buffer __pyx_pybuffer_paramStandard;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyArrayObject *__pyx_t_9 = NULL;
  PyArrayObject *__pyx_t_10 = NULL;
  PyArrayObject *__pyx_t_11 = NULL;
  char *__pyx_t_12;
  char *__pyx_t_13;
  char *__pyx_t_14;
  Py_ssize_t __pyx_t_15;
  int __pyx_t_16;
  Py_ssize_t __pyx_t_17;
  Py_ssize_t __pyx_t_18;
  PyObject *__pyx_t_19 = NULL;
  PyObject *__pyx_t_20 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_param_info", 0);
  __Pyx_INCREF(__pyx_v_params);
  __pyx_pybuffer_paramMin.pybuffer.buf = NULL;
  __pyx_pybuffer_paramMin.refcount = 0;
  __pyx_pybuffernd_paramMin.data = NULL;
  __pyx_pybuffernd_paramMin.rcbuffer = &__pyx_pybuffer_paramMin;
  __pyx_pybuffer_paramMax.pybuffer.buf = NULL;
  __pyx_pybuffer_paramMax.refcount = 0;
  __pyx_pybuffernd_paramMax.data = NULL;
  __pyx_pybuffernd_paramMax.rcbuffer = &__pyx_pybuffer_paramMax;
  __pyx_pybuffer_paramStandard.pybuffer.buf = NULL;
  __pyx_pybuffer_paramStandard.refcount = 0;
  __pyx_pybuffernd_paramStandard.data = NULL;
  __pyx_pybuffernd_paramStandard.rcbuffer = &__pyx_pybuffer_paramStandard;

  /* "VocalTractLab/VocalTractLabApi.pyx":278
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):
 * 	if params not in [ 'tract', 'glottis' ]:             # <<<<<<<<<<<<<<
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 * 		params = 'tract'
 */
  __Pyx_INCREF(__pyx_v_params);
  __pyx_t_1 = __pyx_v_params;
  __pyx_t_3 = (__Pyx_PyString_Equals(__pyx_t_1, __pyx_n_s_tract, Py_NE)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 278, __pyx_L1_error)
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {
  } else {
    __pyx_t_2 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_t_1, __pyx_n_s_glottis, Py_NE)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 278, __pyx_L1_error)
  __pyx_t_3 = (__pyx_t_4 != 0);
  __pyx_t_2 = __pyx_t_3;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":279
 * def get_param_info( str params ):
 * 	if params not in [ 'tract', 'glottis' ]:
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )             # <<<<<<<<<<<<<<
 * 		params = 'tract'
 * 	if params == 'tract':
 */
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_log); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 279, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_warning); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 279, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_7, __pyx_t_6, __pyx_kp_s_Unknown_key_in_get_param_info_Ke) : __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_kp_s_Unknown_key_in_get_param_info_Ke);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 279, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":280
 * 	if params not in [ 'tract', 'glottis' ]:
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 * 		params = 'tract'             # <<<<<<<<<<<<<<
 * 	if params == 'tract':
 * 		key = 'n_tract_params'
 */
    __Pyx_INCREF(__pyx_n_s_tract);
    __Pyx_DECREF_SET(__pyx_v_params, __pyx_n_s_tract);

    /* "VocalTractLab/VocalTractLabApi.pyx":278
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):
 * 	if params not in [ 'tract', 'glottis' ]:             # <<<<<<<<<<<<<<
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 * 		params = 'tract'
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":281
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 * 		params = 'tract'
 * 	if params == 'tract':             # <<<<<<<<<<<<<<
 * 		key = 'n_tract_params'
 * 	elif params == 'glottis':
 */
  __pyx_t_3 = (__Pyx_PyString_Equals(__pyx_v_params, __pyx_n_s_tract, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 281, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_3 != 0);
  if (__pyx_t_2) {

    /* "VocalTractLab/VocalTractLabApi.pyx":282
 * 		params = 'tract'
 * 	if params == 'tract':
 * 		key = 'n_tract_params'             # <<<<<<<<<<<<<<
 * 	elif params == 'glottis':
 * 		key = 'n_glottis_params'
 */
    __Pyx_INCREF(__pyx_n_s_n_tract_params);
    __pyx_v_key = __pyx_n_s_n_tract_params;

    /* "VocalTractLab/VocalTractLabApi.pyx":281
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 * 		params = 'tract'
 * 	if params == 'tract':             # <<<<<<<<<<<<<<
 * 		key = 'n_tract_params'
 * 	elif params == 'glottis':
 */
    goto __pyx_L6;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":283
 * 	if params == 'tract':
 * 		key = 'n_tract_params'
 * 	elif params == 'glottis':             # <<<<<<<<<<<<<<
 * 		key = 'n_glottis_params'
 * 	constants = get_constants()
 */
  __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_params, __pyx_n_s_glottis, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 283, __pyx_L1_error)
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":284
 * 		key = 'n_tract_params'
 * 	elif params == 'glottis':
 * 		key = 'n_glottis_params'             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	names = ( ' ' * 10 * constants[ key ] ).encode()
 */
    __Pyx_INCREF(__pyx_n_s_n_glottis_params);
    __pyx_v_key = __pyx_n_s_n_glottis_params;

    /* "VocalTractLab/VocalTractLabApi.pyx":283
 * 	if params == 'tract':
 * 		key = 'n_tract_params'
 * 	elif params == 'glottis':             # <<<<<<<<<<<<<<
 * 		key = 'n_glottis_params'
 * 	constants = get_constants()
 */
  }
  __pyx_L6:;

  /* "VocalTractLab/VocalTractLabApi.pyx":285
 * 	elif params == 'glottis':
 * 		key = 'n_glottis_params'
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	names = ( ' ' * 10 * constants[ key ] ).encode()
 * 	descriptions = (' ' * 100 * constants[key]).encode()
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_constants = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":286
 * 		key = 'n_glottis_params'
 * 	constants = get_constants()
 * 	names = ( ' ' * 10 * constants[ key ] ).encode()             # <<<<<<<<<<<<<<
 * 	descriptions = (' ' * 100 * constants[key]).encode()
 * 	units = (' ' * 10 * constants[key]).encode()
 */
  if (unlikely(!__pyx_v_key)) { __Pyx_RaiseUnboundLocalError("key"); __PYX_ERR(0, 286, __pyx_L1_error) }
  __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_v_constants, __pyx_v_key); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = PyNumber_Multiply(__pyx_kp_s__2, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_encode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_names = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":287
 * 	constants = get_constants()
 * 	names = ( ' ' * 10 * constants[ key ] ).encode()
 * 	descriptions = (' ' * 100 * constants[key]).encode()             # <<<<<<<<<<<<<<
 * 	units = (' ' * 10 * constants[key]).encode()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMin = np.empty( constants[key], dtype='float64' )
 */
  if (unlikely(!__pyx_v_key)) { __Pyx_RaiseUnboundLocalError("key"); __PYX_ERR(0, 287, __pyx_L1_error) }
  __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_v_constants, __pyx_v_key); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = PyNumber_Multiply(__pyx_kp_s__3, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_encode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_descriptions = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":288
 * 	names = ( ' ' * 10 * constants[ key ] ).encode()
 * 	descriptions = (' ' * 100 * constants[key]).encode()
 * 	units = (' ' * 10 * constants[key]).encode()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMin = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMax = np.empty( constants[key], dtype='float64' )
 */
  if (unlikely(!__pyx_v_key)) { __Pyx_RaiseUnboundLocalError("key"); __PYX_ERR(0, 288, __pyx_L1_error) }
  __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_v_constants, __pyx_v_key); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = PyNumber_Multiply(__pyx_kp_s__2, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_encode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_units = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":289
 * 	descriptions = (' ' * 100 * constants[key]).encode()
 * 	units = (' ' * 10 * constants[key]).encode()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMin = np.empty( constants[key], dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMax = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramStandard = np.empty( constants[key], dtype='float64' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_empty); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_v_key)) { __Pyx_RaiseUnboundLocalError("key"); __PYX_ERR(0, 289, __pyx_L1_error) }
  __pyx_t_5 = __Pyx_PyObject_GetItem(__pyx_v_constants, __pyx_v_key); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5);
  __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 289, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_6, __pyx_t_5); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 289, __pyx_L1_error)
  __pyx_t_9 = ((PyArrayObject *)__pyx_t_8);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_paramMin.rcbuffer->pybuffer, (PyObject*)__pyx_t_9, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_paramMin = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_paramMin.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 289, __pyx_L1_error)
    } else {__pyx_pybuffernd_paramMin.diminfo[0].strides = __pyx_pybuffernd_paramMin.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_paramMin.diminfo[0].shape = __pyx_pybuffernd_paramMin.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_9 = 0;
  __pyx_v_paramMin = ((PyArrayObject *)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":290
 * 	units = (' ' * 10 * constants[key]).encode()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMin = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMax = np.empty( constants[key], dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramStandard = np.empty( constants[key], dtype='float64' )
 * 	if params == 'tract':
 */
  __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_np); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_empty); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_v_key)) { __Pyx_RaiseUnboundLocalError("key"); __PYX_ERR(0, 290, __pyx_L1_error) }
  __pyx_t_8 = __Pyx_PyObject_GetItem(__pyx_v_constants, __pyx_v_key); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_8);
  PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8);
  __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 290, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, __pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (!(likely(((__pyx_t_7) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_7, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 290, __pyx_L1_error)
  __pyx_t_10 = ((PyArrayObject *)__pyx_t_7);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_paramMax.rcbuffer->pybuffer, (PyObject*)__pyx_t_10, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_paramMax = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_paramMax.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 290, __pyx_L1_error)
    } else {__pyx_pybuffernd_paramMax.diminfo[0].strides = __pyx_pybuffernd_paramMax.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_paramMax.diminfo[0].shape = __pyx_pybuffernd_paramMax.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_10 = 0;
  __pyx_v_paramMax = ((PyArrayObject *)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":291
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMin = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMax = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramStandard = np.empty( constants[key], dtype='float64' )             # <<<<<<<<<<<<<<
 * 	if params == 'tract':
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_np); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_empty); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(!__pyx_v_key)) { __Pyx_RaiseUnboundLocalError("key"); __PYX_ERR(0, 291, __pyx_L1_error) }
  __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_v_constants, __pyx_v_key); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7);
  __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 291, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!(likely(((__pyx_t_5) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_5, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 291, __pyx_L1_error)
  __pyx_t_11 = ((PyArrayObject *)__pyx_t_5);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_paramStandard.rcbuffer->pybuffer, (PyObject*)__pyx_t_11, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_paramStandard = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_paramStandard.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 291, __pyx_L1_error)
    } else {__pyx_pybuffernd_paramStandard.diminfo[0].strides = __pyx_pybuffernd_paramStandard.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_paramStandard.diminfo[0].shape = __pyx_pybuffernd_paramStandard.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_11 = 0;
  __pyx_v_paramStandard = ((PyArrayObject *)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":292
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMax = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramStandard = np.empty( constants[key], dtype='float64' )
 * 	if params == 'tract':             # <<<<<<<<<<<<<<
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	elif params == 'glottis':
 */
  __pyx_t_3 = (__Pyx_PyString_Equals(__pyx_v_params, __pyx_n_s_tract, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 292, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_3 != 0);
  if (__pyx_t_2) {

    /* "VocalTractLab/VocalTractLabApi.pyx":293
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramStandard = np.empty( constants[key], dtype='float64' )
 * 	if params == 'tract':
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )             # <<<<<<<<<<<<<<
 * 	elif params == 'glottis':
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 */
    __pyx_t_12 = __Pyx_PyObject_AsWritableString(__pyx_v_names); if (unlikely((!__pyx_t_12) && PyErr_Occurred())) __PYX_ERR(0, 293, __pyx_L1_error)
    __pyx_t_13 = __Pyx_PyObject_AsWritableString(__pyx_v_descriptions); if (unlikely((!__pyx_t_13) && PyErr_Occurred())) __PYX_ERR(0, 293, __pyx_L1_error)
    __pyx_t_14 = __Pyx_PyObject_AsWritableString(__pyx_v_units); if (unlikely((!__pyx_t_14) && PyErr_Occurred())) __PYX_ERR(0, 293, __pyx_L1_error)
    __pyx_t_15 = 0;
    __pyx_t_16 = -1;
    if (__pyx_t_15 < 0) {
      __pyx_t_15 += __pyx_pybuffernd_paramMin.diminfo[0].shape;
      if (unlikely(__pyx_t_15 < 0)) __pyx_t_16 = 0;
    } else if (unlikely(__pyx_t_15 >= __pyx_pybuffernd_paramMin.diminfo[0].shape)) __pyx_t_16 = 0;
    if (unlikely(__pyx_t_16 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_16);
      __PYX_ERR(0, 293, __pyx_L1_error)
    }
    __pyx_t_17 = 0;
    __pyx_t_16 = -1;
    if (__pyx_t_17 < 0) {
      __pyx_t_17 += __pyx_pybuffernd_paramMax.diminfo[0].shape;
      if (unlikely(__pyx_t_17 < 0)) __pyx_t_16 = 0;
    } else if (unlikely(__pyx_t_17 >= __pyx_pybuffernd_paramMax.diminfo[0].shape)) __pyx_t_16 = 0;
    if (unlikely(__pyx_t_16 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_16);
      __PYX_ERR(0, 293, __pyx_L1_error)
    }
    __pyx_t_18 = 0;
    __pyx_t_16 = -1;
    if (__pyx_t_18 < 0) {
      __pyx_t_18 += __pyx_pybuffernd_paramStandard.diminfo[0].shape;
      if (unlikely(__pyx_t_18 < 0)) __pyx_t_16 = 0;
    } else if (unlikely(__pyx_t_18 >= __pyx_pybuffernd_paramStandard.diminfo[0].shape)) __pyx_t_16 = 0;
    if (unlikely(__pyx_t_16 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_16);
      __PYX_ERR(0, 293, __pyx_L1_error)
    }
    __pyx_v_value = vtlGetTractParamInfo(__pyx_t_12, __pyx_t_13, __pyx_t_14, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_paramMin.rcbuffer->pybuffer.buf, __pyx_t_15, __pyx_pybuffernd_paramMin.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_paramMax.rcbuffer->pybuffer.buf, __pyx_t_17, __pyx_pybuffernd_paramMax.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_paramStandard.rcbuffer->pybuffer.buf, __pyx_t_18, __pyx_pybuffernd_paramStandard.diminfo[0].strides))));

    /* "VocalTractLab/VocalTractLabApi.pyx":292
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramMax = np.empty( constants[key], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] paramStandard = np.empty( constants[key], dtype='float64' )
 * 	if params == 'tract':             # <<<<<<<<<<<<<<
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	elif params == 'glottis':
 */
    goto __pyx_L7;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":294
 * 	if params == 'tract':
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	elif params == 'glottis':             # <<<<<<<<<<<<<<
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	if value != 0:
 */
  __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_params, __pyx_n_s_glottis, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 294, __pyx_L1_error)
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":295
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	elif params == 'glottis':
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )             # <<<<<<<<<<<<<<
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 */
    __pyx_t_14 = __Pyx_PyObject_AsWritableString(__pyx_v_names); if (unlikely((!__pyx_t_14) && PyErr_Occurred())) __PYX_ERR(0, 295, __pyx_L1_error)
    __pyx_t_13 = __Pyx_PyObject_AsWritableString(__pyx_v_descriptions); if (unlikely((!__pyx_t_13) && PyErr_Occurred())) __PYX_ERR(0, 295, __pyx_L1_error)
    __pyx_t_12 = __Pyx_PyObject_AsWritableString(__pyx_v_units); if (unlikely((!__pyx_t_12) && PyErr_Occurred())) __PYX_ERR(0, 295, __pyx_L1_error)
    __pyx_t_18 = 0;
    __pyx_t_16 = -1;
    if (__pyx_t_18 < 0) {
      __pyx_t_18 += __pyx_pybuffernd_paramMin.diminfo[0].shape;
      if (unlikely(__pyx_t_18 < 0)) __pyx_t_16 = 0;
    } else if (unlikely(__pyx_t_18 >= __pyx_pybuffernd_paramMin.diminfo[0].shape)) __pyx_t_16 = 0;
    if (unlikely(__pyx_t_16 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_16);
      __PYX_ERR(0, 295, __pyx_L1_error)
    }
    __pyx_t_17 = 0;
    __pyx_t_16 = -1;
    if (__pyx_t_17 < 0) {
      __pyx_t_17 += __pyx_pybuffernd_paramMax.diminfo[0].shape;
      if (unlikely(__pyx_t_17 < 0)) __pyx_t_16 = 0;
    } else if (unlikely(__pyx_t_17 >= __pyx_pybuffernd_paramMax.diminfo[0].shape)) __pyx_t_16 = 0;
    if (unlikely(__pyx_t_16 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_16);
      __PYX_ERR(0, 295, __pyx_L1_error)
    }
    __pyx_t_15 = 0;
    __pyx_t_16 = -1;
    if (__pyx_t_15 < 0) {
      __pyx_t_15 += __pyx_pybuffernd_paramStandard.diminfo[0].shape;
      if (unlikely(__pyx_t_15 < 0)) __pyx_t_16 = 0;
    } else if (unlikely(__pyx_t_15 >= __pyx_pybuffernd_paramStandard.diminfo[0].shape)) __pyx_t_16 = 0;
    if (unlikely(__pyx_t_16 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_16);
      __PYX_ERR(0, 295, __pyx_L1_error)
    }
    __pyx_v_value = vtlGetGlottisParamInfo(__pyx_t_14, __pyx_t_13, __pyx_t_12, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_paramMin.rcbuffer->pybuffer.buf, __pyx_t_18, __pyx_pybuffernd_paramMin.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_paramMax.rcbuffer->pybuffer.buf, __pyx_t_17, __pyx_pybuffernd_paramMax.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_paramStandard.rcbuffer->pybuffer.buf, __pyx_t_15, __pyx_pybuffernd_paramStandard.diminfo[0].strides))));

    /* "VocalTractLab/VocalTractLabApi.pyx":294
 * 	if params == 'tract':
 * 		value = vtlGetTractParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	elif params == 'glottis':             # <<<<<<<<<<<<<<
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	if value != 0:
 */
  }
  __pyx_L7:;

  /* "VocalTractLab/VocalTractLabApi.pyx":296
 * 	elif params == 'glottis':
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')
 */
  __pyx_t_3 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_3)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":297
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )             # <<<<<<<<<<<<<<
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')
 * 	units = units.decode().replace('\x00', '').strip(' ').strip( '' ).split('\t')
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlGetTractPara, __pyx_n_s_format); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    __pyx_t_5 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_7, __pyx_t_8, __pyx_t_6) : __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6);
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(0, 297, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":296
 * 	elif params == 'glottis':
 * 		value = vtlGetGlottisParamInfo( names, descriptions, units, &paramMin[0], &paramMax[0], &paramStandard[0] )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":298
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')             # <<<<<<<<<<<<<<
 * 	units = units.decode().replace('\x00', '').strip(' ').strip( '' ).split('\t')
 * 	df = pd.DataFrame( np.array( [ descriptions, units, paramMin, paramMax, paramStandard ] ).T, columns = [ 'description', 'unit', 'min', 'max', 'standard' ] )
 */
  __pyx_t_19 = __Pyx_PyObject_GetAttrStr(__pyx_v_descriptions, __pyx_n_s_decode); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __pyx_t_20 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_19))) {
    __pyx_t_20 = PyMethod_GET_SELF(__pyx_t_19);
    if (likely(__pyx_t_20)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_19);
      __Pyx_INCREF(__pyx_t_20);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_19, function);
    }
  }
  __pyx_t_8 = (__pyx_t_20) ? __Pyx_PyObject_CallOneArg(__pyx_t_19, __pyx_t_20) : __Pyx_PyObject_CallNoArg(__pyx_t_19);
  __Pyx_XDECREF(__pyx_t_20); __pyx_t_20 = 0;
  if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_replace); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_19, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_strip); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_19))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_19);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_19);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_19, function);
    }
  }
  __pyx_t_6 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_19, __pyx_t_8, __pyx_kp_s__7) : __Pyx_PyObject_CallOneArg(__pyx_t_19, __pyx_kp_s__7);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_strip); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_19))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_19);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_19);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_19, function);
    }
  }
  __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_19, __pyx_t_6, __pyx_kp_s__5) : __Pyx_PyObject_CallOneArg(__pyx_t_19, __pyx_kp_s__5);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_split); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_19))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_19);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_19);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_19, function);
    }
  }
  __pyx_t_7 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_19, __pyx_t_5, __pyx_kp_s__8) : __Pyx_PyObject_CallOneArg(__pyx_t_19, __pyx_kp_s__8);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __Pyx_DECREF_SET(__pyx_v_descriptions, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":299
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')
 * 	units = units.decode().replace('\x00', '').strip(' ').strip( '' ).split('\t')             # <<<<<<<<<<<<<<
 * 	df = pd.DataFrame( np.array( [ descriptions, units, paramMin, paramMax, paramStandard ] ).T, columns = [ 'description', 'unit', 'min', 'max', 'standard' ] )
 * 	df.index = names.decode().replace('\x00','').strip( ' ' ).strip('').split( '\t' )
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_units, __pyx_n_s_decode); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_20 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_20 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_20)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_20);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_6 = (__pyx_t_20) ? __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_20) : __Pyx_PyObject_CallNoArg(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_20); __pyx_t_20 = 0;
  if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_replace); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_strip); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_5 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_6, __pyx_kp_s__7) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_kp_s__7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_strip); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_19 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_5, __pyx_kp_s__5) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_kp_s__5);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_19, __pyx_n_s_split); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_19 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_19)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_19);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_7 = (__pyx_t_19) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_19, __pyx_kp_s__8) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_kp_s__8);
  __Pyx_XDECREF(__pyx_t_19); __pyx_t_19 = 0;
  if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF_SET(__pyx_v_units, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":300
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')
 * 	units = units.decode().replace('\x00', '').strip(' ').strip( '' ).split('\t')
 * 	df = pd.DataFrame( np.array( [ descriptions, units, paramMin, paramMax, paramStandard ] ).T, columns = [ 'description', 'unit', 'min', 'max', 'standard' ] )             # <<<<<<<<<<<<<<
 * 	df.index = names.decode().replace('\x00','').strip( ' ' ).strip('').split( '\t' )
 * 	return df
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_pd); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_DataFrame); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_19, __pyx_n_s_np); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_19, __pyx_n_s_array); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = PyList_New(5); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_INCREF(__pyx_v_descriptions);
  __Pyx_GIVEREF(__pyx_v_descriptions);
  PyList_SET_ITEM(__pyx_t_19, 0, __pyx_v_descriptions);
  __Pyx_INCREF(__pyx_v_units);
  __Pyx_GIVEREF(__pyx_v_units);
  PyList_SET_ITEM(__pyx_t_19, 1, __pyx_v_units);
  __Pyx_INCREF(((PyObject *)__pyx_v_paramMin));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_paramMin));
  PyList_SET_ITEM(__pyx_t_19, 2, ((PyObject *)__pyx_v_paramMin));
  __Pyx_INCREF(((PyObject *)__pyx_v_paramMax));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_paramMax));
  PyList_SET_ITEM(__pyx_t_19, 3, ((PyObject *)__pyx_v_paramMax));
  __Pyx_INCREF(((PyObject *)__pyx_v_paramStandard));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_paramStandard));
  PyList_SET_ITEM(__pyx_t_19, 4, ((PyObject *)__pyx_v_paramStandard));
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_7 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, __pyx_t_19) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_19);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_T); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5);
  __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_19 = PyList_New(5); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_INCREF(__pyx_n_s_description);
  __Pyx_GIVEREF(__pyx_n_s_description);
  PyList_SET_ITEM(__pyx_t_19, 0, __pyx_n_s_description);
  __Pyx_INCREF(__pyx_n_s_unit);
  __Pyx_GIVEREF(__pyx_n_s_unit);
  PyList_SET_ITEM(__pyx_t_19, 1, __pyx_n_s_unit);
  __Pyx_INCREF(__pyx_n_s_min);
  __Pyx_GIVEREF(__pyx_n_s_min);
  PyList_SET_ITEM(__pyx_t_19, 2, __pyx_n_s_min);
  __Pyx_INCREF(__pyx_n_s_max);
  __Pyx_GIVEREF(__pyx_n_s_max);
  PyList_SET_ITEM(__pyx_t_19, 3, __pyx_n_s_max);
  __Pyx_INCREF(__pyx_n_s_standard);
  __Pyx_GIVEREF(__pyx_n_s_standard);
  PyList_SET_ITEM(__pyx_t_19, 4, __pyx_n_s_standard);
  if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_columns, __pyx_t_19) < 0) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;
  __pyx_t_19 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_7, __pyx_t_5); if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_df = __pyx_t_19;
  __pyx_t_19 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":301
 * 	units = units.decode().replace('\x00', '').strip(' ').strip( '' ).split('\t')
 * 	df = pd.DataFrame( np.array( [ descriptions, units, paramMin, paramMax, paramStandard ] ).T, columns = [ 'description', 'unit', 'min', 'max', 'standard' ] )
 * 	df.index = names.decode().replace('\x00','').strip( ' ' ).strip('').split( '\t' )             # <<<<<<<<<<<<<<
 * 	return df
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_names, __pyx_n_s_decode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_20 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_20 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_20)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_20);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_8 = (__pyx_t_20) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_20) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_20); __pyx_t_20 = 0;
  if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_replace); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_strip); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_7 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_8, __pyx_kp_s__7) : __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_kp_s__7);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_strip); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_5 = (__pyx_t_7) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_7, __pyx_kp_s__5) : __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_kp_s__5);
  __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_split); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_19 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_5, __pyx_kp_s__8) : __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_kp_s__8);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_19)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_19);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_df, __pyx_n_s_index, __pyx_t_19) < 0) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_19); __pyx_t_19 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":302
 * 	df = pd.DataFrame( np.array( [ descriptions, units, paramMin, paramMax, paramStandard ] ).T, columns = [ 'description', 'unit', 'min', 'max', 'standard' ] )
 * 	df.index = names.decode().replace('\x00','').strip( ' ' ).strip('').split( '\t' )
 * 	return df             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shape( shape_list, str params = None, return_motor_sequence = True ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_df);
  __pyx_r = __pyx_v_df;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":277
 * 	return constants
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):             # <<<<<<<<<<<<<<
 * 	if params not in [ 'tract', 'glottis' ]:
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_19);
  __Pyx_XDECREF(__pyx_t_20);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_paramMax.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_paramMin.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_paramStandard.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_param_info", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_paramMax.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_paramMin.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_paramStandard.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_key);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF(__pyx_v_names);
  __Pyx_XDECREF(__pyx_v_descriptions);
  __Pyx_XDECREF(__pyx_v_units);
  __Pyx_XDECREF((PyObject *)__pyx_v_paramMin);
  __Pyx_XDECREF((PyObject *)__pyx_v_paramMax);
  __Pyx_XDECREF((PyObject *)__pyx_v_paramStandard);
  __Pyx_XDECREF(__pyx_v_df);
  __Pyx_XDECREF(__pyx_v_params);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":304
 * 	return df
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shape( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_9get_shape(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_9get_shape = {"get_shape", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_9get_shape, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_9get_shape(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape_list = 0;
  PyObject *__pyx_v_params = 0;
  PyObject *__pyx_v_return_motor_sequence = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_shape (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shape_list,&__pyx_n_s_params,&__pyx_n_s_return_motor_sequence,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject*)Py_None);
    values[2] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_shape_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_params);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_motor_sequence);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get_shape") < 0)) __PYX_ERR(0, 304, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_shape_list = values[0];
    __pyx_v_params = ((PyObject*)values[1]);
    __pyx_v_return_motor_sequence = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get_shape", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 304, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_params), (&PyString_Type), 1, "params", 1))) __PYX_ERR(0, 304, __pyx_L1_error)
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_8get_shape(__pyx_self, __pyx_v_shape_list, __pyx_v_params, __pyx_v_return_motor_sequence);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_8get_shape(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape_list, PyObject *__pyx_v_params, PyObject *__pyx_v_return_motor_sequence) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_shape", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":305
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shape( shape_list, str params = None, return_motor_sequence = True ):
 * 	return get_shapes( shape_list,  params, return_motor_sequence )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_get_shapes); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 305, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_shape_list, __pyx_v_params, __pyx_v_return_motor_sequence};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 305, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_shape_list, __pyx_v_params, __pyx_v_return_motor_sequence};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 305, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_shape_list);
    __Pyx_GIVEREF(__pyx_v_shape_list);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_shape_list);
    __Pyx_INCREF(__pyx_v_params);
    __Pyx_GIVEREF(__pyx_v_params);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_params);
    __Pyx_INCREF(__pyx_v_return_motor_sequence);
    __Pyx_GIVEREF(__pyx_v_return_motor_sequence);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_return_motor_sequence);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":304
 * 	return df
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shape( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":307
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )
 * 	constants = get_constants()
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_11get_shapes(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_11get_shapes = {"get_shapes", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_11get_shapes, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_11get_shapes(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape_list = 0;
  CYTHON_UNUSED PyObject *__pyx_v_params = 0;
  PyObject *__pyx_v_return_motor_sequence = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_shapes (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shape_list,&__pyx_n_s_params,&__pyx_n_s_return_motor_sequence,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject*)Py_None);
    values[2] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_shape_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_params);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_motor_sequence);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get_shapes") < 0)) __PYX_ERR(0, 307, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_shape_list = values[0];
    __pyx_v_params = ((PyObject*)values[1]);
    __pyx_v_return_motor_sequence = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get_shapes", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 307, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_shapes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_params), (&PyString_Type), 1, "params", 1))) __PYX_ERR(0, 307, __pyx_L1_error)
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_10get_shapes(__pyx_self, __pyx_v_shape_list, __pyx_v_params, __pyx_v_return_motor_sequence);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_10get_shapes(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape_list, CYTHON_UNUSED PyObject *__pyx_v_params, PyObject *__pyx_v_return_motor_sequence) {
  PyObject *__pyx_v_constants = NULL;
  PyArrayObject *__pyx_v_tractParams = 0;
  PyArrayObject *__pyx_v_glottisParams = 0;
  PyObject *__pyx_v_supra_glottal_shapes = NULL;
  PyObject *__pyx_v_sub_glottal_shapes = NULL;
  PyObject *__pyx_v_supra_glottal_shape_names = NULL;
  PyObject *__pyx_v_sub_glottal_shape_names = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_shapeName = NULL;
  int __pyx_v_value;
  PyObject *__pyx_v_supra_glottal_sequence_name = NULL;
  PyObject *__pyx_v_sub_glottal_sequence_name = NULL;
  PyObject *__pyx_v_supra_glottal_sequence = NULL;
  PyObject *__pyx_v_sub_glottal_sequence = NULL;
  PyObject *__pyx_v_motor_sequence_name = NULL;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_glottisParams;
  __Pyx_Buffer __pyx_pybuffer_glottisParams;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tractParams;
  __Pyx_Buffer __pyx_pybuffer_tractParams;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyArrayObject *__pyx_t_6 = NULL;
  PyArrayObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  char const *__pyx_t_10;
  Py_ssize_t __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  char const *__pyx_t_16;
  int __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_shapes", 0);
  __Pyx_INCREF(__pyx_v_shape_list);
  __pyx_pybuffer_tractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_tractParams.refcount = 0;
  __pyx_pybuffernd_tractParams.data = NULL;
  __pyx_pybuffernd_tractParams.rcbuffer = &__pyx_pybuffer_tractParams;
  __pyx_pybuffer_glottisParams.pybuffer.buf = NULL;
  __pyx_pybuffer_glottisParams.refcount = 0;
  __pyx_pybuffernd_glottisParams.data = NULL;
  __pyx_pybuffernd_glottisParams.rcbuffer = &__pyx_pybuffer_glottisParams;

  /* "VocalTractLab/VocalTractLabApi.pyx":308
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = np.empty( shape = constants[ 'n_tract_params' ],  dtype='float64' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_list_is_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_shape_list, ((PyObject *)(&PyString_Type))};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 308, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_shape_list, ((PyObject *)(&PyString_Type))};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 308, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 308, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_shape_list);
    __Pyx_GIVEREF(__pyx_v_shape_list);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_shape_list);
    __Pyx_INCREF(((PyObject *)(&PyString_Type)));
    __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, ((PyObject *)(&PyString_Type)));
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 308, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_shape_list, __pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":309
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = np.empty( shape = constants[ 'n_tract_params' ],  dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = np.empty( shape = constants[ 'n_glottis_params' ],  dtype='float64' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_1 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_constants = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":310
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = np.empty( shape = constants[ 'n_tract_params' ],  dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = np.empty( shape = constants[ 'n_glottis_params' ],  dtype='float64' )
 * 	supra_glottal_shapes, sub_glottal_shapes = [], []
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_empty); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_tract_params); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_t_5) < 0) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 310, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!(likely(((__pyx_t_5) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_5, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 310, __pyx_L1_error)
  __pyx_t_6 = ((PyArrayObject *)__pyx_t_5);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_6, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 310, __pyx_L1_error)
    } else {__pyx_pybuffernd_tractParams.diminfo[0].strides = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tractParams.diminfo[0].shape = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_6 = 0;
  __pyx_v_tractParams = ((PyArrayObject *)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":311
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = np.empty( shape = constants[ 'n_tract_params' ],  dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = np.empty( shape = constants[ 'n_glottis_params' ],  dtype='float64' )             # <<<<<<<<<<<<<<
 * 	supra_glottal_shapes, sub_glottal_shapes = [], []
 * 	supra_glottal_shape_names, sub_glottal_shape_names = [], []
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_empty); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_glottis_params); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_shape, __pyx_t_3) < 0) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 311, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 311, __pyx_L1_error)
  __pyx_t_7 = ((PyArrayObject *)__pyx_t_3);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_glottisParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_7, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_glottisParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 311, __pyx_L1_error)
    } else {__pyx_pybuffernd_glottisParams.diminfo[0].strides = __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_glottisParams.diminfo[0].shape = __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_7 = 0;
  __pyx_v_glottisParams = ((PyArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":312
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = np.empty( shape = constants[ 'n_tract_params' ],  dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = np.empty( shape = constants[ 'n_glottis_params' ],  dtype='float64' )
 * 	supra_glottal_shapes, sub_glottal_shapes = [], []             # <<<<<<<<<<<<<<
 * 	supra_glottal_shape_names, sub_glottal_shape_names = [], []
 * 	for shape in shape_list:
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = PyList_New(0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_v_supra_glottal_shapes = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_v_sub_glottal_shapes = ((PyObject*)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":313
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = np.empty( shape = constants[ 'n_glottis_params' ],  dtype='float64' )
 * 	supra_glottal_shapes, sub_glottal_shapes = [], []
 * 	supra_glottal_shape_names, sub_glottal_shape_names = [], []             # <<<<<<<<<<<<<<
 * 	for shape in shape_list:
 * 		#print(shape)
 */
  __pyx_t_5 = PyList_New(0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_supra_glottal_shape_names = ((PyObject*)__pyx_t_5);
  __pyx_t_5 = 0;
  __pyx_v_sub_glottal_shape_names = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":314
 * 	supra_glottal_shapes, sub_glottal_shapes = [], []
 * 	supra_glottal_shape_names, sub_glottal_shape_names = [], []
 * 	for shape in shape_list:             # <<<<<<<<<<<<<<
 * 		#print(shape)
 * 		shapeName = shape.encode()
 */
  if (likely(PyList_CheckExact(__pyx_v_shape_list)) || PyTuple_CheckExact(__pyx_v_shape_list)) {
    __pyx_t_3 = __pyx_v_shape_list; __Pyx_INCREF(__pyx_t_3); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_shape_list); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 314, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_9 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 314, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_8); __Pyx_INCREF(__pyx_t_5); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 314, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 314, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_8); __Pyx_INCREF(__pyx_t_5); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 314, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 314, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_9(__pyx_t_3);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 314, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":316
 * 	for shape in shape_list:
 * 		#print(shape)
 * 		shapeName = shape.encode()             # <<<<<<<<<<<<<<
 * 		#if params == 'tract':
 * 		#	value = vtlGetTractParams( shapeName, &tractParams[0, 0] )
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_shape, __pyx_n_s_encode); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 316, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_5 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 316, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_shapeName, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":324
 * 		#	sub_glottal_shapes.append( [ glottisParams, shape ] )
 * 		#else:
 * 		value = vtlGetTractParams( shapeName, &tractParams[ 0 ] )             # <<<<<<<<<<<<<<
 * 		if value == 0:
 * 			supra_glottal_shapes.append( tractParams.copy() )
 */
    __pyx_t_10 = __Pyx_PyObject_AsString(__pyx_v_shapeName); if (unlikely((!__pyx_t_10) && PyErr_Occurred())) __PYX_ERR(0, 324, __pyx_L1_error)
    __pyx_t_11 = 0;
    __pyx_t_4 = -1;
    if (__pyx_t_11 < 0) {
      __pyx_t_11 += __pyx_pybuffernd_tractParams.diminfo[0].shape;
      if (unlikely(__pyx_t_11 < 0)) __pyx_t_4 = 0;
    } else if (unlikely(__pyx_t_11 >= __pyx_pybuffernd_tractParams.diminfo[0].shape)) __pyx_t_4 = 0;
    if (unlikely(__pyx_t_4 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_4);
      __PYX_ERR(0, 324, __pyx_L1_error)
    }
    __pyx_v_value = vtlGetTractParams(__pyx_t_10, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf, __pyx_t_11, __pyx_pybuffernd_tractParams.diminfo[0].strides))));

    /* "VocalTractLab/VocalTractLabApi.pyx":325
 * 		#else:
 * 		value = vtlGetTractParams( shapeName, &tractParams[ 0 ] )
 * 		if value == 0:             # <<<<<<<<<<<<<<
 * 			supra_glottal_shapes.append( tractParams.copy() )
 * 			supra_glottal_shape_names.append( shape )
 */
    __pyx_t_12 = ((__pyx_v_value == 0) != 0);
    if (__pyx_t_12) {

      /* "VocalTractLab/VocalTractLabApi.pyx":326
 * 		value = vtlGetTractParams( shapeName, &tractParams[ 0 ] )
 * 		if value == 0:
 * 			supra_glottal_shapes.append( tractParams.copy() )             # <<<<<<<<<<<<<<
 * 			supra_glottal_shape_names.append( shape )
 * 		if value == 2:
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_tractParams), __pyx_n_s_copy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 326, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_2)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      __pyx_t_5 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 326, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_13 = __Pyx_PyList_Append(__pyx_v_supra_glottal_shapes, __pyx_t_5); if (unlikely(__pyx_t_13 == ((int)-1))) __PYX_ERR(0, 326, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":327
 * 		if value == 0:
 * 			supra_glottal_shapes.append( tractParams.copy() )
 * 			supra_glottal_shape_names.append( shape )             # <<<<<<<<<<<<<<
 * 		if value == 2:
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )
 */
      __pyx_t_13 = __Pyx_PyList_Append(__pyx_v_supra_glottal_shape_names, __pyx_v_shape); if (unlikely(__pyx_t_13 == ((int)-1))) __PYX_ERR(0, 327, __pyx_L1_error)

      /* "VocalTractLab/VocalTractLabApi.pyx":325
 * 		#else:
 * 		value = vtlGetTractParams( shapeName, &tractParams[ 0 ] )
 * 		if value == 0:             # <<<<<<<<<<<<<<
 * 			supra_glottal_shapes.append( tractParams.copy() )
 * 			supra_glottal_shape_names.append( shape )
 */
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":328
 * 			supra_glottal_shapes.append( tractParams.copy() )
 * 			supra_glottal_shape_names.append( shape )
 * 		if value == 2:             # <<<<<<<<<<<<<<
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )
 */
    __pyx_t_12 = ((__pyx_v_value == 2) != 0);
    if (__pyx_t_12) {

      /* "VocalTractLab/VocalTractLabApi.pyx":329
 * 			supra_glottal_shape_names.append( shape )
 * 		if value == 2:
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )             # <<<<<<<<<<<<<<
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )
 * 			if value == 0:
 */
      __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_log); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 329, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_info); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 329, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Specified_shape_was_not_found_in, __pyx_n_s_format); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 329, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __pyx_t_15 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
        __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_14);
        if (likely(__pyx_t_15)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
          __Pyx_INCREF(__pyx_t_15);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_14, function);
        }
      }
      __pyx_t_1 = (__pyx_t_15) ? __Pyx_PyObject_Call2Args(__pyx_t_14, __pyx_t_15, __pyx_v_shape) : __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_v_shape);
      __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 329, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_14 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_14)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_14);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      __pyx_t_5 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_14, __pyx_t_1) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1);
      __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 329, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":330
 * 		if value == 2:
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )             # <<<<<<<<<<<<<<
 * 			if value == 0:
 * 				sub_glottal_shapes.append( glottisParams.copy() )
 */
      __pyx_t_16 = __Pyx_PyObject_AsString(__pyx_v_shapeName); if (unlikely((!__pyx_t_16) && PyErr_Occurred())) __PYX_ERR(0, 330, __pyx_L1_error)
      __pyx_t_11 = 0;
      __pyx_t_4 = -1;
      if (__pyx_t_11 < 0) {
        __pyx_t_11 += __pyx_pybuffernd_glottisParams.diminfo[0].shape;
        if (unlikely(__pyx_t_11 < 0)) __pyx_t_4 = 0;
      } else if (unlikely(__pyx_t_11 >= __pyx_pybuffernd_glottisParams.diminfo[0].shape)) __pyx_t_4 = 0;
      if (unlikely(__pyx_t_4 != -1)) {
        __Pyx_RaiseBufferIndexError(__pyx_t_4);
        __PYX_ERR(0, 330, __pyx_L1_error)
      }
      __pyx_v_value = vtlGetGlottisParams(__pyx_t_16, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.buf, __pyx_t_11, __pyx_pybuffernd_glottisParams.diminfo[0].strides))));

      /* "VocalTractLab/VocalTractLabApi.pyx":331
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )
 * 			if value == 0:             # <<<<<<<<<<<<<<
 * 				sub_glottal_shapes.append( glottisParams.copy() )
 * 				sub_glottal_shape_names.append( shape )
 */
      __pyx_t_12 = ((__pyx_v_value == 0) != 0);
      if (__pyx_t_12) {

        /* "VocalTractLab/VocalTractLabApi.pyx":332
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )
 * 			if value == 0:
 * 				sub_glottal_shapes.append( glottisParams.copy() )             # <<<<<<<<<<<<<<
 * 				sub_glottal_shape_names.append( shape )
 * 		if value != 0:
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_glottisParams), __pyx_n_s_copy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 332, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_1 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
          __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
          if (likely(__pyx_t_1)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
            __Pyx_INCREF(__pyx_t_1);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_2, function);
          }
        }
        __pyx_t_5 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 332, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_13 = __Pyx_PyList_Append(__pyx_v_sub_glottal_shapes, __pyx_t_5); if (unlikely(__pyx_t_13 == ((int)-1))) __PYX_ERR(0, 332, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

        /* "VocalTractLab/VocalTractLabApi.pyx":333
 * 			if value == 0:
 * 				sub_glottal_shapes.append( glottisParams.copy() )
 * 				sub_glottal_shape_names.append( shape )             # <<<<<<<<<<<<<<
 * 		if value != 0:
 * 			raise ValueError('VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 */
        __pyx_t_13 = __Pyx_PyList_Append(__pyx_v_sub_glottal_shape_names, __pyx_v_shape); if (unlikely(__pyx_t_13 == ((int)-1))) __PYX_ERR(0, 333, __pyx_L1_error)

        /* "VocalTractLab/VocalTractLabApi.pyx":331
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )
 * 			if value == 0:             # <<<<<<<<<<<<<<
 * 				sub_glottal_shapes.append( glottisParams.copy() )
 * 				sub_glottal_shape_names.append( shape )
 */
      }

      /* "VocalTractLab/VocalTractLabApi.pyx":328
 * 			supra_glottal_shapes.append( tractParams.copy() )
 * 			supra_glottal_shape_names.append( shape )
 * 		if value == 2:             # <<<<<<<<<<<<<<
 * 			log.info('Specified shape: {} was not found in tract state shapes. Looking for glottal shapes now.'.format( shape ) )
 * 			value = vtlGetGlottisParams( shapeName, &glottisParams[ 0 ] )
 */
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":334
 * 				sub_glottal_shapes.append( glottisParams.copy() )
 * 				sub_glottal_shape_names.append( shape )
 * 		if value != 0:             # <<<<<<<<<<<<<<
 * 			raise ValueError('VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	supra_glottal_sequence_name = ','.join( supra_glottal_shape_names )
 */
    __pyx_t_12 = ((__pyx_v_value != 0) != 0);
    if (unlikely(__pyx_t_12)) {

      /* "VocalTractLab/VocalTractLabApi.pyx":335
 * 				sub_glottal_shape_names.append( shape )
 * 		if value != 0:
 * 			raise ValueError('VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)'.format( value ) )             # <<<<<<<<<<<<<<
 * 	supra_glottal_sequence_name = ','.join( supra_glottal_shape_names )
 * 	sub_glottal_sequence_name = ','.join( sub_glottal_shape_names )
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlGetTractPara_2, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 335, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 335, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_14 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_14)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_14);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      __pyx_t_5 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_14, __pyx_t_1) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1);
      __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 335, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 335, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 335, __pyx_L1_error)

      /* "VocalTractLab/VocalTractLabApi.pyx":334
 * 				sub_glottal_shapes.append( glottisParams.copy() )
 * 				sub_glottal_shape_names.append( shape )
 * 		if value != 0:             # <<<<<<<<<<<<<<
 * 			raise ValueError('VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	supra_glottal_sequence_name = ','.join( supra_glottal_shape_names )
 */
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":314
 * 	supra_glottal_shapes, sub_glottal_shapes = [], []
 * 	supra_glottal_shape_names, sub_glottal_shape_names = [], []
 * 	for shape in shape_list:             # <<<<<<<<<<<<<<
 * 		#print(shape)
 * 		shapeName = shape.encode()
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":336
 * 		if value != 0:
 * 			raise ValueError('VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	supra_glottal_sequence_name = ','.join( supra_glottal_shape_names )             # <<<<<<<<<<<<<<
 * 	sub_glottal_sequence_name = ','.join( sub_glottal_shape_names )
 * 	#print( 'array shape: {}'.format(np.array( supra_glottal_shapes ).shape )  )
 */
  __pyx_t_3 = __Pyx_PyString_Join(__pyx_kp_s__9, __pyx_v_supra_glottal_shape_names); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 336, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_supra_glottal_sequence_name = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":337
 * 			raise ValueError('VTL API function vtlGetTractParams returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	supra_glottal_sequence_name = ','.join( supra_glottal_shape_names )
 * 	sub_glottal_sequence_name = ','.join( sub_glottal_shape_names )             # <<<<<<<<<<<<<<
 * 	#print( 'array shape: {}'.format(np.array( supra_glottal_shapes ).shape )  )
 * 	if len( supra_glottal_shapes ) != 0 and len( sub_glottal_shapes ) != 0:
 */
  __pyx_t_3 = __Pyx_PyString_Join(__pyx_kp_s__9, __pyx_v_sub_glottal_shape_names); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_sub_glottal_sequence_name = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":339
 * 	sub_glottal_sequence_name = ','.join( sub_glottal_shape_names )
 * 	#print( 'array shape: {}'.format(np.array( supra_glottal_shapes ).shape )  )
 * 	if len( supra_glottal_shapes ) != 0 and len( sub_glottal_shapes ) != 0:             # <<<<<<<<<<<<<<
 * 		supra_glottal_sequence = Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 */
  __pyx_t_8 = PyList_GET_SIZE(__pyx_v_supra_glottal_shapes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 339, __pyx_L1_error)
  __pyx_t_17 = ((__pyx_t_8 != 0) != 0);
  if (__pyx_t_17) {
  } else {
    __pyx_t_12 = __pyx_t_17;
    goto __pyx_L10_bool_binop_done;
  }
  __pyx_t_8 = PyList_GET_SIZE(__pyx_v_sub_glottal_shapes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 339, __pyx_L1_error)
  __pyx_t_17 = ((__pyx_t_8 != 0) != 0);
  __pyx_t_12 = __pyx_t_17;
  __pyx_L10_bool_binop_done:;
  if (__pyx_t_12) {

    /* "VocalTractLab/VocalTractLabApi.pyx":340
 * 	#print( 'array shape: {}'.format(np.array( supra_glottal_shapes ).shape )  )
 * 	if len( supra_glottal_shapes ) != 0 and len( sub_glottal_shapes ) != 0:
 * 		supra_glottal_sequence = Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )             # <<<<<<<<<<<<<<
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * 		if return_motor_sequence:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_array); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_5, __pyx_v_supra_glottal_shapes) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_supra_glottal_shapes);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_name, __pyx_v_supra_glottal_sequence_name) < 0) __PYX_ERR(0, 340, __pyx_L1_error)
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_supra_glottal_sequence = __pyx_t_5;
    __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":341
 * 	if len( supra_glottal_shapes ) != 0 and len( sub_glottal_shapes ) != 0:
 * 		supra_glottal_sequence = Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )             # <<<<<<<<<<<<<<
 * 		if return_motor_sequence:
 * 			motor_sequence_name = ','.join( [ supra_glottal_sequence_name, sub_glottal_sequence_name ] )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_Sub_Glottal_Sequence); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_array); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    __pyx_t_2 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_1, __pyx_v_sub_glottal_shapes) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_sub_glottal_shapes);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_name, __pyx_v_sub_glottal_sequence_name) < 0) __PYX_ERR(0, 341, __pyx_L1_error)
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_sub_glottal_sequence = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":342
 * 		supra_glottal_sequence = Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * 		if return_motor_sequence:             # <<<<<<<<<<<<<<
 * 			motor_sequence_name = ','.join( [ supra_glottal_sequence_name, sub_glottal_sequence_name ] )
 * 			return Motor_Sequence( supra_glottal_sequence, sub_glottal_sequence, name = motor_sequence_name )
 */
    __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_v_return_motor_sequence); if (unlikely(__pyx_t_12 < 0)) __PYX_ERR(0, 342, __pyx_L1_error)
    if (__pyx_t_12) {

      /* "VocalTractLab/VocalTractLabApi.pyx":343
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * 		if return_motor_sequence:
 * 			motor_sequence_name = ','.join( [ supra_glottal_sequence_name, sub_glottal_sequence_name ] )             # <<<<<<<<<<<<<<
 * 			return Motor_Sequence( supra_glottal_sequence, sub_glottal_sequence, name = motor_sequence_name )
 * 		else:
 */
      __pyx_t_1 = PyList_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 343, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_v_supra_glottal_sequence_name);
      __Pyx_GIVEREF(__pyx_v_supra_glottal_sequence_name);
      PyList_SET_ITEM(__pyx_t_1, 0, __pyx_v_supra_glottal_sequence_name);
      __Pyx_INCREF(__pyx_v_sub_glottal_sequence_name);
      __Pyx_GIVEREF(__pyx_v_sub_glottal_sequence_name);
      PyList_SET_ITEM(__pyx_t_1, 1, __pyx_v_sub_glottal_sequence_name);
      __pyx_t_2 = __Pyx_PyString_Join(__pyx_kp_s__9, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 343, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_motor_sequence_name = ((PyObject*)__pyx_t_2);
      __pyx_t_2 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":344
 * 		if return_motor_sequence:
 * 			motor_sequence_name = ','.join( [ supra_glottal_sequence_name, sub_glottal_sequence_name ] )
 * 			return Motor_Sequence( supra_glottal_sequence, sub_glottal_sequence, name = motor_sequence_name )             # <<<<<<<<<<<<<<
 * 		else:
 * 			return [ supra_glottal_sequence, sub_glottal_sequence ]
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_v_supra_glottal_sequence);
      __Pyx_GIVEREF(__pyx_v_supra_glottal_sequence);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_supra_glottal_sequence);
      __Pyx_INCREF(__pyx_v_sub_glottal_sequence);
      __Pyx_GIVEREF(__pyx_v_sub_glottal_sequence);
      PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_v_sub_glottal_sequence);
      __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_name, __pyx_v_motor_sequence_name) < 0) __PYX_ERR(0, 344, __pyx_L1_error)
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_5;
      __pyx_t_5 = 0;
      goto __pyx_L0;

      /* "VocalTractLab/VocalTractLabApi.pyx":342
 * 		supra_glottal_sequence = Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * 		if return_motor_sequence:             # <<<<<<<<<<<<<<
 * 			motor_sequence_name = ','.join( [ supra_glottal_sequence_name, sub_glottal_sequence_name ] )
 * 			return Motor_Sequence( supra_glottal_sequence, sub_glottal_sequence, name = motor_sequence_name )
 */
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":346
 * 			return Motor_Sequence( supra_glottal_sequence, sub_glottal_sequence, name = motor_sequence_name )
 * 		else:
 * 			return [ supra_glottal_sequence, sub_glottal_sequence ]             # <<<<<<<<<<<<<<
 * 	elif len( supra_glottal_shapes ) != 0:
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 */
    /*else*/ {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_5 = PyList_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 346, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_v_supra_glottal_sequence);
      __Pyx_GIVEREF(__pyx_v_supra_glottal_sequence);
      PyList_SET_ITEM(__pyx_t_5, 0, __pyx_v_supra_glottal_sequence);
      __Pyx_INCREF(__pyx_v_sub_glottal_sequence);
      __Pyx_GIVEREF(__pyx_v_sub_glottal_sequence);
      PyList_SET_ITEM(__pyx_t_5, 1, __pyx_v_sub_glottal_sequence);
      __pyx_r = __pyx_t_5;
      __pyx_t_5 = 0;
      goto __pyx_L0;
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":339
 * 	sub_glottal_sequence_name = ','.join( sub_glottal_shape_names )
 * 	#print( 'array shape: {}'.format(np.array( supra_glottal_shapes ).shape )  )
 * 	if len( supra_glottal_shapes ) != 0 and len( sub_glottal_shapes ) != 0:             # <<<<<<<<<<<<<<
 * 		supra_glottal_sequence = Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 		sub_glottal_sequence = Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":347
 * 		else:
 * 			return [ supra_glottal_sequence, sub_glottal_sequence ]
 * 	elif len( supra_glottal_shapes ) != 0:             # <<<<<<<<<<<<<<
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 	elif len( sub_glottal_shapes ) != 0:
 */
  __pyx_t_8 = PyList_GET_SIZE(__pyx_v_supra_glottal_shapes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 347, __pyx_L1_error)
  __pyx_t_12 = ((__pyx_t_8 != 0) != 0);
  if (__pyx_t_12) {

    /* "VocalTractLab/VocalTractLabApi.pyx":348
 * 			return [ supra_glottal_sequence, sub_glottal_sequence ]
 * 	elif len( supra_glottal_shapes ) != 0:
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )             # <<<<<<<<<<<<<<
 * 	elif len( sub_glottal_shapes ) != 0:
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_array); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_1, __pyx_v_supra_glottal_shapes) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_supra_glottal_shapes);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_name, __pyx_v_supra_glottal_sequence_name) < 0) __PYX_ERR(0, 348, __pyx_L1_error)
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 348, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":347
 * 		else:
 * 			return [ supra_glottal_sequence, sub_glottal_sequence ]
 * 	elif len( supra_glottal_shapes ) != 0:             # <<<<<<<<<<<<<<
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 	elif len( sub_glottal_shapes ) != 0:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":349
 * 	elif len( supra_glottal_shapes ) != 0:
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 	elif len( sub_glottal_shapes ) != 0:             # <<<<<<<<<<<<<<
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_8 = PyList_GET_SIZE(__pyx_v_sub_glottal_shapes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 349, __pyx_L1_error)
  __pyx_t_12 = ((__pyx_t_8 != 0) != 0);
  if (__pyx_t_12) {

    /* "VocalTractLab/VocalTractLabApi.pyx":350
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 	elif len( sub_glottal_shapes ) != 0:
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_supra_glottal_state( key ):
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_Sub_Glottal_Sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_array); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_3 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_2, __pyx_v_sub_glottal_shapes) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_sub_glottal_shapes);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_name, __pyx_v_sub_glottal_sequence_name) < 0) __PYX_ERR(0, 350, __pyx_L1_error)
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 350, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":349
 * 	elif len( supra_glottal_shapes ) != 0:
 * 		return Supra_Glottal_Sequence( np.array( supra_glottal_shapes ), name = supra_glottal_sequence_name )
 * 	elif len( sub_glottal_shapes ) != 0:             # <<<<<<<<<<<<<<
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":307
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )
 * 	constants = get_constants()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_XDECREF(__pyx_t_15);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_glottisParams.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_shapes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_glottisParams.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF((PyObject *)__pyx_v_tractParams);
  __Pyx_XDECREF((PyObject *)__pyx_v_glottisParams);
  __Pyx_XDECREF(__pyx_v_supra_glottal_shapes);
  __Pyx_XDECREF(__pyx_v_sub_glottal_shapes);
  __Pyx_XDECREF(__pyx_v_supra_glottal_shape_names);
  __Pyx_XDECREF(__pyx_v_sub_glottal_shape_names);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_shapeName);
  __Pyx_XDECREF(__pyx_v_supra_glottal_sequence_name);
  __Pyx_XDECREF(__pyx_v_sub_glottal_sequence_name);
  __Pyx_XDECREF(__pyx_v_supra_glottal_sequence);
  __Pyx_XDECREF(__pyx_v_sub_glottal_sequence);
  __Pyx_XDECREF(__pyx_v_motor_sequence_name);
  __Pyx_XDECREF(__pyx_v_shape_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":352
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_supra_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_13get_supra_glottal_state(PyObject *__pyx_self, PyObject *__pyx_v_key); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_13get_supra_glottal_state = {"get_supra_glottal_state", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_13get_supra_glottal_state, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_13get_supra_glottal_state(PyObject *__pyx_self, PyObject *__pyx_v_key) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_supra_glottal_state (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_12get_supra_glottal_state(__pyx_self, ((PyObject *)__pyx_v_key));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_12get_supra_glottal_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_key) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_supra_glottal_state", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":353
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_supra_glottal_state( key ):
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_sub_glottal_state( key ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_get_param_info); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_n_s_tract) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_n_s_tract);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetItem(__pyx_t_1, __pyx_v_key); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_to_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, ((PyObject *)(&PyFloat_Type))) < 0) __PYX_ERR(0, 353, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":352
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_supra_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_supra_glottal_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":355
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_sub_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_15get_sub_glottal_state(PyObject *__pyx_self, PyObject *__pyx_v_key); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_15get_sub_glottal_state = {"get_sub_glottal_state", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_15get_sub_glottal_state, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_15get_sub_glottal_state(PyObject *__pyx_self, PyObject *__pyx_v_key) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_sub_glottal_state (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_14get_sub_glottal_state(__pyx_self, ((PyObject *)__pyx_v_key));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_14get_sub_glottal_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_key) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_sub_glottal_state", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":356
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_sub_glottal_state( key ):
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def load_speaker_file( str speaker_file_path ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_get_param_info); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_n_s_glottis) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_n_s_glottis);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetItem(__pyx_t_1, __pyx_v_key); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_to_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, ((PyObject *)(&PyFloat_Type))) < 0) __PYX_ERR(0, 356, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":355
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_sub_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_sub_glottal_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":358
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def load_speaker_file( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	_close()
 * 	_initialize( speaker_file_path )
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_17load_speaker_file(PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_17load_speaker_file = {"load_speaker_file", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_17load_speaker_file, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_17load_speaker_file(PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("load_speaker_file (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_speaker_file_path), (&PyString_Type), 1, "speaker_file_path", 1))) __PYX_ERR(0, 358, __pyx_L1_error)
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_16load_speaker_file(__pyx_self, ((PyObject*)__pyx_v_speaker_file_path));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_16load_speaker_file(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("load_speaker_file", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":359
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def load_speaker_file( str speaker_file_path ):
 * 	_close()             # <<<<<<<<<<<<<<
 * 	_initialize( speaker_file_path )
 * 	log.info( 'Loaded new speakerfile: {}. Overwriting existing settings with the values from the new speaker file.'.format( speaker_file_path ) )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_close); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 359, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 359, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":360
 * def load_speaker_file( str speaker_file_path ):
 * 	_close()
 * 	_initialize( speaker_file_path )             # <<<<<<<<<<<<<<
 * 	log.info( 'Loaded new speakerfile: {}. Overwriting existing settings with the values from the new speaker file.'.format( speaker_file_path ) )
 * 	return
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_initialize); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 360, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_v_speaker_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_speaker_file_path);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 360, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":361
 * 	_close()
 * 	_initialize( speaker_file_path )
 * 	log.info( 'Loaded new speakerfile: {}. Overwriting existing settings with the values from the new speaker file.'.format( speaker_file_path ) )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_log); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_info); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Loaded_new_speakerfile_Overwriti, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_v_speaker_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_speaker_file_path);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":362
 * 	_initialize( speaker_file_path )
 * 	log.info( 'Loaded new speakerfile: {}. Overwriting existing settings with the values from the new speaker file.'.format( speaker_file_path ) )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":358
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def load_speaker_file( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	_close()
 * 	_initialize( speaker_file_path )
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.load_speaker_file", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":369
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_gestural_score_audio_duration( str ges_file_path, return_samples = True ):             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	cdef int numAudioSamples = 0
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_19get_gestural_score_audio_duration(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_19get_gestural_score_audio_duration = {"get_gestural_score_audio_duration", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_19get_gestural_score_audio_duration, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_19get_gestural_score_audio_duration(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ges_file_path = 0;
  PyObject *__pyx_v_return_samples = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_gestural_score_audio_duration (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ges_file_path,&__pyx_n_s_return_samples,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_ges_file_path)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_samples);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get_gestural_score_audio_duration") < 0)) __PYX_ERR(0, 369, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_ges_file_path = ((PyObject*)values[0]);
    __pyx_v_return_samples = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get_gestural_score_audio_duration", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 369, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_gestural_score_audio_duration", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_ges_file_path), (&PyString_Type), 1, "ges_file_path", 1))) __PYX_ERR(0, 369, __pyx_L1_error)
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_18get_gestural_score_audio_duration(__pyx_self, __pyx_v_ges_file_path, __pyx_v_return_samples);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_18get_gestural_score_audio_duration(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ges_file_path, PyObject *__pyx_v_return_samples) {
  PyObject *__pyx_v_gesFileName = NULL;
  int __pyx_v_numAudioSamples;
  void *__pyx_v_numGestureSamples;
  int __pyx_v_n_samples;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char const *__pyx_t_2;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_gestural_score_audio_duration", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":370
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_gestural_score_audio_duration( str ges_file_path, return_samples = True ):
 * 	gesFileName = ges_file_path.encode()             # <<<<<<<<<<<<<<
 * 	cdef int numAudioSamples = 0
 * 	numGestureSamples = NULL
 */
  __pyx_t_1 = __Pyx_CallUnboundCMethod0(&__pyx_umethod_PyString_Type_encode, __pyx_v_ges_file_path); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 370, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_gesFileName = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":371
 * def get_gestural_score_audio_duration( str ges_file_path, return_samples = True ):
 * 	gesFileName = ges_file_path.encode()
 * 	cdef int numAudioSamples = 0             # <<<<<<<<<<<<<<
 * 	numGestureSamples = NULL
 * 	vtlGetGesturalScoreDuration( gesFileName, &numAudioSamples, numGestureSamples )
 */
  __pyx_v_numAudioSamples = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":372
 * 	gesFileName = ges_file_path.encode()
 * 	cdef int numAudioSamples = 0
 * 	numGestureSamples = NULL             # <<<<<<<<<<<<<<
 * 	vtlGetGesturalScoreDuration( gesFileName, &numAudioSamples, numGestureSamples )
 * 	n_samples = numAudioSamples
 */
  __pyx_v_numGestureSamples = NULL;

  /* "VocalTractLab/VocalTractLabApi.pyx":373
 * 	cdef int numAudioSamples = 0
 * 	numGestureSamples = NULL
 * 	vtlGetGesturalScoreDuration( gesFileName, &numAudioSamples, numGestureSamples )             # <<<<<<<<<<<<<<
 * 	n_samples = numAudioSamples
 * 	if return_samples: # returning number of audio samples
 */
  __pyx_t_2 = __Pyx_PyObject_AsString(__pyx_v_gesFileName); if (unlikely((!__pyx_t_2) && PyErr_Occurred())) __PYX_ERR(0, 373, __pyx_L1_error)
  (void)(vtlGetGesturalScoreDuration(__pyx_t_2, (&__pyx_v_numAudioSamples), __pyx_v_numGestureSamples));

  /* "VocalTractLab/VocalTractLabApi.pyx":374
 * 	numGestureSamples = NULL
 * 	vtlGetGesturalScoreDuration( gesFileName, &numAudioSamples, numGestureSamples )
 * 	n_samples = numAudioSamples             # <<<<<<<<<<<<<<
 * 	if return_samples: # returning number of audio samples
 * 		return n_samples
 */
  __pyx_v_n_samples = __pyx_v_numAudioSamples;

  /* "VocalTractLab/VocalTractLabApi.pyx":375
 * 	vtlGetGesturalScoreDuration( gesFileName, &numAudioSamples, numGestureSamples )
 * 	n_samples = numAudioSamples
 * 	if return_samples: # returning number of audio samples             # <<<<<<<<<<<<<<
 * 		return n_samples
 * 	#else: # returning time in seconds
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v_return_samples); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 375, __pyx_L1_error)
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":376
 * 	n_samples = numAudioSamples
 * 	if return_samples: # returning number of audio samples
 * 		return n_samples             # <<<<<<<<<<<<<<
 * 	#else: # returning time in seconds
 * 	#	return n_samples / self.params.samplerate_audio
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_n_samples); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 376, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":375
 * 	vtlGetGesturalScoreDuration( gesFileName, &numAudioSamples, numGestureSamples )
 * 	n_samples = numAudioSamples
 * 	if return_samples: # returning number of audio samples             # <<<<<<<<<<<<<<
 * 		return n_samples
 * 	#else: # returning time in seconds
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":369
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_gestural_score_audio_duration( str ges_file_path, return_samples = True ):             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	cdef int numAudioSamples = 0
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.get_gestural_score_audio_duration", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_gesFileName);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":385
 * # 		User mp enabled functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def change_gestural_score(             # <<<<<<<<<<<<<<
 * 	in_ges_file_path_list,
 * 	out_ges_file_path_list,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_21change_gestural_score(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_21change_gestural_score = {"change_gestural_score", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_21change_gestural_score, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_21change_gestural_score(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  CYTHON_UNUSED PyObject *__pyx_v_in_ges_file_path_list = 0;
  CYTHON_UNUSED PyObject *__pyx_v_out_ges_file_path_list = 0;
  CYTHON_UNUSED PyObject *__pyx_v_modification_kwargs = 0;
  CYTHON_UNUSED bool __pyx_v_workers;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("change_gestural_score (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_in_ges_file_path_list,&__pyx_n_s_out_ges_file_path_list,&__pyx_n_s_modification_kwargs,&__pyx_n_s_workers,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_in_ges_file_path_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_out_ges_file_path_list)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("change_gestural_score", 0, 3, 4, 1); __PYX_ERR(0, 385, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_modification_kwargs)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("change_gestural_score", 0, 3, 4, 2); __PYX_ERR(0, 385, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "change_gestural_score") < 0)) __PYX_ERR(0, 385, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_in_ges_file_path_list = values[0];
    __pyx_v_out_ges_file_path_list = values[1];
    __pyx_v_modification_kwargs = values[2];
    if (values[3]) {
      __pyx_v_workers = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_workers == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 389, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":389
 * 	out_ges_file_path_list,
 * 	modification_kwargs,
 * 	workers: bool = False,             # <<<<<<<<<<<<<<
 * 	):
 * 
 */
      __pyx_v_workers = ((bool)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("change_gestural_score", 0, 3, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 385, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.change_gestural_score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_20change_gestural_score(__pyx_self, __pyx_v_in_ges_file_path_list, __pyx_v_out_ges_file_path_list, __pyx_v_modification_kwargs, __pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":385
 * # 		User mp enabled functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def change_gestural_score(             # <<<<<<<<<<<<<<
 * 	in_ges_file_path_list,
 * 	out_ges_file_path_list,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_20change_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, CYTHON_UNUSED PyObject *__pyx_v_in_ges_file_path_list, CYTHON_UNUSED PyObject *__pyx_v_out_ges_file_path_list, CYTHON_UNUSED PyObject *__pyx_v_modification_kwargs, CYTHON_UNUSED bool __pyx_v_workers) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("change_gestural_score", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":392
 * 	):
 * 
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":385
 * # 		User mp enabled functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def change_gestural_score(             # <<<<<<<<<<<<<<
 * 	in_ges_file_path_list,
 * 	out_ges_file_path_list,
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":394
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_23gestural_score_to_audio(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_23gestural_score_to_audio = {"gestural_score_to_audio", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_23gestural_score_to_audio, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_23gestural_score_to_audio(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ges_file_path_list = 0;
  PyObject *__pyx_v_audio_file_path_list = 0;
  bool __pyx_v_save_file;
  PyObject *__pyx_v_normalize_audio = 0;
  PyObject *__pyx_v_sr = 0;
  bool __pyx_v_return_data;
  PyObject *__pyx_v_workers = 0;
  bool __pyx_v_verbose;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gestural_score_to_audio (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ges_file_path_list,&__pyx_n_s_audio_file_path_list,&__pyx_n_s_save_file,&__pyx_n_s_normalize_audio,&__pyx_n_s_sr,&__pyx_n_s_return_data,&__pyx_n_s_workers,&__pyx_n_s_verbose,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":395
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,
 * 								audio_file_path_list = None,             # <<<<<<<<<<<<<<
 * 								save_file: bool = True,
 * 								normalize_audio: int = None,
 */
    values[1] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":397
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,
 * 								normalize_audio: int = None,             # <<<<<<<<<<<<<<
 * 								sr: int = None,
 * 								return_data: bool = False,
 */
    values[3] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":398
 * 								save_file: bool = True,
 * 								normalize_audio: int = None,
 * 								sr: int = None,             # <<<<<<<<<<<<<<
 * 								return_data: bool = False,
 * 								workers: int = None,
 */
    values[4] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":400
 * 								sr: int = None,
 * 								return_data: bool = False,
 * 								workers: int = None,             # <<<<<<<<<<<<<<
 * 								verbose: bool = False,
 * 							):
 */
    values[6] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_ges_file_path_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_audio_file_path_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_file);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_normalize_audio);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_sr);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_data);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_verbose);
          if (value) { values[7] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "gestural_score_to_audio") < 0)) __PYX_ERR(0, 394, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_ges_file_path_list = values[0];
    __pyx_v_audio_file_path_list = values[1];
    if (values[2]) {
      __pyx_v_save_file = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_save_file == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 396, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":396
 * def gestural_score_to_audio(	ges_file_path_list,
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,             # <<<<<<<<<<<<<<
 * 								normalize_audio: int = None,
 * 								sr: int = None,
 */
      __pyx_v_save_file = ((bool)1);
    }
    __pyx_v_normalize_audio = values[3];
    __pyx_v_sr = values[4];
    if (values[5]) {
      __pyx_v_return_data = __Pyx_PyObject_IsTrue(values[5]); if (unlikely((__pyx_v_return_data == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 399, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":399
 * 								normalize_audio: int = None,
 * 								sr: int = None,
 * 								return_data: bool = False,             # <<<<<<<<<<<<<<
 * 								workers: int = None,
 * 								verbose: bool = False,
 */
      __pyx_v_return_data = ((bool)0);
    }
    __pyx_v_workers = values[6];
    if (values[7]) {
      __pyx_v_verbose = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_verbose == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 401, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":401
 * 								return_data: bool = False,
 * 								workers: int = None,
 * 								verbose: bool = False,             # <<<<<<<<<<<<<<
 * 							):
 * 	ges_file_path_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, audio_file_path_list ],
 */
      __pyx_v_verbose = ((bool)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gestural_score_to_audio", 0, 1, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 394, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.gestural_score_to_audio", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_22gestural_score_to_audio(__pyx_self, __pyx_v_ges_file_path_list, __pyx_v_audio_file_path_list, __pyx_v_save_file, __pyx_v_normalize_audio, __pyx_v_sr, __pyx_v_return_data, __pyx_v_workers, __pyx_v_verbose);

  /* "VocalTractLab/VocalTractLabApi.pyx":394
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_22gestural_score_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ges_file_path_list, PyObject *__pyx_v_audio_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_audio_data_list = NULL;
  PyObject *__pyx_v_ges_file_path = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gestural_score_to_audio", 0);
  __Pyx_INCREF(__pyx_v_ges_file_path_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":403
 * 								verbose: bool = False,
 * 							):
 * 	ges_file_path_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, audio_file_path_list ],             # <<<<<<<<<<<<<<
 *                                                                                   [ str, ( str, type(None) ) ],
 * 	                                                                            )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 403, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 403, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 403, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_ges_file_path_list);
  __Pyx_GIVEREF(__pyx_v_ges_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_ges_file_path_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);
  __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_audio_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":404
 * 							):
 * 	ges_file_path_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, audio_file_path_list ],
 *                                                                                   [ str, ( str, type(None) ) ],             # <<<<<<<<<<<<<<
 * 	                                                                            )
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]
 */
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 404, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_4, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_5 = PyList_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 404, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyList_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyList_SET_ITEM(__pyx_t_5, 1, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_5);
    __pyx_t_2 = 0;
    __pyx_t_5 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 403, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_7);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = Py_TYPE(__pyx_t_5)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_7 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_7)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_7);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_5), 2) < 0) __PYX_ERR(0, 403, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 403, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":403
 * 								verbose: bool = False,
 * 							):
 * 	ges_file_path_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, audio_file_path_list ],             # <<<<<<<<<<<<<<
 *                                                                                   [ str, ( str, type(None) ) ],
 * 	                                                                            )
 */
  __Pyx_DECREF_SET(__pyx_v_ges_file_path_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_audio_file_path_list, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":406
 *                                                                                   [ str, ( str, type(None) ) ],
 * 	                                                                            )
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]             # <<<<<<<<<<<<<<
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]
 * 	if len( args ) == 1:
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 406, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":407
 * 	                                                                            )
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	if len( args ) == 1:
 * 		audio_data_list = _gestural_score_to_audio( args[ 0 ] )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_itertools); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 407, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 407, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_ges_file_path_list, __pyx_v_audio_file_path_list};
    __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_ges_file_path_list, __pyx_v_audio_file_path_list};
    __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_ges_file_path_list);
    __Pyx_GIVEREF(__pyx_v_ges_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_6, __pyx_v_ges_file_path_list);
    __Pyx_INCREF(__pyx_v_audio_file_path_list);
    __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_6, __pyx_v_audio_file_path_list);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (likely(PyList_CheckExact(__pyx_t_7)) || PyTuple_CheckExact(__pyx_t_7)) {
    __pyx_t_5 = __pyx_t_7; __Pyx_INCREF(__pyx_t_5); __pyx_t_9 = 0;
    __pyx_t_10 = NULL;
  } else {
    __pyx_t_9 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 407, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  for (;;) {
    if (likely(!__pyx_t_10)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_7); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 407, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 407, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_7); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 407, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 407, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_10(__pyx_t_5);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 407, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_7))) || (PyList_CheckExact(__pyx_t_7))) {
      PyObject* sequence = __pyx_t_7;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 407, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 407, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 407, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_4 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 407, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_8 = Py_TYPE(__pyx_t_4)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_3 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_3);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_4), 2) < 0) __PYX_ERR(0, 407, __pyx_L1_error)
      __pyx_t_8 = NULL;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_8 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 407, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_ges_file_path, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_audio_file_path, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":406
 *                                                                                   [ str, ( str, type(None) ) ],
 * 	                                                                            )
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]             # <<<<<<<<<<<<<<
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]
 * 	if len( args ) == 1:
 */
    __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_save_file); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_v_verbose); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = PyList_New(6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_v_ges_file_path);
    PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_ges_file_path);
    __Pyx_INCREF(__pyx_v_audio_file_path);
    __Pyx_GIVEREF(__pyx_v_audio_file_path);
    PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_audio_file_path);
    __Pyx_GIVEREF(__pyx_t_7);
    PyList_SET_ITEM(__pyx_t_2, 2, __pyx_t_7);
    __Pyx_INCREF(__pyx_v_normalize_audio);
    __Pyx_GIVEREF(__pyx_v_normalize_audio);
    PyList_SET_ITEM(__pyx_t_2, 3, __pyx_v_normalize_audio);
    __Pyx_INCREF(__pyx_v_sr);
    __Pyx_GIVEREF(__pyx_v_sr);
    PyList_SET_ITEM(__pyx_t_2, 4, __pyx_v_sr);
    __Pyx_GIVEREF(__pyx_t_3);
    PyList_SET_ITEM(__pyx_t_2, 5, __pyx_t_3);
    __pyx_t_7 = 0;
    __pyx_t_3 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_2))) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":407
 * 	                                                                            )
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	if len( args ) == 1:
 * 		audio_data_list = _gestural_score_to_audio( args[ 0 ] )
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":408
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]
 * 	if len( args ) == 1:             # <<<<<<<<<<<<<<
 * 		audio_data_list = _gestural_score_to_audio( args[ 0 ] )
 * 	else:
 */
  __pyx_t_9 = PyList_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 408, __pyx_L1_error)
  __pyx_t_11 = ((__pyx_t_9 == 1) != 0);
  if (__pyx_t_11) {

    /* "VocalTractLab/VocalTractLabApi.pyx":409
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]
 * 	if len( args ) == 1:
 * 		audio_data_list = _gestural_score_to_audio( args[ 0 ] )             # <<<<<<<<<<<<<<
 * 	else:
 * 		audio_data_list = _run_multiprocessing( _gestural_score_to_audio, args, return_data, workers )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_gestural_score_to_audio); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 409, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_GetItemInt_List(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 409, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_3, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_2);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 409, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_audio_data_list = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":408
 * 	args =  [ [ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for ges_file_path, audio_file_path in itertools.zip_longest( ges_file_path_list, audio_file_path_list ) ]
 * 	if len( args ) == 1:             # <<<<<<<<<<<<<<
 * 		audio_data_list = _gestural_score_to_audio( args[ 0 ] )
 * 	else:
 */
    goto __pyx_L9;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":411
 * 		audio_data_list = _gestural_score_to_audio( args[ 0 ] )
 * 	else:
 * 		audio_data_list = _run_multiprocessing( _gestural_score_to_audio, args, return_data, workers )             # <<<<<<<<<<<<<<
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 411, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_gestural_score_to_audio); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 411, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_v_return_data); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 411, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = NULL;
    __pyx_t_6 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_6 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_2, __pyx_v_args, __pyx_t_3, __pyx_v_workers};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 411, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_2, __pyx_v_args, __pyx_t_3, __pyx_v_workers};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 411, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(4+__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 411, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (__pyx_t_7) {
        __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7); __pyx_t_7 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_6, __pyx_t_2);
      __Pyx_INCREF(__pyx_v_args);
      __Pyx_GIVEREF(__pyx_v_args);
      PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_6, __pyx_v_args);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_6, __pyx_t_3);
      __Pyx_INCREF(__pyx_v_workers);
      __Pyx_GIVEREF(__pyx_v_workers);
      PyTuple_SET_ITEM(__pyx_t_4, 3+__pyx_t_6, __pyx_v_workers);
      __pyx_t_2 = 0;
      __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 411, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_audio_data_list = __pyx_t_1;
    __pyx_t_1 = 0;
  }
  __pyx_L9:;

  /* "VocalTractLab/VocalTractLabApi.pyx":412
 * 	else:
 * 		audio_data_list = _run_multiprocessing( _gestural_score_to_audio, args, return_data, workers )
 * 	return audio_data_list             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_audio_data_list);
  __pyx_r = __pyx_v_audio_data_list;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":394
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.gestural_score_to_audio", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_audio_data_list);
  __Pyx_XDECREF(__pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_ges_file_path_list);
  __Pyx_XDECREF(__pyx_v_audio_file_path_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":414
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_25gestural_score_to_tract_sequence(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_25gestural_score_to_tract_sequence = {"gestural_score_to_tract_sequence", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_25gestural_score_to_tract_sequence, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_25gestural_score_to_tract_sequence(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ges_file_path_list = 0;
  PyObject *__pyx_v_tract_file_path_list = 0;
  bool __pyx_v_return_data;
  PyObject *__pyx_v_workers = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gestural_score_to_tract_sequence (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ges_file_path_list,&__pyx_n_s_tract_file_path_list,&__pyx_n_s_return_data,&__pyx_n_s_workers,0};
    PyObject* values[4] = {0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":415
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,
 * 										tract_file_path_list = None,             # <<<<<<<<<<<<<<
 * 										return_data: bool = False,
 * 										workers: int = None,
 */
    values[1] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":417
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,
 * 										workers: int = None,             # <<<<<<<<<<<<<<
 * 									):
 * 	ges_file_path_list, tract_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, tract_file_path_list ],
 */
    values[3] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_ges_file_path_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tract_file_path_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_data);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "gestural_score_to_tract_sequence") < 0)) __PYX_ERR(0, 414, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_ges_file_path_list = values[0];
    __pyx_v_tract_file_path_list = values[1];
    if (values[2]) {
      __pyx_v_return_data = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_return_data == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 416, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":416
 * def gestural_score_to_tract_sequence(	ges_file_path_list,
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,             # <<<<<<<<<<<<<<
 * 										workers: int = None,
 * 									):
 */
      __pyx_v_return_data = ((bool)0);
    }
    __pyx_v_workers = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gestural_score_to_tract_sequence", 0, 1, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 414, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.gestural_score_to_tract_sequence", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_24gestural_score_to_tract_sequence(__pyx_self, __pyx_v_ges_file_path_list, __pyx_v_tract_file_path_list, __pyx_v_return_data, __pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":414
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_24gestural_score_to_tract_sequence(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ges_file_path_list, PyObject *__pyx_v_tract_file_path_list, bool __pyx_v_return_data, PyObject *__pyx_v_workers) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_tract_sequence_list = NULL;
  PyObject *__pyx_v_ges_file_path = NULL;
  PyObject *__pyx_v_tract_file_path = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gestural_score_to_tract_sequence", 0);
  __Pyx_INCREF(__pyx_v_ges_file_path_list);
  __Pyx_INCREF(__pyx_v_tract_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":419
 * 										workers: int = None,
 * 									):
 * 	ges_file_path_list, tract_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, tract_file_path_list ],             # <<<<<<<<<<<<<<
 * 	                                                                              [ str, ( str, type(None) ) ],
 * 	                                                                            )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 419, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 419, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 419, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_ges_file_path_list);
  __Pyx_GIVEREF(__pyx_v_ges_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_ges_file_path_list);
  __Pyx_INCREF(__pyx_v_tract_file_path_list);
  __Pyx_GIVEREF(__pyx_v_tract_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_tract_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":420
 * 									):
 * 	ges_file_path_list, tract_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, tract_file_path_list ],
 * 	                                                                              [ str, ( str, type(None) ) ],             # <<<<<<<<<<<<<<
 * 	                                                                            )
 * 	args = [ [ges_file_path, tract_file_path, return_data ]
 */
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_4, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_5 = PyList_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyList_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyList_SET_ITEM(__pyx_t_5, 1, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_5);
    __pyx_t_2 = 0;
    __pyx_t_5 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 419, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_7);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = Py_TYPE(__pyx_t_5)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_7 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_7)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_7);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_5), 2) < 0) __PYX_ERR(0, 419, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 419, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":419
 * 										workers: int = None,
 * 									):
 * 	ges_file_path_list, tract_file_path_list = FT.check_if_input_lists_are_valid( [ ges_file_path_list, tract_file_path_list ],             # <<<<<<<<<<<<<<
 * 	                                                                              [ str, ( str, type(None) ) ],
 * 	                                                                            )
 */
  __Pyx_DECREF_SET(__pyx_v_ges_file_path_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_tract_file_path_list, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":422
 * 	                                                                              [ str, ( str, type(None) ) ],
 * 	                                                                            )
 * 	args = [ [ges_file_path, tract_file_path, return_data ]             # <<<<<<<<<<<<<<
 * 		for ges_file_path, tract_file_path in itertools.zip_longest( ges_file_path_list, tract_file_path_list ) ]
 * 	tract_sequence_list = _run_multiprocessing( _gestural_score_to_tract_sequence, args, return_data, workers )
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 422, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":423
 * 	                                                                            )
 * 	args = [ [ges_file_path, tract_file_path, return_data ]
 * 		for ges_file_path, tract_file_path in itertools.zip_longest( ges_file_path_list, tract_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	tract_sequence_list = _run_multiprocessing( _gestural_score_to_tract_sequence, args, return_data, workers )
 * 	return tract_sequence_list
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_itertools); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_ges_file_path_list, __pyx_v_tract_file_path_list};
    __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_ges_file_path_list, __pyx_v_tract_file_path_list};
    __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_ges_file_path_list);
    __Pyx_GIVEREF(__pyx_v_ges_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_6, __pyx_v_ges_file_path_list);
    __Pyx_INCREF(__pyx_v_tract_file_path_list);
    __Pyx_GIVEREF(__pyx_v_tract_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_6, __pyx_v_tract_file_path_list);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (likely(PyList_CheckExact(__pyx_t_7)) || PyTuple_CheckExact(__pyx_t_7)) {
    __pyx_t_5 = __pyx_t_7; __Pyx_INCREF(__pyx_t_5); __pyx_t_9 = 0;
    __pyx_t_10 = NULL;
  } else {
    __pyx_t_9 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 423, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  for (;;) {
    if (likely(!__pyx_t_10)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_7); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 423, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_7); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 423, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_10(__pyx_t_5);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 423, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_7))) || (PyList_CheckExact(__pyx_t_7))) {
      PyObject* sequence = __pyx_t_7;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 423, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 423, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 423, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_4 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 423, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_8 = Py_TYPE(__pyx_t_4)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_3 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_3);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_4), 2) < 0) __PYX_ERR(0, 423, __pyx_L1_error)
      __pyx_t_8 = NULL;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_8 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 423, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_ges_file_path, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_tract_file_path, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":422
 * 	                                                                              [ str, ( str, type(None) ) ],
 * 	                                                                            )
 * 	args = [ [ges_file_path, tract_file_path, return_data ]             # <<<<<<<<<<<<<<
 * 		for ges_file_path, tract_file_path in itertools.zip_longest( ges_file_path_list, tract_file_path_list ) ]
 * 	tract_sequence_list = _run_multiprocessing( _gestural_score_to_tract_sequence, args, return_data, workers )
 */
    __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_return_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = PyList_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_v_ges_file_path);
    PyList_SET_ITEM(__pyx_t_3, 0, __pyx_v_ges_file_path);
    __Pyx_INCREF(__pyx_v_tract_file_path);
    __Pyx_GIVEREF(__pyx_v_tract_file_path);
    PyList_SET_ITEM(__pyx_t_3, 1, __pyx_v_tract_file_path);
    __Pyx_GIVEREF(__pyx_t_7);
    PyList_SET_ITEM(__pyx_t_3, 2, __pyx_t_7);
    __pyx_t_7 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_3))) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":423
 * 	                                                                            )
 * 	args = [ [ges_file_path, tract_file_path, return_data ]
 * 		for ges_file_path, tract_file_path in itertools.zip_longest( ges_file_path_list, tract_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	tract_sequence_list = _run_multiprocessing( _gestural_score_to_tract_sequence, args, return_data, workers )
 * 	return tract_sequence_list
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":424
 * 	args = [ [ges_file_path, tract_file_path, return_data ]
 * 		for ges_file_path, tract_file_path in itertools.zip_longest( ges_file_path_list, tract_file_path_list ) ]
 * 	tract_sequence_list = _run_multiprocessing( _gestural_score_to_tract_sequence, args, return_data, workers )             # <<<<<<<<<<<<<<
 * 	return tract_sequence_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 424, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_gestural_score_to_tract_sequenc); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 424, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_return_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 424, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[5] = {__pyx_t_2, __pyx_t_3, __pyx_v_args, __pyx_t_7, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[5] = {__pyx_t_2, __pyx_t_3, __pyx_v_args, __pyx_t_7, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else
  #endif
  {
    __pyx_t_4 = PyTuple_New(4+__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_6, __pyx_t_3);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_6, __pyx_v_args);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_6, __pyx_t_7);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_4, 3+__pyx_t_6, __pyx_v_workers);
    __pyx_t_3 = 0;
    __pyx_t_7 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_tract_sequence_list = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":425
 * 		for ges_file_path, tract_file_path in itertools.zip_longest( ges_file_path_list, tract_file_path_list ) ]
 * 	tract_sequence_list = _run_multiprocessing( _gestural_score_to_tract_sequence, args, return_data, workers )
 * 	return tract_sequence_list             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_tract_sequence_list);
  __pyx_r = __pyx_v_tract_sequence_list;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":414
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.gestural_score_to_tract_sequence", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_tract_sequence_list);
  __Pyx_XDECREF(__pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_v_tract_file_path);
  __Pyx_XDECREF(__pyx_v_ges_file_path_list);
  __Pyx_XDECREF(__pyx_v_tract_file_path_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":427
 * 	return tract_sequence_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,             # <<<<<<<<<<<<<<
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_27segment_sequence_to_gestural_score(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_27segment_sequence_to_gestural_score = {"segment_sequence_to_gestural_score", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_27segment_sequence_to_gestural_score, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_27segment_sequence_to_gestural_score(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_seg_file_path_list = 0;
  PyObject *__pyx_v_ges_file_path_list = 0;
  PyObject *__pyx_v_workers = 0;
  bool __pyx_v_verbose;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("segment_sequence_to_gestural_score (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_seg_file_path_list,&__pyx_n_s_ges_file_path_list,&__pyx_n_s_workers,&__pyx_n_s_verbose,0};
    PyObject* values[4] = {0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":428
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,
 * 	                                    ges_file_path_list = None,             # <<<<<<<<<<<<<<
 * 	                                    workers: int = None,
 * 	                                    verbose: bool = False,
 */
    values[1] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":429
 * def segment_sequence_to_gestural_score( seg_file_path_list,
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,             # <<<<<<<<<<<<<<
 * 	                                    verbose: bool = False,
 * 	                                    ):
 */
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_seg_file_path_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_ges_file_path_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_verbose);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "segment_sequence_to_gestural_score") < 0)) __PYX_ERR(0, 427, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_seg_file_path_list = values[0];
    __pyx_v_ges_file_path_list = values[1];
    __pyx_v_workers = values[2];
    if (values[3]) {
      __pyx_v_verbose = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_verbose == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":430
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,
 * 	                                    verbose: bool = False,             # <<<<<<<<<<<<<<
 * 	                                    ):
 * 	seg_file_path_list, ges_file_path_list = FT.check_if_input_lists_are_valid( [ seg_file_path_list, ges_file_path_list ],
 */
      __pyx_v_verbose = ((bool)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("segment_sequence_to_gestural_score", 0, 1, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 427, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.segment_sequence_to_gestural_score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_26segment_sequence_to_gestural_score(__pyx_self, __pyx_v_seg_file_path_list, __pyx_v_ges_file_path_list, __pyx_v_workers, __pyx_v_verbose);

  /* "VocalTractLab/VocalTractLabApi.pyx":427
 * 	return tract_sequence_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,             # <<<<<<<<<<<<<<
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_26segment_sequence_to_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_seg_file_path_list, PyObject *__pyx_v_ges_file_path_list, PyObject *__pyx_v_workers, bool __pyx_v_verbose) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_seg_file_path = NULL;
  PyObject *__pyx_v_ges_file_path = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("segment_sequence_to_gestural_score", 0);
  __Pyx_INCREF(__pyx_v_seg_file_path_list);
  __Pyx_INCREF(__pyx_v_ges_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":432
 * 	                                    verbose: bool = False,
 * 	                                    ):
 * 	seg_file_path_list, ges_file_path_list = FT.check_if_input_lists_are_valid( [ seg_file_path_list, ges_file_path_list ],             # <<<<<<<<<<<<<<
 * 	                                                                            [ str, ( str, type(None) ) ]
 * 	                                                                          )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 432, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 432, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 432, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_seg_file_path_list);
  __Pyx_GIVEREF(__pyx_v_seg_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_seg_file_path_list);
  __Pyx_INCREF(__pyx_v_ges_file_path_list);
  __Pyx_GIVEREF(__pyx_v_ges_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_ges_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":433
 * 	                                    ):
 * 	seg_file_path_list, ges_file_path_list = FT.check_if_input_lists_are_valid( [ seg_file_path_list, ges_file_path_list ],
 * 	                                                                            [ str, ( str, type(None) ) ]             # <<<<<<<<<<<<<<
 * 	                                                                          )
 * 	args = [ [ seg_file_path, ges_file_path, verbose ]
 */
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 433, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_4, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_5 = PyList_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 433, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyList_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyList_SET_ITEM(__pyx_t_5, 1, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_5);
    __pyx_t_2 = 0;
    __pyx_t_5 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 432, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_7);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = Py_TYPE(__pyx_t_5)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_7 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_7)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_7);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_5), 2) < 0) __PYX_ERR(0, 432, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 432, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":432
 * 	                                    verbose: bool = False,
 * 	                                    ):
 * 	seg_file_path_list, ges_file_path_list = FT.check_if_input_lists_are_valid( [ seg_file_path_list, ges_file_path_list ],             # <<<<<<<<<<<<<<
 * 	                                                                            [ str, ( str, type(None) ) ]
 * 	                                                                          )
 */
  __Pyx_DECREF_SET(__pyx_v_seg_file_path_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_ges_file_path_list, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":435
 * 	                                                                            [ str, ( str, type(None) ) ]
 * 	                                                                          )
 * 	args = [ [ seg_file_path, ges_file_path, verbose ]             # <<<<<<<<<<<<<<
 * 		for seg_file_path, ges_file_path in itertools.zip_longest( seg_file_path_list, ges_file_path_list ) ]
 * 	_run_multiprocessing( _segment_sequence_to_gestural_score, args, False, workers )
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 435, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":436
 * 	                                                                          )
 * 	args = [ [ seg_file_path, ges_file_path, verbose ]
 * 		for seg_file_path, ges_file_path in itertools.zip_longest( seg_file_path_list, ges_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	_run_multiprocessing( _segment_sequence_to_gestural_score, args, False, workers )
 * 	return
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_itertools); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 436, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 436, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_seg_file_path_list, __pyx_v_ges_file_path_list};
    __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 436, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_seg_file_path_list, __pyx_v_ges_file_path_list};
    __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 436, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 436, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_seg_file_path_list);
    __Pyx_GIVEREF(__pyx_v_seg_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_6, __pyx_v_seg_file_path_list);
    __Pyx_INCREF(__pyx_v_ges_file_path_list);
    __Pyx_GIVEREF(__pyx_v_ges_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_6, __pyx_v_ges_file_path_list);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 436, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (likely(PyList_CheckExact(__pyx_t_7)) || PyTuple_CheckExact(__pyx_t_7)) {
    __pyx_t_5 = __pyx_t_7; __Pyx_INCREF(__pyx_t_5); __pyx_t_9 = 0;
    __pyx_t_10 = NULL;
  } else {
    __pyx_t_9 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 436, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 436, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  for (;;) {
    if (likely(!__pyx_t_10)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_7); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 436, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 436, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_7); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 436, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 436, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_10(__pyx_t_5);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 436, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_7))) || (PyList_CheckExact(__pyx_t_7))) {
      PyObject* sequence = __pyx_t_7;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 436, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 436, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 436, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_4 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 436, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_8 = Py_TYPE(__pyx_t_4)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_3 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_3);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_4), 2) < 0) __PYX_ERR(0, 436, __pyx_L1_error)
      __pyx_t_8 = NULL;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_8 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 436, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_seg_file_path, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_ges_file_path, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":435
 * 	                                                                            [ str, ( str, type(None) ) ]
 * 	                                                                          )
 * 	args = [ [ seg_file_path, ges_file_path, verbose ]             # <<<<<<<<<<<<<<
 * 		for seg_file_path, ges_file_path in itertools.zip_longest( seg_file_path_list, ges_file_path_list ) ]
 * 	_run_multiprocessing( _segment_sequence_to_gestural_score, args, False, workers )
 */
    __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_verbose); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 435, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = PyList_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 435, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_seg_file_path);
    __Pyx_GIVEREF(__pyx_v_seg_file_path);
    PyList_SET_ITEM(__pyx_t_3, 0, __pyx_v_seg_file_path);
    __Pyx_INCREF(__pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_v_ges_file_path);
    PyList_SET_ITEM(__pyx_t_3, 1, __pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_t_7);
    PyList_SET_ITEM(__pyx_t_3, 2, __pyx_t_7);
    __pyx_t_7 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_3))) __PYX_ERR(0, 435, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":436
 * 	                                                                          )
 * 	args = [ [ seg_file_path, ges_file_path, verbose ]
 * 		for seg_file_path, ges_file_path in itertools.zip_longest( seg_file_path_list, ges_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	_run_multiprocessing( _segment_sequence_to_gestural_score, args, False, workers )
 * 	return
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":437
 * 	args = [ [ seg_file_path, ges_file_path, verbose ]
 * 		for seg_file_path, ges_file_path in itertools.zip_longest( seg_file_path_list, ges_file_path_list ) ]
 * 	_run_multiprocessing( _segment_sequence_to_gestural_score, args, False, workers )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_segment_sequence_to_gestural_sc); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_7 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_3, __pyx_v_args, Py_False, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 437, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_3, __pyx_v_args, Py_False, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 437, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(4+__pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 437, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_7) {
      __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7); __pyx_t_7 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_6, __pyx_t_3);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_6, __pyx_v_args);
    __Pyx_INCREF(Py_False);
    __Pyx_GIVEREF(Py_False);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_6, Py_False);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_2, 3+__pyx_t_6, __pyx_v_workers);
    __pyx_t_3 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 437, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":438
 * 		for seg_file_path, ges_file_path in itertools.zip_longest( seg_file_path_list, ges_file_path_list ) ]
 * 	_run_multiprocessing( _segment_sequence_to_gestural_score, args, False, workers )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":427
 * 	return tract_sequence_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,             # <<<<<<<<<<<<<<
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.segment_sequence_to_gestural_score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_seg_file_path);
  __Pyx_XDECREF(__pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_v_seg_file_path_list);
  __Pyx_XDECREF(__pyx_v_ges_file_path_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":440
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                         audio_file_path_list = None,
 * 	                         save_file: bool = True,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_29tract_sequence_to_audio(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_29tract_sequence_to_audio = {"tract_sequence_to_audio", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_29tract_sequence_to_audio, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_29tract_sequence_to_audio(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence_list = 0;
  PyObject *__pyx_v_audio_file_path_list = 0;
  bool __pyx_v_save_file;
  PyObject *__pyx_v_normalize_audio = 0;
  PyObject *__pyx_v_sr = 0;
  bool __pyx_v_return_data;
  PyObject *__pyx_v_workers = 0;
  bool __pyx_v_verbose;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tract_sequence_to_audio (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence_list,&__pyx_n_s_audio_file_path_list,&__pyx_n_s_save_file,&__pyx_n_s_normalize_audio,&__pyx_n_s_sr,&__pyx_n_s_return_data,&__pyx_n_s_workers,&__pyx_n_s_verbose,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":441
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,
 * 	                         audio_file_path_list = None,             # <<<<<<<<<<<<<<
 * 	                         save_file: bool = True,
 * 	                         normalize_audio: int = -1,
 */
    values[1] = ((PyObject *)Py_None);
    values[3] = ((PyObject *)__pyx_int_neg_1);

    /* "VocalTractLab/VocalTractLabApi.pyx":444
 * 	                         save_file: bool = True,
 * 	                         normalize_audio: int = -1,
 * 	                         sr: int = None,             # <<<<<<<<<<<<<<
 * 	                         return_data: bool = False,
 * 	                         workers: int = None,
 */
    values[4] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":446
 * 	                         sr: int = None,
 * 	                         return_data: bool = False,
 * 	                         workers: int = None,             # <<<<<<<<<<<<<<
 * 	                         verbose: bool = False,
 * 	                         ):
 */
    values[6] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_audio_file_path_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_file);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_normalize_audio);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_sr);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_data);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_verbose);
          if (value) { values[7] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "tract_sequence_to_audio") < 0)) __PYX_ERR(0, 440, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence_list = values[0];
    __pyx_v_audio_file_path_list = values[1];
    if (values[2]) {
      __pyx_v_save_file = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_save_file == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 442, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":442
 * def tract_sequence_to_audio( motor_sequence_list,
 * 	                         audio_file_path_list = None,
 * 	                         save_file: bool = True,             # <<<<<<<<<<<<<<
 * 	                         normalize_audio: int = -1,
 * 	                         sr: int = None,
 */
      __pyx_v_save_file = ((bool)1);
    }
    __pyx_v_normalize_audio = values[3];
    __pyx_v_sr = values[4];
    if (values[5]) {
      __pyx_v_return_data = __Pyx_PyObject_IsTrue(values[5]); if (unlikely((__pyx_v_return_data == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 445, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":445
 * 	                         normalize_audio: int = -1,
 * 	                         sr: int = None,
 * 	                         return_data: bool = False,             # <<<<<<<<<<<<<<
 * 	                         workers: int = None,
 * 	                         verbose: bool = False,
 */
      __pyx_v_return_data = ((bool)0);
    }
    __pyx_v_workers = values[6];
    if (values[7]) {
      __pyx_v_verbose = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_verbose == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 447, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":447
 * 	                         return_data: bool = False,
 * 	                         workers: int = None,
 * 	                         verbose: bool = False,             # <<<<<<<<<<<<<<
 * 	                         ):
 * 	motor_sequence_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, audio_file_path_list ],
 */
      __pyx_v_verbose = ((bool)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("tract_sequence_to_audio", 0, 1, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 440, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_audio", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_28tract_sequence_to_audio(__pyx_self, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_save_file, __pyx_v_normalize_audio, __pyx_v_sr, __pyx_v_return_data, __pyx_v_workers, __pyx_v_verbose);

  /* "VocalTractLab/VocalTractLabApi.pyx":440
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                         audio_file_path_list = None,
 * 	                         save_file: bool = True,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_28tract_sequence_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_audio_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_audio_data_list = NULL;
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_arg = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *(*__pyx_t_8)(PyObject *);
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("tract_sequence_to_audio", 0);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":449
 * 	                         verbose: bool = False,
 * 	                         ):
 * 	motor_sequence_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, audio_file_path_list ],             # <<<<<<<<<<<<<<
 * 																		           [ ( str, Motor_Sequence, Motor_Score ),
 * 	                                                                                 ( str, type(None) ),
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);
  __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_audio_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":450
 * 	                         ):
 * 	motor_sequence_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, audio_file_path_list ],
 * 																		           [ ( str, Motor_Sequence, Motor_Score ),             # <<<<<<<<<<<<<<
 * 	                                                                                 ( str, type(None) ),
 * 	                                                                               ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_Motor_Score); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_5);
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":451
 * 	motor_sequence_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, audio_file_path_list ],
 * 																		           [ ( str, Motor_Sequence, Motor_Score ),
 * 	                                                                                 ( str, type(None) ),             # <<<<<<<<<<<<<<
 * 	                                                                               ]
 * 	                                                                             )
 */
  __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_5, 1, ((PyObject *)Py_TYPE(Py_None)));

  /* "VocalTractLab/VocalTractLabApi.pyx":450
 * 	                         ):
 * 	motor_sequence_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, audio_file_path_list ],
 * 																		           [ ( str, Motor_Sequence, Motor_Score ),             # <<<<<<<<<<<<<<
 * 	                                                                                 ( str, type(None) ),
 * 	                                                                               ]
 */
  __pyx_t_4 = PyList_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_6);
  PyList_SET_ITEM(__pyx_t_4, 0, __pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_5);
  PyList_SET_ITEM(__pyx_t_4, 1, __pyx_t_5);
  __pyx_t_6 = 0;
  __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_7 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_7 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_2, __pyx_t_4};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_2, __pyx_t_4};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_7, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_7, __pyx_t_4);
    __pyx_t_2 = 0;
    __pyx_t_4 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 449, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_6 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_6 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_6);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 449, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_6 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_6)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_6);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_4), 2) < 0) __PYX_ERR(0, 449, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 449, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":449
 * 	                         verbose: bool = False,
 * 	                         ):
 * 	motor_sequence_list, audio_file_path_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, audio_file_path_list ],             # <<<<<<<<<<<<<<
 * 																		           [ ( str, Motor_Sequence, Motor_Score ),
 * 	                                                                                 ( str, type(None) ),
 */
  __Pyx_DECREF_SET(__pyx_v_motor_sequence_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_audio_file_path_list, __pyx_t_6);
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":454
 * 	                                                                               ]
 * 	                                                                             )
 * 	args = [ [motor_sequence, audio_file_path, save_file, normalize_audio, sr, verbose]             # <<<<<<<<<<<<<<
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]
 * 	if len( args ) <= 4:
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":455
 * 	                                                                             )
 * 	args = [ [motor_sequence, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	if len( args ) <= 4:
 * 		audio_data_list = [ _tract_sequence_to_audio( arg ) for arg in args ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_itertools); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_7 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
      __pyx_t_7 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_4)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list};
    __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 455, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_6);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list};
    __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 455, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_6);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_motor_sequence_list);
    __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_7, __pyx_v_motor_sequence_list);
    __Pyx_INCREF(__pyx_v_audio_file_path_list);
    __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_7, __pyx_v_audio_file_path_list);
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_2, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
    __pyx_t_4 = __pyx_t_6; __Pyx_INCREF(__pyx_t_4); __pyx_t_9 = 0;
    __pyx_t_10 = NULL;
  } else {
    __pyx_t_9 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_10 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 455, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  for (;;) {
    if (likely(!__pyx_t_10)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 455, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_4, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 455, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      } else {
        if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 455, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_4, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 455, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      }
    } else {
      __pyx_t_6 = __pyx_t_10(__pyx_t_4);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 455, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_6);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_6))) || (PyList_CheckExact(__pyx_t_6))) {
      PyObject* sequence = __pyx_t_6;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 455, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_5 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 455, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_8 = Py_TYPE(__pyx_t_5)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_3 = __pyx_t_8(__pyx_t_5); if (unlikely(!__pyx_t_3)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_3);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_5), 2) < 0) __PYX_ERR(0, 455, __pyx_L1_error)
      __pyx_t_8 = NULL;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_8 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 455, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_motor_sequence, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_audio_file_path, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":454
 * 	                                                                               ]
 * 	                                                                             )
 * 	args = [ [motor_sequence, audio_file_path, save_file, normalize_audio, sr, verbose]             # <<<<<<<<<<<<<<
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]
 * 	if len( args ) <= 4:
 */
    __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_save_file); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 454, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_v_verbose); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 454, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = PyList_New(6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 454, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_motor_sequence);
    __Pyx_GIVEREF(__pyx_v_motor_sequence);
    PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_motor_sequence);
    __Pyx_INCREF(__pyx_v_audio_file_path);
    __Pyx_GIVEREF(__pyx_v_audio_file_path);
    PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_audio_file_path);
    __Pyx_GIVEREF(__pyx_t_6);
    PyList_SET_ITEM(__pyx_t_2, 2, __pyx_t_6);
    __Pyx_INCREF(__pyx_v_normalize_audio);
    __Pyx_GIVEREF(__pyx_v_normalize_audio);
    PyList_SET_ITEM(__pyx_t_2, 3, __pyx_v_normalize_audio);
    __Pyx_INCREF(__pyx_v_sr);
    __Pyx_GIVEREF(__pyx_v_sr);
    PyList_SET_ITEM(__pyx_t_2, 4, __pyx_v_sr);
    __Pyx_GIVEREF(__pyx_t_3);
    PyList_SET_ITEM(__pyx_t_2, 5, __pyx_t_3);
    __pyx_t_6 = 0;
    __pyx_t_3 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_2))) __PYX_ERR(0, 454, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":455
 * 	                                                                             )
 * 	args = [ [motor_sequence, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]             # <<<<<<<<<<<<<<
 * 	if len( args ) <= 4:
 * 		audio_data_list = [ _tract_sequence_to_audio( arg ) for arg in args ]
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":456
 * 	args = [ [motor_sequence, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]
 * 	if len( args ) <= 4:             # <<<<<<<<<<<<<<
 * 		audio_data_list = [ _tract_sequence_to_audio( arg ) for arg in args ]
 * 	else:
 */
  __pyx_t_9 = PyList_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 456, __pyx_L1_error)
  __pyx_t_11 = ((__pyx_t_9 <= 4) != 0);
  if (__pyx_t_11) {

    /* "VocalTractLab/VocalTractLabApi.pyx":457
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]
 * 	if len( args ) <= 4:
 * 		audio_data_list = [ _tract_sequence_to_audio( arg ) for arg in args ]             # <<<<<<<<<<<<<<
 * 	else:
 * 		audio_data_list = _run_multiprocessing( _tract_sequence_to_audio, args, return_data, workers )
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 457, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __pyx_v_args; __Pyx_INCREF(__pyx_t_4); __pyx_t_9 = 0;
    for (;;) {
      if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_4)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_2 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_9); __Pyx_INCREF(__pyx_t_2); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 457, __pyx_L1_error)
      #else
      __pyx_t_2 = PySequence_ITEM(__pyx_t_4, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 457, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_2);
      __pyx_t_2 = 0;
      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_tract_sequence_to_audio); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 457, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      __pyx_t_2 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_6, __pyx_v_arg) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_arg);
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 457, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_2))) __PYX_ERR(0, 457, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_v_audio_data_list = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":456
 * 	args = [ [motor_sequence, audio_file_path, save_file, normalize_audio, sr, verbose]
 * 		for motor_sequence, audio_file_path in itertools.zip_longest( motor_sequence_list, audio_file_path_list ) ]
 * 	if len( args ) <= 4:             # <<<<<<<<<<<<<<
 * 		audio_data_list = [ _tract_sequence_to_audio( arg ) for arg in args ]
 * 	else:
 */
    goto __pyx_L9;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":459
 * 		audio_data_list = [ _tract_sequence_to_audio( arg ) for arg in args ]
 * 	else:
 * 		audio_data_list = _run_multiprocessing( _tract_sequence_to_audio, args, return_data, workers )             # <<<<<<<<<<<<<<
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 459, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_tract_sequence_to_audio); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 459, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_v_return_data); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 459, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = NULL;
    __pyx_t_7 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_7 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[5] = {__pyx_t_6, __pyx_t_2, __pyx_v_args, __pyx_t_3, __pyx_v_workers};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 4+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[5] = {__pyx_t_6, __pyx_t_2, __pyx_v_args, __pyx_t_3, __pyx_v_workers};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 4+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(4+__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_7, __pyx_t_2);
      __Pyx_INCREF(__pyx_v_args);
      __Pyx_GIVEREF(__pyx_v_args);
      PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_7, __pyx_v_args);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_7, __pyx_t_3);
      __Pyx_INCREF(__pyx_v_workers);
      __Pyx_GIVEREF(__pyx_v_workers);
      PyTuple_SET_ITEM(__pyx_t_5, 3+__pyx_t_7, __pyx_v_workers);
      __pyx_t_2 = 0;
      __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_v_audio_data_list = __pyx_t_1;
    __pyx_t_1 = 0;
  }
  __pyx_L9:;

  /* "VocalTractLab/VocalTractLabApi.pyx":460
 * 	else:
 * 		audio_data_list = _run_multiprocessing( _tract_sequence_to_audio, args, return_data, workers )
 * 	return audio_data_list             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_spectrogram(
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_audio_data_list);
  __pyx_r = __pyx_v_audio_data_list;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":440
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                         audio_file_path_list = None,
 * 	                         save_file: bool = True,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_audio", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_audio_data_list);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_XDECREF(__pyx_v_motor_sequence_list);
  __Pyx_XDECREF(__pyx_v_audio_file_path_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":462
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_spectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_31motor_sequence_to_spectrogram(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_31motor_sequence_to_spectrogram = {"motor_sequence_to_spectrogram", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_31motor_sequence_to_spectrogram, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_31motor_sequence_to_spectrogram(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence_list = 0;
  PyObject *__pyx_v_audio_file_path_list = 0;
  PyObject *__pyx_v_spectrogram_file_path_list = 0;
  bool __pyx_v_save_file;
  PyObject *__pyx_v_normalize_audio = 0;
  PyObject *__pyx_v_sr = 0;
  PyObject *__pyx_v_spectrogram_kwargs = 0;
  bool __pyx_v_return_data;
  PyObject *__pyx_v_workers = 0;
  bool __pyx_v_verbose;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("motor_sequence_to_spectrogram (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence_list,&__pyx_n_s_audio_file_path_list,&__pyx_n_s_spectrogram_file_path_list,&__pyx_n_s_save_file,&__pyx_n_s_normalize_audio,&__pyx_n_s_sr,&__pyx_n_s_spectrogram_kwargs,&__pyx_n_s_return_data,&__pyx_n_s_workers,&__pyx_n_s_verbose,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":464
 * def motor_sequence_to_spectrogram(
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,             # <<<<<<<<<<<<<<
 * 	spectrogram_file_path_list = None,
 * 	save_file: bool = True,
 */
    values[1] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":465
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 * 	spectrogram_file_path_list = None,             # <<<<<<<<<<<<<<
 * 	save_file: bool = True,
 * 	normalize_audio: int = -1,
 */
    values[2] = ((PyObject *)Py_None);
    values[4] = ((PyObject *)__pyx_int_neg_1);
    values[5] = ((PyObject *)__pyx_int_16000);
    values[6] = __pyx_k__10;

    /* "VocalTractLab/VocalTractLabApi.pyx":471
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,
 * 	return_data: bool = True,
 * 	workers: int = None,             # <<<<<<<<<<<<<<
 * 	verbose: bool = False,
 * 	):
 */
    values[8] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_audio_file_path_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_spectrogram_file_path_list);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_file);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_normalize_audio);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_sr);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_spectrogram_kwargs);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_data);
          if (value) { values[7] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[8] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_verbose);
          if (value) { values[9] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "motor_sequence_to_spectrogram") < 0)) __PYX_ERR(0, 462, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence_list = values[0];
    __pyx_v_audio_file_path_list = values[1];
    __pyx_v_spectrogram_file_path_list = values[2];
    if (values[3]) {
      __pyx_v_save_file = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_save_file == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 466, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":466
 * 	audio_file_path_list = None,
 * 	spectrogram_file_path_list = None,
 * 	save_file: bool = True,             # <<<<<<<<<<<<<<
 * 	normalize_audio: int = -1,
 * 	sr: int = 16000,
 */
      __pyx_v_save_file = ((bool)1);
    }
    __pyx_v_normalize_audio = values[4];
    __pyx_v_sr = values[5];
    __pyx_v_spectrogram_kwargs = values[6];
    if (values[7]) {
      __pyx_v_return_data = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_return_data == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 470, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":470
 * 	sr: int = 16000,
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,
 * 	return_data: bool = True,             # <<<<<<<<<<<<<<
 * 	workers: int = None,
 * 	verbose: bool = False,
 */
      __pyx_v_return_data = ((bool)1);
    }
    __pyx_v_workers = values[8];
    if (values[9]) {
      __pyx_v_verbose = __Pyx_PyObject_IsTrue(values[9]); if (unlikely((__pyx_v_verbose == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 472, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":472
 * 	return_data: bool = True,
 * 	workers: int = None,
 * 	verbose: bool = False,             # <<<<<<<<<<<<<<
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(
 */
      __pyx_v_verbose = ((bool)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("motor_sequence_to_spectrogram", 0, 1, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 462, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.motor_sequence_to_spectrogram", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_30motor_sequence_to_spectrogram(__pyx_self, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_spectrogram_file_path_list, __pyx_v_save_file, __pyx_v_normalize_audio, __pyx_v_sr, __pyx_v_spectrogram_kwargs, __pyx_v_return_data, __pyx_v_workers, __pyx_v_verbose);

  /* "VocalTractLab/VocalTractLabApi.pyx":462
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_spectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_30motor_sequence_to_spectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_audio_file_path_list, PyObject *__pyx_v_spectrogram_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, PyObject *__pyx_v_spectrogram_kwargs, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_audio_data_list = NULL;
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_spectrogram_file_path = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  Py_ssize_t __pyx_t_10;
  PyObject *(*__pyx_t_11)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("motor_sequence_to_spectrogram", 0);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);
  __Pyx_INCREF(__pyx_v_spectrogram_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":474
 * 	verbose: bool = False,
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(             # <<<<<<<<<<<<<<
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":475
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],             # <<<<<<<<<<<<<<
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 * 	)
 */
  __pyx_t_2 = PyList_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 475, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);
  __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_audio_file_path_list);
  __Pyx_INCREF(__pyx_v_spectrogram_file_path_list);
  __Pyx_GIVEREF(__pyx_v_spectrogram_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 2, __pyx_v_spectrogram_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":476
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]             # <<<<<<<<<<<<<<
 * 	)
 * 	args = [ [
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_Motor_Score); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_5);
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;
  __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_5, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_4, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_7 = PyList_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_6);
  PyList_SET_ITEM(__pyx_t_7, 0, __pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_5);
  PyList_SET_ITEM(__pyx_t_7, 1, __pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_4);
  PyList_SET_ITEM(__pyx_t_7, 2, __pyx_t_4);
  __pyx_t_6 = 0;
  __pyx_t_5 = 0;
  __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_7};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_7};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_8, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_8, __pyx_t_7);
    __pyx_t_2 = 0;
    __pyx_t_7 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 474, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_7);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_9 = Py_TYPE(__pyx_t_2)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_9(__pyx_t_2); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_5 = __pyx_t_9(__pyx_t_2); if (unlikely(!__pyx_t_5)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_5);
    index = 2; __pyx_t_7 = __pyx_t_9(__pyx_t_2); if (unlikely(!__pyx_t_7)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_7);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_9(__pyx_t_2), 3) < 0) __PYX_ERR(0, 474, __pyx_L1_error)
    __pyx_t_9 = NULL;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_9 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 474, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":474
 * 	verbose: bool = False,
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(             # <<<<<<<<<<<<<<
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 */
  __Pyx_DECREF_SET(__pyx_v_motor_sequence_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_audio_file_path_list, __pyx_t_5);
  __pyx_t_5 = 0;
  __Pyx_DECREF_SET(__pyx_v_spectrogram_file_path_list, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":478
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 * 	)
 * 	args = [ [             # <<<<<<<<<<<<<<
 * 		motor_sequence,
 * 		audio_file_path,
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":487
 * 		spectrogram_kwargs,
 * 		verbose,
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(             # <<<<<<<<<<<<<<
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_itertools); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":490
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 * 			spectrogram_file_path_list,             # <<<<<<<<<<<<<<
 * 		)
 * 	]
 */
  __pyx_t_5 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_spectrogram_file_path_list};
    __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_spectrogram_file_path_list};
    __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_motor_sequence_list);
    __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_8, __pyx_v_motor_sequence_list);
    __Pyx_INCREF(__pyx_v_audio_file_path_list);
    __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_8, __pyx_v_audio_file_path_list);
    __Pyx_INCREF(__pyx_v_spectrogram_file_path_list);
    __Pyx_GIVEREF(__pyx_v_spectrogram_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_8, __pyx_v_spectrogram_file_path_list);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":487
 * 		spectrogram_kwargs,
 * 		verbose,
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(             # <<<<<<<<<<<<<<
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 */
  if (likely(PyList_CheckExact(__pyx_t_7)) || PyTuple_CheckExact(__pyx_t_7)) {
    __pyx_t_3 = __pyx_t_7; __Pyx_INCREF(__pyx_t_3); __pyx_t_10 = 0;
    __pyx_t_11 = NULL;
  } else {
    __pyx_t_10 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_11 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 487, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  for (;;) {
    if (likely(!__pyx_t_11)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_7); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 487, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 487, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_7); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 487, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 487, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_11(__pyx_t_3);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 487, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_7))) || (PyList_CheckExact(__pyx_t_7))) {
      PyObject* sequence = __pyx_t_7;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 3)) {
        if (size > 3) __Pyx_RaiseTooManyValuesError(3);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 487, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
        __pyx_t_4 = PyTuple_GET_ITEM(sequence, 2); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
        __pyx_t_4 = PyList_GET_ITEM(sequence, 2); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 487, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 487, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_4 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 487, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      #endif
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_6 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 487, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_9 = Py_TYPE(__pyx_t_6)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_9(__pyx_t_6); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_5 = __pyx_t_9(__pyx_t_6); if (unlikely(!__pyx_t_5)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_5);
      index = 2; __pyx_t_4 = __pyx_t_9(__pyx_t_6); if (unlikely(!__pyx_t_4)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_4);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_9(__pyx_t_6), 3) < 0) __PYX_ERR(0, 487, __pyx_L1_error)
      __pyx_t_9 = NULL;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_9 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 487, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_motor_sequence, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_audio_file_path, __pyx_t_5);
    __pyx_t_5 = 0;
    __Pyx_XDECREF_SET(__pyx_v_spectrogram_file_path, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":482
 * 		audio_file_path,
 * 		spectrogram_file_path,
 * 		save_file,             # <<<<<<<<<<<<<<
 * 		normalize_audio,
 * 		sr,
 */
    __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_save_file); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 482, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);

    /* "VocalTractLab/VocalTractLabApi.pyx":486
 * 		sr,
 * 		spectrogram_kwargs,
 * 		verbose,             # <<<<<<<<<<<<<<
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(
 * 			motor_sequence_list,
 */
    __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_verbose); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 486, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);

    /* "VocalTractLab/VocalTractLabApi.pyx":478
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 * 	)
 * 	args = [ [             # <<<<<<<<<<<<<<
 * 		motor_sequence,
 * 		audio_file_path,
 */
    __pyx_t_5 = PyList_New(8); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v_motor_sequence);
    __Pyx_GIVEREF(__pyx_v_motor_sequence);
    PyList_SET_ITEM(__pyx_t_5, 0, __pyx_v_motor_sequence);
    __Pyx_INCREF(__pyx_v_audio_file_path);
    __Pyx_GIVEREF(__pyx_v_audio_file_path);
    PyList_SET_ITEM(__pyx_t_5, 1, __pyx_v_audio_file_path);
    __Pyx_INCREF(__pyx_v_spectrogram_file_path);
    __Pyx_GIVEREF(__pyx_v_spectrogram_file_path);
    PyList_SET_ITEM(__pyx_t_5, 2, __pyx_v_spectrogram_file_path);
    __Pyx_GIVEREF(__pyx_t_7);
    PyList_SET_ITEM(__pyx_t_5, 3, __pyx_t_7);
    __Pyx_INCREF(__pyx_v_normalize_audio);
    __Pyx_GIVEREF(__pyx_v_normalize_audio);
    PyList_SET_ITEM(__pyx_t_5, 4, __pyx_v_normalize_audio);
    __Pyx_INCREF(__pyx_v_sr);
    __Pyx_GIVEREF(__pyx_v_sr);
    PyList_SET_ITEM(__pyx_t_5, 5, __pyx_v_sr);
    __Pyx_INCREF(__pyx_v_spectrogram_kwargs);
    __Pyx_GIVEREF(__pyx_v_spectrogram_kwargs);
    PyList_SET_ITEM(__pyx_t_5, 6, __pyx_v_spectrogram_kwargs);
    __Pyx_GIVEREF(__pyx_t_4);
    PyList_SET_ITEM(__pyx_t_5, 7, __pyx_t_4);
    __pyx_t_7 = 0;
    __pyx_t_4 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(0, 478, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":487
 * 		spectrogram_kwargs,
 * 		verbose,
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(             # <<<<<<<<<<<<<<
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":493
 * 		)
 * 	]
 * 	audio_data_list = _run_multiprocessing( _motor_sequence_to_spectrogram, args, return_data, workers )             # <<<<<<<<<<<<<<
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_motor_sequence_to_spectrogram); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_return_data); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_5, __pyx_v_args, __pyx_t_4, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 4+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_5, __pyx_v_args, __pyx_t_4, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 4+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(4+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_7) {
      __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7); __pyx_t_7 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_8, __pyx_t_5);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_8, __pyx_v_args);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_8, __pyx_t_4);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_2, 3+__pyx_t_8, __pyx_v_workers);
    __pyx_t_5 = 0;
    __pyx_t_4 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_audio_data_list = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":494
 * 	]
 * 	audio_data_list = _run_multiprocessing( _motor_sequence_to_spectrogram, args, return_data, workers )
 * 	return audio_data_list             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_melspectrogram(
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_audio_data_list);
  __pyx_r = __pyx_v_audio_data_list;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":462
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_spectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.motor_sequence_to_spectrogram", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_audio_data_list);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_spectrogram_file_path);
  __Pyx_XDECREF(__pyx_v_motor_sequence_list);
  __Pyx_XDECREF(__pyx_v_audio_file_path_list);
  __Pyx_XDECREF(__pyx_v_spectrogram_file_path_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":496
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_melspectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_33motor_sequence_to_melspectrogram(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_33motor_sequence_to_melspectrogram = {"motor_sequence_to_melspectrogram", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_33motor_sequence_to_melspectrogram, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_33motor_sequence_to_melspectrogram(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence_list = 0;
  PyObject *__pyx_v_audio_file_path_list = 0;
  PyObject *__pyx_v_spectrogram_file_path_list = 0;
  bool __pyx_v_save_file;
  PyObject *__pyx_v_normalize_audio = 0;
  PyObject *__pyx_v_sr = 0;
  PyObject *__pyx_v_log_scale = 0;
  PyObject *__pyx_v_spectrogram_kwargs = 0;
  PyObject *__pyx_v_melspectrogram_kwargs = 0;
  bool __pyx_v_return_data;
  PyObject *__pyx_v_workers = 0;
  bool __pyx_v_verbose;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("motor_sequence_to_melspectrogram (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence_list,&__pyx_n_s_audio_file_path_list,&__pyx_n_s_spectrogram_file_path_list,&__pyx_n_s_save_file,&__pyx_n_s_normalize_audio,&__pyx_n_s_sr,&__pyx_n_s_log_scale,&__pyx_n_s_spectrogram_kwargs,&__pyx_n_s_melspectrogram_kwargs,&__pyx_n_s_return_data,&__pyx_n_s_workers,&__pyx_n_s_verbose,0};
    PyObject* values[12] = {0,0,0,0,0,0,0,0,0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":498
 * def motor_sequence_to_melspectrogram(
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,             # <<<<<<<<<<<<<<
 * 	spectrogram_file_path_list = None,
 * 	save_file: bool = True,
 */
    values[1] = ((PyObject *)Py_None);

    /* "VocalTractLab/VocalTractLabApi.pyx":499
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 * 	spectrogram_file_path_list = None,             # <<<<<<<<<<<<<<
 * 	save_file: bool = True,
 * 	normalize_audio: int = -1,
 */
    values[2] = ((PyObject *)Py_None);
    values[4] = ((PyObject *)__pyx_int_neg_1);
    values[5] = ((PyObject *)__pyx_int_16000);

    /* "VocalTractLab/VocalTractLabApi.pyx":503
 * 	normalize_audio: int = -1,
 * 	sr: int = 16000,
 * 	log_scale = True,             # <<<<<<<<<<<<<<
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,
 * 	melspectrogram_kwargs = AT.standard_16kHz_melspectrogram_80_kwargs,
 */
    values[6] = ((PyObject *)Py_True);
    values[7] = __pyx_k__11;
    values[8] = __pyx_k__12;

    /* "VocalTractLab/VocalTractLabApi.pyx":507
 * 	melspectrogram_kwargs = AT.standard_16kHz_melspectrogram_80_kwargs,
 * 	return_data: bool = True,
 * 	workers: int = None,             # <<<<<<<<<<<<<<
 * 	verbose: bool = False,
 * 	):
 */
    values[10] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 12: values[11] = PyTuple_GET_ITEM(__pyx_args, 11);
        CYTHON_FALLTHROUGH;
        case 11: values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
        CYTHON_FALLTHROUGH;
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_audio_file_path_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_spectrogram_file_path_list);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_file);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_normalize_audio);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_sr);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_log_scale);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_spectrogram_kwargs);
          if (value) { values[7] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_melspectrogram_kwargs);
          if (value) { values[8] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_data);
          if (value) { values[9] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case 10:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[10] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case 11:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_verbose);
          if (value) { values[11] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "motor_sequence_to_melspectrogram") < 0)) __PYX_ERR(0, 496, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case 12: values[11] = PyTuple_GET_ITEM(__pyx_args, 11);
        CYTHON_FALLTHROUGH;
        case 11: values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
        CYTHON_FALLTHROUGH;
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence_list = values[0];
    __pyx_v_audio_file_path_list = values[1];
    __pyx_v_spectrogram_file_path_list = values[2];
    if (values[3]) {
      __pyx_v_save_file = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_save_file == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 500, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":500
 * 	audio_file_path_list = None,
 * 	spectrogram_file_path_list = None,
 * 	save_file: bool = True,             # <<<<<<<<<<<<<<
 * 	normalize_audio: int = -1,
 * 	sr: int = 16000,
 */
      __pyx_v_save_file = ((bool)1);
    }
    __pyx_v_normalize_audio = values[4];
    __pyx_v_sr = values[5];
    __pyx_v_log_scale = values[6];
    __pyx_v_spectrogram_kwargs = values[7];
    __pyx_v_melspectrogram_kwargs = values[8];
    if (values[9]) {
      __pyx_v_return_data = __Pyx_PyObject_IsTrue(values[9]); if (unlikely((__pyx_v_return_data == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 506, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":506
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,
 * 	melspectrogram_kwargs = AT.standard_16kHz_melspectrogram_80_kwargs,
 * 	return_data: bool = True,             # <<<<<<<<<<<<<<
 * 	workers: int = None,
 * 	verbose: bool = False,
 */
      __pyx_v_return_data = ((bool)1);
    }
    __pyx_v_workers = values[10];
    if (values[11]) {
      __pyx_v_verbose = __Pyx_PyObject_IsTrue(values[11]); if (unlikely((__pyx_v_verbose == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 508, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":508
 * 	return_data: bool = True,
 * 	workers: int = None,
 * 	verbose: bool = False,             # <<<<<<<<<<<<<<
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(
 */
      __pyx_v_verbose = ((bool)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("motor_sequence_to_melspectrogram", 0, 1, 12, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 496, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.motor_sequence_to_melspectrogram", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_32motor_sequence_to_melspectrogram(__pyx_self, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_spectrogram_file_path_list, __pyx_v_save_file, __pyx_v_normalize_audio, __pyx_v_sr, __pyx_v_log_scale, __pyx_v_spectrogram_kwargs, __pyx_v_melspectrogram_kwargs, __pyx_v_return_data, __pyx_v_workers, __pyx_v_verbose);

  /* "VocalTractLab/VocalTractLabApi.pyx":496
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_melspectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_32motor_sequence_to_melspectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_audio_file_path_list, PyObject *__pyx_v_spectrogram_file_path_list, bool __pyx_v_save_file, PyObject *__pyx_v_normalize_audio, PyObject *__pyx_v_sr, PyObject *__pyx_v_log_scale, PyObject *__pyx_v_spectrogram_kwargs, PyObject *__pyx_v_melspectrogram_kwargs, bool __pyx_v_return_data, PyObject *__pyx_v_workers, bool __pyx_v_verbose) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_audio_data_list = NULL;
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_spectrogram_file_path = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  Py_ssize_t __pyx_t_10;
  PyObject *(*__pyx_t_11)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("motor_sequence_to_melspectrogram", 0);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);
  __Pyx_INCREF(__pyx_v_spectrogram_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":510
 * 	verbose: bool = False,
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(             # <<<<<<<<<<<<<<
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":511
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],             # <<<<<<<<<<<<<<
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 * 	)
 */
  __pyx_t_2 = PyList_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_audio_file_path_list);
  __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_audio_file_path_list);
  __Pyx_INCREF(__pyx_v_spectrogram_file_path_list);
  __Pyx_GIVEREF(__pyx_v_spectrogram_file_path_list);
  PyList_SET_ITEM(__pyx_t_2, 2, __pyx_v_spectrogram_file_path_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":512
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]             # <<<<<<<<<<<<<<
 * 	)
 * 	args = [ [
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_Motor_Score); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_5);
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;
  __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_5, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_4, 1, ((PyObject *)Py_TYPE(Py_None)));
  __pyx_t_7 = PyList_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_6);
  PyList_SET_ITEM(__pyx_t_7, 0, __pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_5);
  PyList_SET_ITEM(__pyx_t_7, 1, __pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_4);
  PyList_SET_ITEM(__pyx_t_7, 2, __pyx_t_4);
  __pyx_t_6 = 0;
  __pyx_t_5 = 0;
  __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_7};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_7};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_8, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_8, __pyx_t_7);
    __pyx_t_2 = 0;
    __pyx_t_7 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 510, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_7);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_9 = Py_TYPE(__pyx_t_2)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_9(__pyx_t_2); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_5 = __pyx_t_9(__pyx_t_2); if (unlikely(!__pyx_t_5)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_5);
    index = 2; __pyx_t_7 = __pyx_t_9(__pyx_t_2); if (unlikely(!__pyx_t_7)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_7);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_9(__pyx_t_2), 3) < 0) __PYX_ERR(0, 510, __pyx_L1_error)
    __pyx_t_9 = NULL;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_9 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 510, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":510
 * 	verbose: bool = False,
 * 	):
 * 	motor_sequence_list, audio_file_path_list, spectrogram_file_path_list = FT.check_if_input_lists_are_valid(             # <<<<<<<<<<<<<<
 * 		[ motor_sequence_list, audio_file_path_list, spectrogram_file_path_list ],
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 */
  __Pyx_DECREF_SET(__pyx_v_motor_sequence_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_audio_file_path_list, __pyx_t_5);
  __pyx_t_5 = 0;
  __Pyx_DECREF_SET(__pyx_v_spectrogram_file_path_list, __pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":514
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 * 	)
 * 	args = [ [             # <<<<<<<<<<<<<<
 * 		motor_sequence,
 * 		audio_file_path,
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 514, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":525
 * 		melspectrogram_kwargs,
 * 		verbose,
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(             # <<<<<<<<<<<<<<
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_itertools); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":528
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 * 			spectrogram_file_path_list,             # <<<<<<<<<<<<<<
 * 		)
 * 	]
 */
  __pyx_t_5 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_spectrogram_file_path_list};
    __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 525, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_v_motor_sequence_list, __pyx_v_audio_file_path_list, __pyx_v_spectrogram_file_path_list};
    __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 3+__pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 525, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 525, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_motor_sequence_list);
    __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_8, __pyx_v_motor_sequence_list);
    __Pyx_INCREF(__pyx_v_audio_file_path_list);
    __Pyx_GIVEREF(__pyx_v_audio_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_8, __pyx_v_audio_file_path_list);
    __Pyx_INCREF(__pyx_v_spectrogram_file_path_list);
    __Pyx_GIVEREF(__pyx_v_spectrogram_file_path_list);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_8, __pyx_v_spectrogram_file_path_list);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 525, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":525
 * 		melspectrogram_kwargs,
 * 		verbose,
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(             # <<<<<<<<<<<<<<
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 */
  if (likely(PyList_CheckExact(__pyx_t_7)) || PyTuple_CheckExact(__pyx_t_7)) {
    __pyx_t_3 = __pyx_t_7; __Pyx_INCREF(__pyx_t_3); __pyx_t_10 = 0;
    __pyx_t_11 = NULL;
  } else {
    __pyx_t_10 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 525, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_11 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 525, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  for (;;) {
    if (likely(!__pyx_t_11)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_7); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 525, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 525, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_7); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 525, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 525, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_11(__pyx_t_3);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 525, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_7))) || (PyList_CheckExact(__pyx_t_7))) {
      PyObject* sequence = __pyx_t_7;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 3)) {
        if (size > 3) __Pyx_RaiseTooManyValuesError(3);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 525, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
        __pyx_t_4 = PyTuple_GET_ITEM(sequence, 2); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
        __pyx_t_4 = PyList_GET_ITEM(sequence, 2); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 525, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 525, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_4 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 525, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      #endif
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_6 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 525, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_9 = Py_TYPE(__pyx_t_6)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_9(__pyx_t_6); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_5 = __pyx_t_9(__pyx_t_6); if (unlikely(!__pyx_t_5)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_5);
      index = 2; __pyx_t_4 = __pyx_t_9(__pyx_t_6); if (unlikely(!__pyx_t_4)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_4);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_9(__pyx_t_6), 3) < 0) __PYX_ERR(0, 525, __pyx_L1_error)
      __pyx_t_9 = NULL;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_9 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 525, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_motor_sequence, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_audio_file_path, __pyx_t_5);
    __pyx_t_5 = 0;
    __Pyx_XDECREF_SET(__pyx_v_spectrogram_file_path, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":518
 * 		audio_file_path,
 * 		spectrogram_file_path,
 * 		save_file,             # <<<<<<<<<<<<<<
 * 		normalize_audio,
 * 		sr,
 */
    __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_save_file); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 518, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);

    /* "VocalTractLab/VocalTractLabApi.pyx":524
 * 		spectrogram_kwargs,
 * 		melspectrogram_kwargs,
 * 		verbose,             # <<<<<<<<<<<<<<
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(
 * 			motor_sequence_list,
 */
    __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_verbose); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 524, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);

    /* "VocalTractLab/VocalTractLabApi.pyx":514
 * 		[ ( str, Motor_Sequence, Motor_Score ), ( str, type(None) ), ( str, type(None) ), ]
 * 	)
 * 	args = [ [             # <<<<<<<<<<<<<<
 * 		motor_sequence,
 * 		audio_file_path,
 */
    __pyx_t_5 = PyList_New(10); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 514, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v_motor_sequence);
    __Pyx_GIVEREF(__pyx_v_motor_sequence);
    PyList_SET_ITEM(__pyx_t_5, 0, __pyx_v_motor_sequence);
    __Pyx_INCREF(__pyx_v_audio_file_path);
    __Pyx_GIVEREF(__pyx_v_audio_file_path);
    PyList_SET_ITEM(__pyx_t_5, 1, __pyx_v_audio_file_path);
    __Pyx_INCREF(__pyx_v_spectrogram_file_path);
    __Pyx_GIVEREF(__pyx_v_spectrogram_file_path);
    PyList_SET_ITEM(__pyx_t_5, 2, __pyx_v_spectrogram_file_path);
    __Pyx_GIVEREF(__pyx_t_7);
    PyList_SET_ITEM(__pyx_t_5, 3, __pyx_t_7);
    __Pyx_INCREF(__pyx_v_normalize_audio);
    __Pyx_GIVEREF(__pyx_v_normalize_audio);
    PyList_SET_ITEM(__pyx_t_5, 4, __pyx_v_normalize_audio);
    __Pyx_INCREF(__pyx_v_sr);
    __Pyx_GIVEREF(__pyx_v_sr);
    PyList_SET_ITEM(__pyx_t_5, 5, __pyx_v_sr);
    __Pyx_INCREF(__pyx_v_log_scale);
    __Pyx_GIVEREF(__pyx_v_log_scale);
    PyList_SET_ITEM(__pyx_t_5, 6, __pyx_v_log_scale);
    __Pyx_INCREF(__pyx_v_spectrogram_kwargs);
    __Pyx_GIVEREF(__pyx_v_spectrogram_kwargs);
    PyList_SET_ITEM(__pyx_t_5, 7, __pyx_v_spectrogram_kwargs);
    __Pyx_INCREF(__pyx_v_melspectrogram_kwargs);
    __Pyx_GIVEREF(__pyx_v_melspectrogram_kwargs);
    PyList_SET_ITEM(__pyx_t_5, 8, __pyx_v_melspectrogram_kwargs);
    __Pyx_GIVEREF(__pyx_t_4);
    PyList_SET_ITEM(__pyx_t_5, 9, __pyx_t_4);
    __pyx_t_7 = 0;
    __pyx_t_4 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(0, 514, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":525
 * 		melspectrogram_kwargs,
 * 		verbose,
 * 		] for motor_sequence, audio_file_path, spectrogram_file_path in itertools.zip_longest(             # <<<<<<<<<<<<<<
 * 			motor_sequence_list,
 * 			audio_file_path_list,
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":531
 * 		)
 * 	]
 * 	audio_data_list = _run_multiprocessing( _motor_sequence_to_melspectrogram, args, return_data, workers )             # <<<<<<<<<<<<<<
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 531, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_motor_sequence_to_melspectrogra); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 531, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_return_data); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 531, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = NULL;
  __pyx_t_8 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_5, __pyx_v_args, __pyx_t_4, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 4+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 531, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[5] = {__pyx_t_7, __pyx_t_5, __pyx_v_args, __pyx_t_4, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_8, 4+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 531, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(4+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 531, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_7) {
      __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7); __pyx_t_7 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_8, __pyx_t_5);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_8, __pyx_v_args);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_8, __pyx_t_4);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_2, 3+__pyx_t_8, __pyx_v_workers);
    __pyx_t_5 = 0;
    __pyx_t_4 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 531, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_audio_data_list = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":532
 * 	]
 * 	audio_data_list = _run_multiprocessing( _motor_sequence_to_melspectrogram, args, return_data, workers )
 * 	return audio_data_list             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_audio_data_list);
  __pyx_r = __pyx_v_audio_data_list;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":496
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_melspectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.motor_sequence_to_melspectrogram", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_audio_data_list);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_spectrogram_file_path);
  __Pyx_XDECREF(__pyx_v_motor_sequence_list);
  __Pyx_XDECREF(__pyx_v_audio_file_path_list);
  __Pyx_XDECREF(__pyx_v_spectrogram_file_path_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":534
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                          workers: int = None,
 * 	                                        ):
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_35tract_sequence_to_limited_tract_sequence(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_35tract_sequence_to_limited_tract_sequence = {"tract_sequence_to_limited_tract_sequence", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_35tract_sequence_to_limited_tract_sequence, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_35tract_sequence_to_limited_tract_sequence(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence = 0;
  PyObject *__pyx_v_workers = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tract_sequence_to_limited_tract_sequence (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence,&__pyx_n_s_workers,0};
    PyObject* values[2] = {0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":535
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,
 * 	                                          workers: int = None,             # <<<<<<<<<<<<<<
 * 	                                        ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 */
    values[1] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "tract_sequence_to_limited_tract_sequence") < 0)) __PYX_ERR(0, 534, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence = values[0];
    __pyx_v_workers = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("tract_sequence_to_limited_tract_sequence", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 534, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_limited_tract_sequence", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_34tract_sequence_to_limited_tract_sequence(__pyx_self, __pyx_v_motor_sequence, __pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":534
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                          workers: int = None,
 * 	                                        ):
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_34tract_sequence_to_limited_tract_sequence(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence, PyObject *__pyx_v_workers) {
  PyObject *__pyx_v_tract_param_data = NULL;
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_limited_supra_glottal_sequence = NULL;
  PyObject *__pyx_v_state = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("tract_sequence_to_limited_tract_sequence", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":537
 * 	                                          workers: int = None,
 * 	                                        ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	tract_param_data = []
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 537, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 537, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_1); 
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (!__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_5 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_2); 
  __pyx_t_4 = (__pyx_t_5 != 0);
  __pyx_t_3 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = ((!(__pyx_t_3 != 0)) != 0);
  if (unlikely(__pyx_t_4)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":538
 * 	                                        ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )             # <<<<<<<<<<<<<<
 * 	tract_param_data = []
 * 	args = [ state for state in motor_sequence.states.to_numpy() ]
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_motor_sequence_argument_must_be, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 538, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_6, ((PyObject *)Py_TYPE(__pyx_v_motor_sequence))) : __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)Py_TYPE(__pyx_v_motor_sequence)));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 538, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 538, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 538, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":537
 * 	                                          workers: int = None,
 * 	                                        ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	tract_param_data = []
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":539
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	tract_param_data = []             # <<<<<<<<<<<<<<
 * 	args = [ state for state in motor_sequence.states.to_numpy() ]
 * 	tract_param_data = _run_multiprocessing( _tract_state_to_limited_tract_state, args, True, workers )
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 539, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_v_tract_param_data = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":540
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	tract_param_data = []
 * 	args = [ state for state in motor_sequence.states.to_numpy() ]             # <<<<<<<<<<<<<<
 * 	tract_param_data = _run_multiprocessing( _tract_state_to_limited_tract_state, args, True, workers )
 * 	limited_supra_glottal_sequence = Supra_Glottal_Sequence( np.array( tract_param_data ) )
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 540, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_states); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 540, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_to_numpy); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 540, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 540, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_7 = __pyx_t_1; __Pyx_INCREF(__pyx_t_7); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 540, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_9 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 540, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_7))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_1); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 540, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 540, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_1); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 540, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 540, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_9(__pyx_t_7);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 540, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_state, __pyx_t_1);
    __pyx_t_1 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_v_state))) __PYX_ERR(0, 540, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":541
 * 	tract_param_data = []
 * 	args = [ state for state in motor_sequence.states.to_numpy() ]
 * 	tract_param_data = _run_multiprocessing( _tract_state_to_limited_tract_state, args, True, workers )             # <<<<<<<<<<<<<<
 * 	limited_supra_glottal_sequence = Supra_Glottal_Sequence( np.array( tract_param_data ) )
 * 	if isinstance( motor_sequence,  Motor_Sequence ):
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 541, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_tract_state_to_limited_tract_st); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 541, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = NULL;
  __pyx_t_10 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
      __pyx_t_10 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_7)) {
    PyObject *__pyx_temp[5] = {__pyx_t_6, __pyx_t_1, __pyx_v_args, Py_True, __pyx_v_workers};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 4+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
    PyObject *__pyx_temp[5] = {__pyx_t_6, __pyx_t_1, __pyx_v_args, Py_True, __pyx_v_workers};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 4+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else
  #endif
  {
    __pyx_t_11 = PyTuple_New(4+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 541, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    if (__pyx_t_6) {
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_6); __pyx_t_6 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_10, __pyx_t_1);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_10, __pyx_v_args);
    __Pyx_INCREF(Py_True);
    __Pyx_GIVEREF(Py_True);
    PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_10, Py_True);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_11, 3+__pyx_t_10, __pyx_v_workers);
    __pyx_t_1 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_11, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF_SET(__pyx_v_tract_param_data, __pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":542
 * 	args = [ state for state in motor_sequence.states.to_numpy() ]
 * 	tract_param_data = _run_multiprocessing( _tract_state_to_limited_tract_state, args, True, workers )
 * 	limited_supra_glottal_sequence = Supra_Glottal_Sequence( np.array( tract_param_data ) )             # <<<<<<<<<<<<<<
 * 	if isinstance( motor_sequence,  Motor_Sequence ):
 * 		return Motor_Sequence( tract_states = limited_supra_glottal_sequence, glottis_states = motor_sequence.to_sub_glottal_sequence() )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_array); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_11 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_1, __pyx_v_tract_param_data) : __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_v_tract_param_data);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_2 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_7, __pyx_t_6, __pyx_t_11) : __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_11);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_limited_supra_glottal_sequence = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":543
 * 	tract_param_data = _run_multiprocessing( _tract_state_to_limited_tract_state, args, True, workers )
 * 	limited_supra_glottal_sequence = Supra_Glottal_Sequence( np.array( tract_param_data ) )
 * 	if isinstance( motor_sequence,  Motor_Sequence ):             # <<<<<<<<<<<<<<
 * 		return Motor_Sequence( tract_states = limited_supra_glottal_sequence, glottis_states = motor_sequence.to_sub_glottal_sequence() )
 * 	else:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 543, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_2); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 543, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = (__pyx_t_4 != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":544
 * 	limited_supra_glottal_sequence = Supra_Glottal_Sequence( np.array( tract_param_data ) )
 * 	if isinstance( motor_sequence,  Motor_Sequence ):
 * 		return Motor_Sequence( tract_states = limited_supra_glottal_sequence, glottis_states = motor_sequence.to_sub_glottal_sequence() )             # <<<<<<<<<<<<<<
 * 	else:
 * 		return limited_supra_glottal_sequence
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_7 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_tract_states, __pyx_v_limited_supra_glottal_sequence) < 0) __PYX_ERR(0, 544, __pyx_L1_error)
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_to_sub_glottal_sequence); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    __pyx_t_11 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_glottis_states, __pyx_t_11) < 0) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_empty_tuple, __pyx_t_7); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_r = __pyx_t_11;
    __pyx_t_11 = 0;
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":543
 * 	tract_param_data = _run_multiprocessing( _tract_state_to_limited_tract_state, args, True, workers )
 * 	limited_supra_glottal_sequence = Supra_Glottal_Sequence( np.array( tract_param_data ) )
 * 	if isinstance( motor_sequence,  Motor_Sequence ):             # <<<<<<<<<<<<<<
 * 		return Motor_Sequence( tract_states = limited_supra_glottal_sequence, glottis_states = motor_sequence.to_sub_glottal_sequence() )
 * 	else:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":546
 * 		return Motor_Sequence( tract_states = limited_supra_glottal_sequence, glottis_states = motor_sequence.to_sub_glottal_sequence() )
 * 	else:
 * 		return limited_supra_glottal_sequence             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_limited_supra_glottal_sequence);
    __pyx_r = __pyx_v_limited_supra_glottal_sequence;
    goto __pyx_L0;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":534
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                          workers: int = None,
 * 	                                        ):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_limited_tract_sequence", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tract_param_data);
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_limited_supra_glottal_sequence);
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":548
 * 		return limited_supra_glottal_sequence
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                       svg_dir_list = None,
 * 	                       fps: int = 60,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_37tract_sequence_to_svg(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_37tract_sequence_to_svg = {"tract_sequence_to_svg", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_37tract_sequence_to_svg, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_37tract_sequence_to_svg(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence_list = 0;
  PyObject *__pyx_v_svg_dir_list = 0;
  PyObject *__pyx_v_fps = 0;
  CYTHON_UNUSED PyObject *__pyx_v_save_video = 0;
  PyObject *__pyx_v_workers = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tract_sequence_to_svg (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence_list,&__pyx_n_s_svg_dir_list,&__pyx_n_s_fps,&__pyx_n_s_save_video,&__pyx_n_s_workers,0};
    PyObject* values[5] = {0,0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":549
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,
 * 	                       svg_dir_list = None,             # <<<<<<<<<<<<<<
 * 	                       fps: int = 60,
 * 	                       save_video = False,
 */
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)__pyx_int_60);

    /* "VocalTractLab/VocalTractLabApi.pyx":551
 * 	                       svg_dir_list = None,
 * 	                       fps: int = 60,
 * 	                       save_video = False,             # <<<<<<<<<<<<<<
 * 	                       workers: int = None,
 * 	                       ):
 */
    values[3] = ((PyObject *)Py_False);

    /* "VocalTractLab/VocalTractLabApi.pyx":552
 * 	                       fps: int = 60,
 * 	                       save_video = False,
 * 	                       workers: int = None,             # <<<<<<<<<<<<<<
 * 	                       ):
 * 	motor_sequence_list, svg_dir_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, svg_dir_list ],
 */
    values[4] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence_list)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_svg_dir_list);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_fps);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_video);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "tract_sequence_to_svg") < 0)) __PYX_ERR(0, 548, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence_list = values[0];
    __pyx_v_svg_dir_list = values[1];
    __pyx_v_fps = values[2];
    __pyx_v_save_video = values[3];
    __pyx_v_workers = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("tract_sequence_to_svg", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 548, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_svg", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_36tract_sequence_to_svg(__pyx_self, __pyx_v_motor_sequence_list, __pyx_v_svg_dir_list, __pyx_v_fps, __pyx_v_save_video, __pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":548
 * 		return limited_supra_glottal_sequence
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                       svg_dir_list = None,
 * 	                       fps: int = 60,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_36tract_sequence_to_svg(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence_list, PyObject *__pyx_v_svg_dir_list, PyObject *__pyx_v_fps, CYTHON_UNUSED PyObject *__pyx_v_save_video, PyObject *__pyx_v_workers) {
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_svg_dir = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *(*__pyx_t_8)(PyObject *);
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("tract_sequence_to_svg", 0);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_svg_dir_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":554
 * 	                       workers: int = None,
 * 	                       ):
 * 	motor_sequence_list, svg_dir_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, svg_dir_list ],             # <<<<<<<<<<<<<<
 * 	                                                                       [ ( str, Motor_Sequence ),
 * 	                                                                         ( str, type(None) ),
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 554, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_if_input_lists_are_valid); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 554, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 554, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_motor_sequence_list);
  __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_motor_sequence_list);
  __Pyx_INCREF(__pyx_v_svg_dir_list);
  __Pyx_GIVEREF(__pyx_v_svg_dir_list);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_svg_dir_list);

  /* "VocalTractLab/VocalTractLabApi.pyx":555
 * 	                       ):
 * 	motor_sequence_list, svg_dir_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, svg_dir_list ],
 * 	                                                                       [ ( str, Motor_Sequence ),             # <<<<<<<<<<<<<<
 * 	                                                                         ( str, type(None) ),
 * 	                                                                       ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_4);
  __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":556
 * 	motor_sequence_list, svg_dir_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, svg_dir_list ],
 * 	                                                                       [ ( str, Motor_Sequence ),
 * 	                                                                         ( str, type(None) ),             # <<<<<<<<<<<<<<
 * 	                                                                       ]
 * 	                                                                     )
 */
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 556, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(((PyObject *)(&PyString_Type)));
  __Pyx_GIVEREF(((PyObject *)(&PyString_Type)));
  PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)(&PyString_Type)));
  __Pyx_INCREF(((PyObject *)Py_TYPE(Py_None)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(Py_None)));
  PyTuple_SET_ITEM(__pyx_t_4, 1, ((PyObject *)Py_TYPE(Py_None)));

  /* "VocalTractLab/VocalTractLabApi.pyx":555
 * 	                       ):
 * 	motor_sequence_list, svg_dir_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, svg_dir_list ],
 * 	                                                                       [ ( str, Motor_Sequence ),             # <<<<<<<<<<<<<<
 * 	                                                                         ( str, type(None) ),
 * 	                                                                       ]
 */
  __pyx_t_6 = PyList_New(2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_5);
  PyList_SET_ITEM(__pyx_t_6, 0, __pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_4);
  PyList_SET_ITEM(__pyx_t_6, 1, __pyx_t_4);
  __pyx_t_5 = 0;
  __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_7 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_7 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_6};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_t_2, __pyx_t_6};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_7, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_7, __pyx_t_6);
    __pyx_t_2 = 0;
    __pyx_t_6 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 554, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_5);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_6 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 554, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = Py_TYPE(__pyx_t_6)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_8(__pyx_t_6); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_5 = __pyx_t_8(__pyx_t_6); if (unlikely(!__pyx_t_5)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_5);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_6), 2) < 0) __PYX_ERR(0, 554, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 554, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":554
 * 	                       workers: int = None,
 * 	                       ):
 * 	motor_sequence_list, svg_dir_list = FT.check_if_input_lists_are_valid( [ motor_sequence_list, svg_dir_list ],             # <<<<<<<<<<<<<<
 * 	                                                                       [ ( str, Motor_Sequence ),
 * 	                                                                         ( str, type(None) ),
 */
  __Pyx_DECREF_SET(__pyx_v_motor_sequence_list, __pyx_t_3);
  __pyx_t_3 = 0;
  __Pyx_DECREF_SET(__pyx_v_svg_dir_list, __pyx_t_5);
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":559
 * 	                                                                       ]
 * 	                                                                     )
 * 	args = [ [motor_sequence, svg_dir, fps ]             # <<<<<<<<<<<<<<
 * 	for motor_sequence, svg_dir in itertools.zip_longest( motor_sequence_list, svg_dir_list ) ]
 * 	_run_multiprocessing( _tract_sequence_to_svg, args, False, workers )
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 559, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "VocalTractLab/VocalTractLabApi.pyx":560
 * 	                                                                     )
 * 	args = [ [motor_sequence, svg_dir, fps ]
 * 	for motor_sequence, svg_dir in itertools.zip_longest( motor_sequence_list, svg_dir_list ) ]             # <<<<<<<<<<<<<<
 * 	_run_multiprocessing( _tract_sequence_to_svg, args, False, workers )
 * 	return
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_itertools); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 560, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zip_longest); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 560, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_7 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_7 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_motor_sequence_list, __pyx_v_svg_dir_list};
    __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 560, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_5);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_v_motor_sequence_list, __pyx_v_svg_dir_list};
    __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 560, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_5);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 560, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_v_motor_sequence_list);
    __Pyx_GIVEREF(__pyx_v_motor_sequence_list);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_7, __pyx_v_motor_sequence_list);
    __Pyx_INCREF(__pyx_v_svg_dir_list);
    __Pyx_GIVEREF(__pyx_v_svg_dir_list);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_7, __pyx_v_svg_dir_list);
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_2, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 560, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (likely(PyList_CheckExact(__pyx_t_5)) || PyTuple_CheckExact(__pyx_t_5)) {
    __pyx_t_6 = __pyx_t_5; __Pyx_INCREF(__pyx_t_6); __pyx_t_9 = 0;
    __pyx_t_10 = NULL;
  } else {
    __pyx_t_9 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 560, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_10 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 560, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  for (;;) {
    if (likely(!__pyx_t_10)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_5); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 560, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 560, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_9); __Pyx_INCREF(__pyx_t_5); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 560, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_6, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 560, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_10(__pyx_t_6);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 560, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_5))) || (PyList_CheckExact(__pyx_t_5))) {
      PyObject* sequence = __pyx_t_5;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 560, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_4 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 560, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_8 = Py_TYPE(__pyx_t_4)->tp_iternext;
      index = 0; __pyx_t_2 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_2);
      index = 1; __pyx_t_3 = __pyx_t_8(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L7_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_3);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_4), 2) < 0) __PYX_ERR(0, 560, __pyx_L1_error)
      __pyx_t_8 = NULL;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      goto __pyx_L8_unpacking_done;
      __pyx_L7_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_8 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 560, __pyx_L1_error)
      __pyx_L8_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_motor_sequence, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_svg_dir, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":559
 * 	                                                                       ]
 * 	                                                                     )
 * 	args = [ [motor_sequence, svg_dir, fps ]             # <<<<<<<<<<<<<<
 * 	for motor_sequence, svg_dir in itertools.zip_longest( motor_sequence_list, svg_dir_list ) ]
 * 	_run_multiprocessing( _tract_sequence_to_svg, args, False, workers )
 */
    __pyx_t_5 = PyList_New(3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 559, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v_motor_sequence);
    __Pyx_GIVEREF(__pyx_v_motor_sequence);
    PyList_SET_ITEM(__pyx_t_5, 0, __pyx_v_motor_sequence);
    __Pyx_INCREF(__pyx_v_svg_dir);
    __Pyx_GIVEREF(__pyx_v_svg_dir);
    PyList_SET_ITEM(__pyx_t_5, 1, __pyx_v_svg_dir);
    __Pyx_INCREF(__pyx_v_fps);
    __Pyx_GIVEREF(__pyx_v_fps);
    PyList_SET_ITEM(__pyx_t_5, 2, __pyx_v_fps);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(0, 559, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":560
 * 	                                                                     )
 * 	args = [ [motor_sequence, svg_dir, fps ]
 * 	for motor_sequence, svg_dir in itertools.zip_longest( motor_sequence_list, svg_dir_list ) ]             # <<<<<<<<<<<<<<
 * 	_run_multiprocessing( _tract_sequence_to_svg, args, False, workers )
 * 	return
 */
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":561
 * 	args = [ [motor_sequence, svg_dir, fps ]
 * 	for motor_sequence, svg_dir in itertools.zip_longest( motor_sequence_list, svg_dir_list ) ]
 * 	_run_multiprocessing( _tract_sequence_to_svg, args, False, workers )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 561, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_tract_sequence_to_svg); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 561, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = NULL;
  __pyx_t_7 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_7 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[5] = {__pyx_t_3, __pyx_t_5, __pyx_v_args, Py_False, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 4+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 561, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[5] = {__pyx_t_3, __pyx_t_5, __pyx_v_args, Py_False, __pyx_v_workers};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 4+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 561, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(4+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 561, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_7, __pyx_t_5);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_7, __pyx_v_args);
    __Pyx_INCREF(Py_False);
    __Pyx_GIVEREF(Py_False);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_7, Py_False);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_2, 3+__pyx_t_7, __pyx_v_workers);
    __pyx_t_5 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 561, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":562
 * 	for motor_sequence, svg_dir in itertools.zip_longest( motor_sequence_list, svg_dir_list ) ]
 * 	_run_multiprocessing( _tract_sequence_to_svg, args, False, workers )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_transfer_functions( motor_sequence,
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":548
 * 		return limited_supra_glottal_sequence
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                       svg_dir_list = None,
 * 	                       fps: int = 60,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_svg", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_svg_dir);
  __Pyx_XDECREF(__pyx_v_motor_sequence_list);
  __Pyx_XDECREF(__pyx_v_svg_dir_list);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":564
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_transfer_functions( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_39tract_sequence_to_transfer_functions(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_39tract_sequence_to_transfer_functions = {"tract_sequence_to_transfer_functions", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_39tract_sequence_to_transfer_functions, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_39tract_sequence_to_transfer_functions(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence = 0;
  PyObject *__pyx_v_n_spectrum_samples = 0;
  bool __pyx_v_save_magnitude_spectrum;
  bool __pyx_v_save_phase_spectrum;
  PyObject *__pyx_v_workers = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tract_sequence_to_transfer_functions (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence,&__pyx_n_s_n_spectrum_samples,&__pyx_n_s_save_magnitude_spectrum,&__pyx_n_s_save_phase_spectrum,&__pyx_n_s_workers,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[1] = ((PyObject *)__pyx_int_8192);

    /* "VocalTractLab/VocalTractLabApi.pyx":568
 * 	                                      save_magnitude_spectrum: bool = True,
 * 	                                      save_phase_spectrum: bool = True,
 * 	                                      workers: int = None,             # <<<<<<<<<<<<<<
 * 	                                    ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 */
    values[4] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_n_spectrum_samples);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_magnitude_spectrum);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_phase_spectrum);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "tract_sequence_to_transfer_functions") < 0)) __PYX_ERR(0, 564, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence = values[0];
    __pyx_v_n_spectrum_samples = values[1];
    if (values[2]) {
      __pyx_v_save_magnitude_spectrum = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_save_magnitude_spectrum == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 566, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":566
 * def tract_sequence_to_transfer_functions( motor_sequence,
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,             # <<<<<<<<<<<<<<
 * 	                                      save_phase_spectrum: bool = True,
 * 	                                      workers: int = None,
 */
      __pyx_v_save_magnitude_spectrum = ((bool)1);
    }
    if (values[3]) {
      __pyx_v_save_phase_spectrum = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_save_phase_spectrum == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 567, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":567
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,
 * 	                                      save_phase_spectrum: bool = True,             # <<<<<<<<<<<<<<
 * 	                                      workers: int = None,
 * 	                                    ):
 */
      __pyx_v_save_phase_spectrum = ((bool)1);
    }
    __pyx_v_workers = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("tract_sequence_to_transfer_functions", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 564, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_transfer_functions", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_38tract_sequence_to_transfer_functions(__pyx_self, __pyx_v_motor_sequence, __pyx_v_n_spectrum_samples, __pyx_v_save_magnitude_spectrum, __pyx_v_save_phase_spectrum, __pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":564
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_transfer_functions( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_38tract_sequence_to_transfer_functions(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence, PyObject *__pyx_v_n_spectrum_samples, bool __pyx_v_save_magnitude_spectrum, bool __pyx_v_save_phase_spectrum, PyObject *__pyx_v_workers) {
  CYTHON_UNUSED PyObject *__pyx_v_tract_param_data = NULL;
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_transfer_functions = NULL;
  PyObject *__pyx_v_state = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("tract_sequence_to_transfer_functions", 0);
  __Pyx_INCREF(__pyx_v_motor_sequence);

  /* "VocalTractLab/VocalTractLabApi.pyx":570
 * 	                                      workers: int = None,
 * 	                                    ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 570, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 570, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_1); 
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (!__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_5 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_2); 
  __pyx_t_4 = (__pyx_t_5 != 0);
  __pyx_t_3 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = ((!(__pyx_t_3 != 0)) != 0);
  if (unlikely(__pyx_t_4)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":571
 * 	                                    ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )             # <<<<<<<<<<<<<<
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_motor_sequence_argument_must_be, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 571, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_6, ((PyObject *)Py_TYPE(__pyx_v_motor_sequence))) : __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)Py_TYPE(__pyx_v_motor_sequence)));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 571, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 571, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 571, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":570
 * 	                                      workers: int = None,
 * 	                                    ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":572
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):             # <<<<<<<<<<<<<<
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_2); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = (__pyx_t_4 != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":573
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()             # <<<<<<<<<<<<<<
 * 	tract_param_data = []
 * 	args = [ [ state,
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_to_supra_glottal_sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_2 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_motor_sequence, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":572
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):             # <<<<<<<<<<<<<<
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":574
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []             # <<<<<<<<<<<<<<
 * 	args = [ [ state,
 * 	           n_spectrum_samples,
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 574, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_v_tract_param_data = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":575
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 * 	args = [ [ state,             # <<<<<<<<<<<<<<
 * 	           n_spectrum_samples,
 * 	           save_magnitude_spectrum,
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 575, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "VocalTractLab/VocalTractLabApi.pyx":579
 * 	           save_magnitude_spectrum,
 * 	           save_phase_spectrum ]
 * 		for state in motor_sequence.states.to_numpy() ]             # <<<<<<<<<<<<<<
 * 	transfer_functions = _run_multiprocessing( _tract_state_to_transfer_function, args, True, workers )
 * 	return transfer_functions
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_states); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 579, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_to_numpy); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 579, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_7 = __pyx_t_1; __Pyx_INCREF(__pyx_t_7); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 579, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_9 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 579, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_7))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_1); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 579, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_1); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 579, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_9(__pyx_t_7);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 579, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_state, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":577
 * 	args = [ [ state,
 * 	           n_spectrum_samples,
 * 	           save_magnitude_spectrum,             # <<<<<<<<<<<<<<
 * 	           save_phase_spectrum ]
 * 		for state in motor_sequence.states.to_numpy() ]
 */
    __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_save_magnitude_spectrum); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 577, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);

    /* "VocalTractLab/VocalTractLabApi.pyx":578
 * 	           n_spectrum_samples,
 * 	           save_magnitude_spectrum,
 * 	           save_phase_spectrum ]             # <<<<<<<<<<<<<<
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	transfer_functions = _run_multiprocessing( _tract_state_to_transfer_function, args, True, workers )
 */
    __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_save_phase_spectrum); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);

    /* "VocalTractLab/VocalTractLabApi.pyx":575
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 * 	args = [ [ state,             # <<<<<<<<<<<<<<
 * 	           n_spectrum_samples,
 * 	           save_magnitude_spectrum,
 */
    __pyx_t_10 = PyList_New(4); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 575, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyList_SET_ITEM(__pyx_t_10, 0, __pyx_v_state);
    __Pyx_INCREF(__pyx_v_n_spectrum_samples);
    __Pyx_GIVEREF(__pyx_v_n_spectrum_samples);
    PyList_SET_ITEM(__pyx_t_10, 1, __pyx_v_n_spectrum_samples);
    __Pyx_GIVEREF(__pyx_t_1);
    PyList_SET_ITEM(__pyx_t_10, 2, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_6);
    PyList_SET_ITEM(__pyx_t_10, 3, __pyx_t_6);
    __pyx_t_1 = 0;
    __pyx_t_6 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_10))) __PYX_ERR(0, 575, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":579
 * 	           save_magnitude_spectrum,
 * 	           save_phase_spectrum ]
 * 		for state in motor_sequence.states.to_numpy() ]             # <<<<<<<<<<<<<<
 * 	transfer_functions = _run_multiprocessing( _tract_state_to_transfer_function, args, True, workers )
 * 	return transfer_functions
 */
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":580
 * 	           save_phase_spectrum ]
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	transfer_functions = _run_multiprocessing( _tract_state_to_transfer_function, args, True, workers )             # <<<<<<<<<<<<<<
 * 	return transfer_functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 580, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_n_s_tract_state_to_transfer_functio); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 580, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_6 = NULL;
  __pyx_t_11 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
      __pyx_t_11 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_7)) {
    PyObject *__pyx_temp[5] = {__pyx_t_6, __pyx_t_10, __pyx_v_args, Py_True, __pyx_v_workers};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
    PyObject *__pyx_temp[5] = {__pyx_t_6, __pyx_t_10, __pyx_v_args, Py_True, __pyx_v_workers};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  } else
  #endif
  {
    __pyx_t_1 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (__pyx_t_6) {
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_6); __pyx_t_6 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_10);
    PyTuple_SET_ITEM(__pyx_t_1, 0+__pyx_t_11, __pyx_t_10);
    __Pyx_INCREF(__pyx_v_args);
    __Pyx_GIVEREF(__pyx_v_args);
    PyTuple_SET_ITEM(__pyx_t_1, 1+__pyx_t_11, __pyx_v_args);
    __Pyx_INCREF(Py_True);
    __Pyx_GIVEREF(Py_True);
    PyTuple_SET_ITEM(__pyx_t_1, 2+__pyx_t_11, Py_True);
    __Pyx_INCREF(__pyx_v_workers);
    __Pyx_GIVEREF(__pyx_v_workers);
    PyTuple_SET_ITEM(__pyx_t_1, 3+__pyx_t_11, __pyx_v_workers);
    __pyx_t_10 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_transfer_functions = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":581
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	transfer_functions = _run_multiprocessing( _tract_state_to_transfer_function, args, True, workers )
 * 	return transfer_functions             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_transfer_functions);
  __pyx_r = __pyx_v_transfer_functions;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":564
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_transfer_functions( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_transfer_functions", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tract_param_data);
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_transfer_functions);
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":583
 * 	return transfer_functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_41tract_sequence_to_tube_states(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_41tract_sequence_to_tube_states = {"tract_sequence_to_tube_states", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_41tract_sequence_to_tube_states, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_41tract_sequence_to_tube_states(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_motor_sequence = 0;
  bool __pyx_v_save_tube_length;
  bool __pyx_v_save_tube_area;
  bool __pyx_v_save_tube_articulator;
  bool __pyx_v_save_incisor_position;
  bool __pyx_v_save_tongue_tip_side_elevation;
  bool __pyx_v_save_velum_opening;
  PyObject *__pyx_v_workers = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("tract_sequence_to_tube_states (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_motor_sequence,&__pyx_n_s_save_tube_length,&__pyx_n_s_save_tube_area,&__pyx_n_s_save_tube_articulator,&__pyx_n_s_save_incisor_position,&__pyx_n_s_save_tongue_tip_side_elevation,&__pyx_n_s_save_velum_opening,&__pyx_n_s_workers,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};

    /* "VocalTractLab/VocalTractLabApi.pyx":590
 * 	                               save_tongue_tip_side_elevation: bool = True,
 * 	                               save_velum_opening: bool = True,
 * 	                               workers: int = None,             # <<<<<<<<<<<<<<
 * 	                             ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 */
    values[7] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_motor_sequence)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_tube_length);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_tube_area);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_tube_articulator);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_incisor_position);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_tongue_tip_side_elevation);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_save_velum_opening);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers);
          if (value) { values[7] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "tract_sequence_to_tube_states") < 0)) __PYX_ERR(0, 583, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_motor_sequence = values[0];
    if (values[1]) {
      __pyx_v_save_tube_length = __Pyx_PyObject_IsTrue(values[1]); if (unlikely((__pyx_v_save_tube_length == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 584, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":584
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,
 * 	                               save_tube_length: bool = True,             # <<<<<<<<<<<<<<
 * 	                               save_tube_area: bool = True,
 * 	                               save_tube_articulator: bool = True,
 */
      __pyx_v_save_tube_length = ((bool)1);
    }
    if (values[2]) {
      __pyx_v_save_tube_area = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_save_tube_area == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 585, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":585
 * def tract_sequence_to_tube_states( motor_sequence,
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,             # <<<<<<<<<<<<<<
 * 	                               save_tube_articulator: bool = True,
 * 	                               save_incisor_position: bool = True,
 */
      __pyx_v_save_tube_area = ((bool)1);
    }
    if (values[3]) {
      __pyx_v_save_tube_articulator = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_save_tube_articulator == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 586, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":586
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,
 * 	                               save_tube_articulator: bool = True,             # <<<<<<<<<<<<<<
 * 	                               save_incisor_position: bool = True,
 * 	                               save_tongue_tip_side_elevation: bool = True,
 */
      __pyx_v_save_tube_articulator = ((bool)1);
    }
    if (values[4]) {
      __pyx_v_save_incisor_position = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_save_incisor_position == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 587, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":587
 * 	                               save_tube_area: bool = True,
 * 	                               save_tube_articulator: bool = True,
 * 	                               save_incisor_position: bool = True,             # <<<<<<<<<<<<<<
 * 	                               save_tongue_tip_side_elevation: bool = True,
 * 	                               save_velum_opening: bool = True,
 */
      __pyx_v_save_incisor_position = ((bool)1);
    }
    if (values[5]) {
      __pyx_v_save_tongue_tip_side_elevation = __Pyx_PyObject_IsTrue(values[5]); if (unlikely((__pyx_v_save_tongue_tip_side_elevation == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 588, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":588
 * 	                               save_tube_articulator: bool = True,
 * 	                               save_incisor_position: bool = True,
 * 	                               save_tongue_tip_side_elevation: bool = True,             # <<<<<<<<<<<<<<
 * 	                               save_velum_opening: bool = True,
 * 	                               workers: int = None,
 */
      __pyx_v_save_tongue_tip_side_elevation = ((bool)1);
    }
    if (values[6]) {
      __pyx_v_save_velum_opening = __Pyx_PyObject_IsTrue(values[6]); if (unlikely((__pyx_v_save_velum_opening == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 589, __pyx_L3_error)
    } else {

      /* "VocalTractLab/VocalTractLabApi.pyx":589
 * 	                               save_incisor_position: bool = True,
 * 	                               save_tongue_tip_side_elevation: bool = True,
 * 	                               save_velum_opening: bool = True,             # <<<<<<<<<<<<<<
 * 	                               workers: int = None,
 * 	                             ):
 */
      __pyx_v_save_velum_opening = ((bool)1);
    }
    __pyx_v_workers = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("tract_sequence_to_tube_states", 0, 1, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 583, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_tube_states", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_40tract_sequence_to_tube_states(__pyx_self, __pyx_v_motor_sequence, __pyx_v_save_tube_length, __pyx_v_save_tube_area, __pyx_v_save_tube_articulator, __pyx_v_save_incisor_position, __pyx_v_save_tongue_tip_side_elevation, __pyx_v_save_velum_opening, __pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":583
 * 	return transfer_functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_40tract_sequence_to_tube_states(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_motor_sequence, bool __pyx_v_save_tube_length, bool __pyx_v_save_tube_area, bool __pyx_v_save_tube_articulator, bool __pyx_v_save_incisor_position, bool __pyx_v_save_tongue_tip_side_elevation, bool __pyx_v_save_velum_opening, PyObject *__pyx_v_workers) {
  CYTHON_UNUSED PyObject *__pyx_v_tract_param_data = NULL;
  PyObject *__pyx_v_args = NULL;
  PyObject *__pyx_v_tube_states = NULL;
  PyObject *__pyx_v_state = NULL;
  PyObject *__pyx_v_arg = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  int __pyx_t_15;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("tract_sequence_to_tube_states", 0);
  __Pyx_INCREF(__pyx_v_motor_sequence);

  /* "VocalTractLab/VocalTractLabApi.pyx":592
 * 	                               workers: int = None,
 * 	                             ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 592, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 592, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_1); 
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (!__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_5 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_2); 
  __pyx_t_4 = (__pyx_t_5 != 0);
  __pyx_t_3 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = ((!(__pyx_t_3 != 0)) != 0);
  if (unlikely(__pyx_t_4)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":593
 * 	                             ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )             # <<<<<<<<<<<<<<
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_motor_sequence_argument_must_be, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 593, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_6, ((PyObject *)Py_TYPE(__pyx_v_motor_sequence))) : __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)Py_TYPE(__pyx_v_motor_sequence)));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 593, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 593, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 593, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":592
 * 	                               workers: int = None,
 * 	                             ):
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":594
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):             # <<<<<<<<<<<<<<
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 594, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_motor_sequence, __pyx_t_2); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 594, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = (__pyx_t_4 != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":595
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()             # <<<<<<<<<<<<<<
 * 	tract_param_data = []
 * 	args = [ [ state,
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_to_supra_glottal_sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 595, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_2 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 595, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_motor_sequence, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":594
 * 	if not isinstance( motor_sequence, ( Motor_Sequence, Supra_Glottal_Sequence ) ):
 * 		raise ValueError( 'motor_sequence argument must be Motor_Sequence or Supra_Glottal_Sequence, not {}'.format( type( motor_sequence ) ) )
 * 	if isinstance( motor_sequence, Motor_Sequence ):             # <<<<<<<<<<<<<<
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":596
 * 	if isinstance( motor_sequence, Motor_Sequence ):
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []             # <<<<<<<<<<<<<<
 * 	args = [ [ state,
 * 	           save_tube_length,
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 596, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_v_tract_param_data = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":597
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 * 	args = [ [ state,             # <<<<<<<<<<<<<<
 * 	           save_tube_length,
 * 	           save_tube_area,
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 597, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "VocalTractLab/VocalTractLabApi.pyx":604
 * 	           save_tongue_tip_side_elevation,
 * 	           save_velum_opening ]
 * 		for state in motor_sequence.states.to_numpy() ]             # <<<<<<<<<<<<<<
 * 	if len( args ) <= 4:
 * 		tube_states = [ _tract_state_to_tube_state( arg ) for arg in args ]
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_states); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 604, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_to_numpy); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 604, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 604, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_7 = __pyx_t_1; __Pyx_INCREF(__pyx_t_7); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 604, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_9 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 604, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_7))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_1); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 604, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 604, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_1); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 604, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 604, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_9(__pyx_t_7);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 604, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_state, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":598
 * 	tract_param_data = []
 * 	args = [ [ state,
 * 	           save_tube_length,             # <<<<<<<<<<<<<<
 * 	           save_tube_area,
 * 	           save_tube_articulator,
 */
    __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_v_save_tube_length); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 598, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);

    /* "VocalTractLab/VocalTractLabApi.pyx":599
 * 	args = [ [ state,
 * 	           save_tube_length,
 * 	           save_tube_area,             # <<<<<<<<<<<<<<
 * 	           save_tube_articulator,
 * 	           save_incisor_position,
 */
    __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_save_tube_area); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 599, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);

    /* "VocalTractLab/VocalTractLabApi.pyx":600
 * 	           save_tube_length,
 * 	           save_tube_area,
 * 	           save_tube_articulator,             # <<<<<<<<<<<<<<
 * 	           save_incisor_position,
 * 	           save_tongue_tip_side_elevation,
 */
    __pyx_t_10 = __Pyx_PyBool_FromLong(__pyx_v_save_tube_articulator); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 600, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);

    /* "VocalTractLab/VocalTractLabApi.pyx":601
 * 	           save_tube_area,
 * 	           save_tube_articulator,
 * 	           save_incisor_position,             # <<<<<<<<<<<<<<
 * 	           save_tongue_tip_side_elevation,
 * 	           save_velum_opening ]
 */
    __pyx_t_11 = __Pyx_PyBool_FromLong(__pyx_v_save_incisor_position); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 601, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);

    /* "VocalTractLab/VocalTractLabApi.pyx":602
 * 	           save_tube_articulator,
 * 	           save_incisor_position,
 * 	           save_tongue_tip_side_elevation,             # <<<<<<<<<<<<<<
 * 	           save_velum_opening ]
 * 		for state in motor_sequence.states.to_numpy() ]
 */
    __pyx_t_12 = __Pyx_PyBool_FromLong(__pyx_v_save_tongue_tip_side_elevation); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 602, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_12);

    /* "VocalTractLab/VocalTractLabApi.pyx":603
 * 	           save_incisor_position,
 * 	           save_tongue_tip_side_elevation,
 * 	           save_velum_opening ]             # <<<<<<<<<<<<<<
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	if len( args ) <= 4:
 */
    __pyx_t_13 = __Pyx_PyBool_FromLong(__pyx_v_save_velum_opening); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 603, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);

    /* "VocalTractLab/VocalTractLabApi.pyx":597
 * 		motor_sequence = motor_sequence.to_supra_glottal_sequence()
 * 	tract_param_data = []
 * 	args = [ [ state,             # <<<<<<<<<<<<<<
 * 	           save_tube_length,
 * 	           save_tube_area,
 */
    __pyx_t_14 = PyList_New(7); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 597, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyList_SET_ITEM(__pyx_t_14, 0, __pyx_v_state);
    __Pyx_GIVEREF(__pyx_t_1);
    PyList_SET_ITEM(__pyx_t_14, 1, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_6);
    PyList_SET_ITEM(__pyx_t_14, 2, __pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_10);
    PyList_SET_ITEM(__pyx_t_14, 3, __pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_11);
    PyList_SET_ITEM(__pyx_t_14, 4, __pyx_t_11);
    __Pyx_GIVEREF(__pyx_t_12);
    PyList_SET_ITEM(__pyx_t_14, 5, __pyx_t_12);
    __Pyx_GIVEREF(__pyx_t_13);
    PyList_SET_ITEM(__pyx_t_14, 6, __pyx_t_13);
    __pyx_t_1 = 0;
    __pyx_t_6 = 0;
    __pyx_t_10 = 0;
    __pyx_t_11 = 0;
    __pyx_t_12 = 0;
    __pyx_t_13 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_14))) __PYX_ERR(0, 597, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":604
 * 	           save_tongue_tip_side_elevation,
 * 	           save_velum_opening ]
 * 		for state in motor_sequence.states.to_numpy() ]             # <<<<<<<<<<<<<<
 * 	if len( args ) <= 4:
 * 		tube_states = [ _tract_state_to_tube_state( arg ) for arg in args ]
 */
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_args = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":605
 * 	           save_velum_opening ]
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	if len( args ) <= 4:             # <<<<<<<<<<<<<<
 * 		tube_states = [ _tract_state_to_tube_state( arg ) for arg in args ]
 * 	else:
 */
  __pyx_t_8 = PyList_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 605, __pyx_L1_error)
  __pyx_t_3 = ((__pyx_t_8 <= 4) != 0);
  if (__pyx_t_3) {

    /* "VocalTractLab/VocalTractLabApi.pyx":606
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	if len( args ) <= 4:
 * 		tube_states = [ _tract_state_to_tube_state( arg ) for arg in args ]             # <<<<<<<<<<<<<<
 * 	else:
 * 		tube_states = _run_multiprocessing( _tract_state_to_tube_state, args, True, workers )
 */
    __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 606, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_7 = __pyx_v_args; __Pyx_INCREF(__pyx_t_7); __pyx_t_8 = 0;
    for (;;) {
      if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_7)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_14 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_8); __Pyx_INCREF(__pyx_t_14); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 606, __pyx_L1_error)
      #else
      __pyx_t_14 = PySequence_ITEM(__pyx_t_7, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 606, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_14);
      __pyx_t_14 = 0;
      __Pyx_GetModuleGlobalName(__pyx_t_13, __pyx_n_s_tract_state_to_tube_state); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 606, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      __pyx_t_12 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_13))) {
        __pyx_t_12 = PyMethod_GET_SELF(__pyx_t_13);
        if (likely(__pyx_t_12)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_13);
          __Pyx_INCREF(__pyx_t_12);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_13, function);
        }
      }
      __pyx_t_14 = (__pyx_t_12) ? __Pyx_PyObject_Call2Args(__pyx_t_13, __pyx_t_12, __pyx_v_arg) : __Pyx_PyObject_CallOneArg(__pyx_t_13, __pyx_v_arg);
      __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
      if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 606, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_14))) __PYX_ERR(0, 606, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_tube_states = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":605
 * 	           save_velum_opening ]
 * 		for state in motor_sequence.states.to_numpy() ]
 * 	if len( args ) <= 4:             # <<<<<<<<<<<<<<
 * 		tube_states = [ _tract_state_to_tube_state( arg ) for arg in args ]
 * 	else:
 */
    goto __pyx_L9;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":608
 * 		tube_states = [ _tract_state_to_tube_state( arg ) for arg in args ]
 * 	else:
 * 		tube_states = _run_multiprocessing( _tract_state_to_tube_state, args, True, workers )             # <<<<<<<<<<<<<<
 * 	return tube_states
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_run_multiprocessing); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GetModuleGlobalName(__pyx_t_14, __pyx_n_s_tract_state_to_tube_state); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __pyx_t_13 = NULL;
    __pyx_t_15 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_13)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_13);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_15 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_13, __pyx_t_14, __pyx_v_args, Py_True, __pyx_v_workers};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_15, 4+__pyx_t_15); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[5] = {__pyx_t_13, __pyx_t_14, __pyx_v_args, Py_True, __pyx_v_workers};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_15, 4+__pyx_t_15); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    {
      __pyx_t_12 = PyTuple_New(4+__pyx_t_15); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 608, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_12);
      if (__pyx_t_13) {
        __Pyx_GIVEREF(__pyx_t_13); PyTuple_SET_ITEM(__pyx_t_12, 0, __pyx_t_13); __pyx_t_13 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_14);
      PyTuple_SET_ITEM(__pyx_t_12, 0+__pyx_t_15, __pyx_t_14);
      __Pyx_INCREF(__pyx_v_args);
      __Pyx_GIVEREF(__pyx_v_args);
      PyTuple_SET_ITEM(__pyx_t_12, 1+__pyx_t_15, __pyx_v_args);
      __Pyx_INCREF(Py_True);
      __Pyx_GIVEREF(Py_True);
      PyTuple_SET_ITEM(__pyx_t_12, 2+__pyx_t_15, Py_True);
      __Pyx_INCREF(__pyx_v_workers);
      __Pyx_GIVEREF(__pyx_v_workers);
      PyTuple_SET_ITEM(__pyx_t_12, 3+__pyx_t_15, __pyx_v_workers);
      __pyx_t_14 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_12, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_tube_states = __pyx_t_2;
    __pyx_t_2 = 0;
  }
  __pyx_L9:;

  /* "VocalTractLab/VocalTractLabApi.pyx":609
 * 	else:
 * 		tube_states = _run_multiprocessing( _tract_state_to_tube_state, args, True, workers )
 * 	return tube_states             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * #####################################################################################################################################################
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_tube_states);
  __pyx_r = __pyx_v_tube_states;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":583
 * 	return transfer_functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi.tract_sequence_to_tube_states", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tract_param_data);
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_XDECREF(__pyx_v_tube_states);
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":629
 * # 		constructor / destructor functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _initialize( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_43_initialize(PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_43_initialize = {"_initialize", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_43_initialize, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_43_initialize(PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_initialize (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_speaker_file_path), (&PyString_Type), 1, "speaker_file_path", 1))) __PYX_ERR(0, 629, __pyx_L1_error)
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_42_initialize(__pyx_self, ((PyObject*)__pyx_v_speaker_file_path));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_42_initialize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_speaker_file_path) {
  PyObject *__pyx_v_speakerFileName = NULL;
  int __pyx_v_value;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char const *__pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_initialize", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":630
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _initialize( str speaker_file_path ):
 * 	speakerFileName = speaker_file_path.encode()             # <<<<<<<<<<<<<<
 * 	value = vtlInitialize( speakerFileName )
 * 	if value != 0:
 */
  __pyx_t_1 = __Pyx_CallUnboundCMethod0(&__pyx_umethod_PyString_Type_encode, __pyx_v_speaker_file_path); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 630, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_speakerFileName = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":631
 * def _initialize( str speaker_file_path ):
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )             # <<<<<<<<<<<<<<
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlInitialize returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 */
  __pyx_t_2 = __Pyx_PyObject_AsString(__pyx_v_speakerFileName); if (unlikely((!__pyx_t_2) && PyErr_Occurred())) __PYX_ERR(0, 631, __pyx_L1_error)
  __pyx_v_value = vtlInitialize(__pyx_t_2);

  /* "VocalTractLab/VocalTractLabApi.pyx":632
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlInitialize returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	#log.info( 'VTL API initialized.' )
 */
  __pyx_t_3 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_3)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":633
 * 	value = vtlInitialize( speakerFileName )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlInitialize returned the Errorcode: {}  (See API doc for info.)'.format( value ) )             # <<<<<<<<<<<<<<
 * 	#log.info( 'VTL API initialized.' )
 * 	return
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlInitialize_r, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 633, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 633, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_1 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_6, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 633, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 633, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 633, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":632
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlInitialize returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	#log.info( 'VTL API initialized.' )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":635
 * 		raise ValueError('VTL API function vtlInitialize returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	#log.info( 'VTL API initialized.' )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _close():
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":629
 * # 		constructor / destructor functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _initialize( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._initialize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_speakerFileName);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":637
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _close():             # <<<<<<<<<<<<<<
 * 	value = vtlClose()
 * 	if value != 0:
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_45_close(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_45_close = {"_close", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_45_close, METH_NOARGS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_45_close(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_close (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_44_close(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_44_close(CYTHON_UNUSED PyObject *__pyx_self) {
  int __pyx_v_value;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_close", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":638
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _close():
 * 	value = vtlClose()             # <<<<<<<<<<<<<<
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlClose returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 */
  __pyx_v_value = vtlClose();

  /* "VocalTractLab/VocalTractLabApi.pyx":639
 * def _close():
 * 	value = vtlClose()
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlClose returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	#log.info( 'VTL API closed.' )
 */
  __pyx_t_1 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":640
 * 	value = vtlClose()
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlClose returned the Errorcode: {}  (See API doc for info.)'.format( value ) )             # <<<<<<<<<<<<<<
 * 	#log.info( 'VTL API closed.' )
 * 	return
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlClose_return, __pyx_n_s_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_5, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 640, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":639
 * def _close():
 * 	value = vtlClose()
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlClose returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	#log.info( 'VTL API closed.' )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":642
 * 		raise ValueError('VTL API function vtlClose returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	#log.info( 'VTL API closed.' )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":637
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _close():             # <<<<<<<<<<<<<<
 * 	value = vtlClose()
 * 	if value != 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._close", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":659
 * #	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _modify_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	in_ges_file_path, out_ges_file_path = args
 * 	ges_file = open( in_ges_file_path ).read()
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_47_modify_gestural_score(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_47_modify_gestural_score = {"_modify_gestural_score", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_47_modify_gestural_score, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_47_modify_gestural_score(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_modify_gestural_score (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_46_modify_gestural_score(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_46_modify_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_in_ges_file_path = NULL;
  PyObject *__pyx_v_out_ges_file_path = NULL;
  PyObject *__pyx_v_ges_file = NULL;
  PyObject *__pyx_v_ges_soup = NULL;
  PyObject *__pyx_v_f = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_modify_gestural_score", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":660
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _modify_gestural_score( args ):
 * 	in_ges_file_path, out_ges_file_path = args             # <<<<<<<<<<<<<<
 * 	ges_file = open( in_ges_file_path ).read()
 * 	ges_soup = BeautifulSoup( ges_file, 'html.parser' )
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 660, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_3 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = Py_TYPE(__pyx_t_3)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_4(__pyx_t_3); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_4(__pyx_t_3); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_4(__pyx_t_3), 2) < 0) __PYX_ERR(0, 660, __pyx_L1_error)
    __pyx_t_4 = NULL;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 660, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_in_ges_file_path = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_out_ges_file_path = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":661
 * def _modify_gestural_score( args ):
 * 	in_ges_file_path, out_ges_file_path = args
 * 	ges_file = open( in_ges_file_path ).read()             # <<<<<<<<<<<<<<
 * 	ges_soup = BeautifulSoup( ges_file, 'html.parser' )
 * 	#do manipulations here
 */
  __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_builtin_open, __pyx_v_in_ges_file_path); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 661, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_read); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 661, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_2 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 661, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ges_file = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":662
 * 	in_ges_file_path, out_ges_file_path = args
 * 	ges_file = open( in_ges_file_path ).read()
 * 	ges_soup = BeautifulSoup( ges_file, 'html.parser' )             # <<<<<<<<<<<<<<
 * 	#do manipulations here
 * 	f = open( out_ges_file_path, "w" )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_BeautifulSoup); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 662, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = NULL;
  __pyx_t_5 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_5 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_1, __pyx_v_ges_file, __pyx_kp_s_html_parser};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 662, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_1, __pyx_v_ges_file, __pyx_kp_s_html_parser};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 662, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 662, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_ges_file);
    __Pyx_GIVEREF(__pyx_v_ges_file);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_5, __pyx_v_ges_file);
    __Pyx_INCREF(__pyx_kp_s_html_parser);
    __Pyx_GIVEREF(__pyx_kp_s_html_parser);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_5, __pyx_kp_s_html_parser);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 662, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ges_soup = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":664
 * 	ges_soup = BeautifulSoup( ges_file, 'html.parser' )
 * 	#do manipulations here
 * 	f = open( out_ges_file_path, "w" )             # <<<<<<<<<<<<<<
 * 	f.write( ges_soup.prettify( formatter = None ) )
 * 	f.close()
 */
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 664, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_out_ges_file_path);
  __Pyx_GIVEREF(__pyx_v_out_ges_file_path);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_out_ges_file_path);
  __Pyx_INCREF(__pyx_n_s_w);
  __Pyx_GIVEREF(__pyx_n_s_w);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_n_s_w);
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_open, __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 664, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_f = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":665
 * 	#do manipulations here
 * 	f = open( out_ges_file_path, "w" )
 * 	f.write( ges_soup.prettify( formatter = None ) )             # <<<<<<<<<<<<<<
 * 	f.close()
 * 	return
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_f, __pyx_n_s_write); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_ges_soup, __pyx_n_s_prettify); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_formatter, Py_None) < 0) __PYX_ERR(0, 665, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_1, __pyx_t_7) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_7);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":666
 * 	f = open( out_ges_file_path, "w" )
 * 	f.write( ges_soup.prettify( formatter = None ) )
 * 	f.close()             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_f, __pyx_n_s_close_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 666, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_7) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_7) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 666, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":667
 * 	f.write( ges_soup.prettify( formatter = None ) )
 * 	f.close()
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_voice_quality( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":659
 * #	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _modify_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	in_ges_file_path, out_ges_file_path = args
 * 	ges_file = open( in_ges_file_path ).read()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._modify_gestural_score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_in_ges_file_path);
  __Pyx_XDECREF(__pyx_v_out_ges_file_path);
  __Pyx_XDECREF(__pyx_v_ges_file);
  __Pyx_XDECREF(__pyx_v_ges_soup);
  __Pyx_XDECREF(__pyx_v_f);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":669
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_voice_quality( args ):             # <<<<<<<<<<<<<<
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_49_gestural_score_change_voice_quality(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_49_gestural_score_change_voice_quality = {"_gestural_score_change_voice_quality", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_49_gestural_score_change_voice_quality, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_49_gestural_score_change_voice_quality(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_gestural_score_change_voice_quality (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_48_gestural_score_change_voice_quality(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_48_gestural_score_change_voice_quality(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_gestural_score_soup = NULL;
  PyObject *__pyx_v_voice_quality_new = NULL;
  PyObject *__pyx_v_voice_quality_old = NULL;
  PyObject *__pyx_v_element = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  int __pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_gestural_score_change_voice_quality", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":670
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_voice_quality( args ):
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args             # <<<<<<<<<<<<<<
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 * 		try:
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 670, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 2; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 3) < 0) __PYX_ERR(0, 670, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 670, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_gestural_score_soup = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_voice_quality_new = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_voice_quality_old = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":671
 * def _gestural_score_change_voice_quality( args ):
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):             # <<<<<<<<<<<<<<
 * 		try:
 * 			if element.value == voice_quality_old:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gestural_score_soup, __pyx_n_s_gestural_score); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_find); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_type, __pyx_kp_s_glottal_shape_gestures) < 0) __PYX_ERR(0, 671, __pyx_L1_error)
  __pyx_t_4 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_1)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_n_s_gesture_sequence, __pyx_t_2};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 671, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_n_s_gesture_sequence, __pyx_t_2};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 671, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 671, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_n_s_gesture_sequence);
    __Pyx_GIVEREF(__pyx_n_s_gesture_sequence);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_n_s_gesture_sequence);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 671, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
    __pyx_t_1 = __pyx_t_3; __Pyx_INCREF(__pyx_t_1); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_9 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 671, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_8); __Pyx_INCREF(__pyx_t_3); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 671, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_1, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 671, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_8); __Pyx_INCREF(__pyx_t_3); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 671, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_1, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 671, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      }
    } else {
      __pyx_t_3 = __pyx_t_9(__pyx_t_1);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 671, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_element, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":672
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 * 		try:             # <<<<<<<<<<<<<<
 * 			if element.value == voice_quality_old:
 * 				element.value = voice_quality_new
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_10, &__pyx_t_11, &__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_10);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      /*try:*/ {

        /* "VocalTractLab/VocalTractLabApi.pyx":673
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 * 		try:
 * 			if element.value == voice_quality_old:             # <<<<<<<<<<<<<<
 * 				element.value = voice_quality_new
 * 		except Exception:
 */
        __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_element, __pyx_n_s_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 673, __pyx_L7_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_7 = PyObject_RichCompare(__pyx_t_3, __pyx_v_voice_quality_old, Py_EQ); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 673, __pyx_L7_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_13 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_13 < 0)) __PYX_ERR(0, 673, __pyx_L7_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        if (__pyx_t_13) {

          /* "VocalTractLab/VocalTractLabApi.pyx":674
 * 		try:
 * 			if element.value == voice_quality_old:
 * 				element.value = voice_quality_new             # <<<<<<<<<<<<<<
 * 		except Exception:
 * 			ValueError( 'Error at element: {}, element.value: {}, vq old: {}, vq new: {}'.format( element, element.value, voice_quality_old, voice_quality_new ) )
 */
          if (__Pyx_PyObject_SetAttrStr(__pyx_v_element, __pyx_n_s_value, __pyx_v_voice_quality_new) < 0) __PYX_ERR(0, 674, __pyx_L7_error)

          /* "VocalTractLab/VocalTractLabApi.pyx":673
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 * 		try:
 * 			if element.value == voice_quality_old:             # <<<<<<<<<<<<<<
 * 				element.value = voice_quality_new
 * 		except Exception:
 */
        }

        /* "VocalTractLab/VocalTractLabApi.pyx":672
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 * 		try:             # <<<<<<<<<<<<<<
 * 			if element.value == voice_quality_old:
 * 				element.value = voice_quality_new
 */
      }
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
      goto __pyx_L14_try_end;
      __pyx_L7_error:;
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":675
 * 			if element.value == voice_quality_old:
 * 				element.value = voice_quality_new
 * 		except Exception:             # <<<<<<<<<<<<<<
 * 			ValueError( 'Error at element: {}, element.value: {}, vq old: {}, vq new: {}'.format( element, element.value, voice_quality_old, voice_quality_new ) )
 * 	return gestural_score_soup
 */
      __pyx_t_6 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
      if (__pyx_t_6) {
        __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._gestural_score_change_voice_quality", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_7, &__pyx_t_3, &__pyx_t_2) < 0) __PYX_ERR(0, 675, __pyx_L9_except_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GOTREF(__pyx_t_2);

        /* "VocalTractLab/VocalTractLabApi.pyx":676
 * 				element.value = voice_quality_new
 * 		except Exception:
 * 			ValueError( 'Error at element: {}, element.value: {}, vq old: {}, vq new: {}'.format( element, element.value, voice_quality_old, voice_quality_new ) )             # <<<<<<<<<<<<<<
 * 	return gestural_score_soup
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
        __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Error_at_element_element_value_v, __pyx_n_s_format); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 676, __pyx_L9_except_error)
        __Pyx_GOTREF(__pyx_t_14);
        __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_v_element, __pyx_n_s_value); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 676, __pyx_L9_except_error)
        __Pyx_GOTREF(__pyx_t_15);
        __pyx_t_16 = NULL;
        __pyx_t_6 = 0;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
          __pyx_t_16 = PyMethod_GET_SELF(__pyx_t_14);
          if (likely(__pyx_t_16)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
            __Pyx_INCREF(__pyx_t_16);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_14, function);
            __pyx_t_6 = 1;
          }
        }
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_14)) {
          PyObject *__pyx_temp[5] = {__pyx_t_16, __pyx_v_element, __pyx_t_15, __pyx_v_voice_quality_old, __pyx_v_voice_quality_new};
          __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_14, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 676, __pyx_L9_except_error)
          __Pyx_XDECREF(__pyx_t_16); __pyx_t_16 = 0;
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_14)) {
          PyObject *__pyx_temp[5] = {__pyx_t_16, __pyx_v_element, __pyx_t_15, __pyx_v_voice_quality_old, __pyx_v_voice_quality_new};
          __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_14, __pyx_temp+1-__pyx_t_6, 4+__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 676, __pyx_L9_except_error)
          __Pyx_XDECREF(__pyx_t_16); __pyx_t_16 = 0;
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
        } else
        #endif
        {
          __pyx_t_17 = PyTuple_New(4+__pyx_t_6); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 676, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_17);
          if (__pyx_t_16) {
            __Pyx_GIVEREF(__pyx_t_16); PyTuple_SET_ITEM(__pyx_t_17, 0, __pyx_t_16); __pyx_t_16 = NULL;
          }
          __Pyx_INCREF(__pyx_v_element);
          __Pyx_GIVEREF(__pyx_v_element);
          PyTuple_SET_ITEM(__pyx_t_17, 0+__pyx_t_6, __pyx_v_element);
          __Pyx_GIVEREF(__pyx_t_15);
          PyTuple_SET_ITEM(__pyx_t_17, 1+__pyx_t_6, __pyx_t_15);
          __Pyx_INCREF(__pyx_v_voice_quality_old);
          __Pyx_GIVEREF(__pyx_v_voice_quality_old);
          PyTuple_SET_ITEM(__pyx_t_17, 2+__pyx_t_6, __pyx_v_voice_quality_old);
          __Pyx_INCREF(__pyx_v_voice_quality_new);
          __Pyx_GIVEREF(__pyx_v_voice_quality_new);
          PyTuple_SET_ITEM(__pyx_t_17, 3+__pyx_t_6, __pyx_v_voice_quality_new);
          __pyx_t_15 = 0;
          __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_14, __pyx_t_17, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 676, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
        }
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __pyx_t_14 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 676, __pyx_L9_except_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        goto __pyx_L8_exception_handled;
      }
      goto __pyx_L9_except_error;
      __pyx_L9_except_error:;

      /* "VocalTractLab/VocalTractLabApi.pyx":672
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 * 		try:             # <<<<<<<<<<<<<<
 * 			if element.value == voice_quality_old:
 * 				element.value = voice_quality_new
 */
      __Pyx_XGIVEREF(__pyx_t_10);
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_11, __pyx_t_12);
      goto __pyx_L1_error;
      __pyx_L8_exception_handled:;
      __Pyx_XGIVEREF(__pyx_t_10);
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_11, __pyx_t_12);
      __pyx_L14_try_end:;
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":671
 * def _gestural_score_change_voice_quality( args ):
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):             # <<<<<<<<<<<<<<
 * 		try:
 * 			if element.value == voice_quality_old:
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":677
 * 		except Exception:
 * 			ValueError( 'Error at element: {}, element.value: {}, vq old: {}, vq new: {}'.format( element, element.value, voice_quality_old, voice_quality_new ) )
 * 	return gestural_score_soup             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_duration():
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_gestural_score_soup);
  __pyx_r = __pyx_v_gestural_score_soup;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":669
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_voice_quality( args ):             # <<<<<<<<<<<<<<
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_XDECREF(__pyx_t_16);
  __Pyx_XDECREF(__pyx_t_17);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._gestural_score_change_voice_quality", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_gestural_score_soup);
  __Pyx_XDECREF(__pyx_v_voice_quality_new);
  __Pyx_XDECREF(__pyx_v_voice_quality_old);
  __Pyx_XDECREF(__pyx_v_element);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":679
 * 	return gestural_score_soup
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_duration():             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_51_gestural_score_change_duration(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_51_gestural_score_change_duration = {"_gestural_score_change_duration", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_51_gestural_score_change_duration, METH_NOARGS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_51_gestural_score_change_duration(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_gestural_score_change_duration (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_50_gestural_score_change_duration(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_50_gestural_score_change_duration(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_gestural_score_change_duration", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":680
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_duration():
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_audio( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":679
 * 	return gestural_score_soup
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_duration():             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":682
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	time_start = time.time()
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_53_gestural_score_to_audio(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_53_gestural_score_to_audio = {"_gestural_score_to_audio", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_53_gestural_score_to_audio, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_53_gestural_score_to_audio(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_gestural_score_to_audio (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_52_gestural_score_to_audio(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_52_gestural_score_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  CYTHON_UNUSED PyObject *__pyx_v_time_start = NULL;
  PyObject *__pyx_v_ges_file_path = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_save_file = NULL;
  PyObject *__pyx_v_normalize_audio = NULL;
  PyObject *__pyx_v_sr = NULL;
  PyObject *__pyx_v_verbose = NULL;
  PyObject *__pyx_v_constants = NULL;
  CYTHON_UNUSED int __pyx_v_return_audio;
  PyObject *__pyx_v_wavFileName = NULL;
  PyObject *__pyx_v_gesFileName = NULL;
  PyArrayObject *__pyx_v_audio = 0;
  bool __pyx_v_enableConsoleOutput;
  CYTHON_UNUSED PyObject *__pyx_v_time_synth_start = NULL;
  int __pyx_v_numS;
  int __pyx_v_value;
  CYTHON_UNUSED PyObject *__pyx_v_time_synth_end = NULL;
  CYTHON_UNUSED PyObject *__pyx_v_time_end = NULL;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_audio;
  __Pyx_Buffer __pyx_pybuffer_audio;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  bool __pyx_t_12;
  PyArrayObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  char const *__pyx_t_17;
  char const *__pyx_t_18;
  Py_ssize_t __pyx_t_19;
  int __pyx_t_20;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_gestural_score_to_audio", 0);
  __pyx_pybuffer_audio.pybuffer.buf = NULL;
  __pyx_pybuffer_audio.refcount = 0;
  __pyx_pybuffernd_audio.data = NULL;
  __pyx_pybuffernd_audio.rcbuffer = &__pyx_pybuffer_audio;

  /* "VocalTractLab/VocalTractLabApi.pyx":684
 * def _gestural_score_to_audio( args ):
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	time_start = time.time()             # <<<<<<<<<<<<<<
 * 	ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	constants = get_constants()
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_time); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 684, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_time); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 684, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_1 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 684, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_time_start = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":685
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	time_start = time.time()
 * 	ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose = args             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	if sr == None:
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 6)) {
      if (size > 6) __Pyx_RaiseTooManyValuesError(6);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 685, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyTuple_GET_ITEM(sequence, 5); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyList_GET_ITEM(sequence, 5); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_6);
    #else
    {
      Py_ssize_t i;
      PyObject** temps[6] = {&__pyx_t_1,&__pyx_t_3,&__pyx_t_2,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6};
      for (i=0; i < 6; i++) {
        PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 685, __pyx_L1_error)
        __Pyx_GOTREF(item);
        *(temps[i]) = item;
      }
    }
    #endif
  } else {
    Py_ssize_t index = -1;
    PyObject** temps[6] = {&__pyx_t_1,&__pyx_t_3,&__pyx_t_2,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6};
    __pyx_t_7 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = Py_TYPE(__pyx_t_7)->tp_iternext;
    for (index=0; index < 6; index++) {
      PyObject* item = __pyx_t_8(__pyx_t_7); if (unlikely(!item)) goto __pyx_L3_unpacking_failed;
      __Pyx_GOTREF(item);
      *(temps[index]) = item;
    }
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_7), 6) < 0) __PYX_ERR(0, 685, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 685, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_ges_file_path = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_audio_file_path = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_save_file = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_normalize_audio = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_v_sr = __pyx_t_5;
  __pyx_t_5 = 0;
  __pyx_v_verbose = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":686
 * 	time_start = time.time()
 * 	ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 686, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 686, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_constants = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":687
 * 	ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	constants = get_constants()
 * 	if sr == None:             # <<<<<<<<<<<<<<
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if not os.path.exists( ges_file_path ):
 */
  __pyx_t_6 = PyObject_RichCompare(__pyx_v_sr, Py_None, Py_EQ); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 687, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 687, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_9) {

    /* "VocalTractLab/VocalTractLabApi.pyx":688
 * 	constants = get_constants()
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]             # <<<<<<<<<<<<<<
 * 	if not os.path.exists( ges_file_path ):
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 */
    __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 688, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF_SET(__pyx_v_sr, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":687
 * 	ges_file_path, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	constants = get_constants()
 * 	if sr == None:             # <<<<<<<<<<<<<<
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if not os.path.exists( ges_file_path ):
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":689
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if not os.path.exists( ges_file_path ):             # <<<<<<<<<<<<<<
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_os); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 689, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_path); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 689, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_exists); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 689, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_4, __pyx_v_ges_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 689, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 689, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_10 = ((!__pyx_t_9) != 0);
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":690
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if not os.path.exists( ges_file_path ):
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )             # <<<<<<<<<<<<<<
 * 		return
 * 	if save_file:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_warnings); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 690, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_warn); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 690, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_the_specified_gestural_score_fil, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 690, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_5 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_v_ges_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_ges_file_path);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 690, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_6 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_2, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 690, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":691
 * 	if not os.path.exists( ges_file_path ):
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return             # <<<<<<<<<<<<<<
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":689
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if not os.path.exists( ges_file_path ):             # <<<<<<<<<<<<<<
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":692
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 * 	if save_file:             # <<<<<<<<<<<<<<
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):
 */
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_save_file); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 692, __pyx_L1_error)
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":693
 * 		return
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )             # <<<<<<<<<<<<<<
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):
 * 		save_file = False
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_FT); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 693, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_make_output_path); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 693, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ges_file_path, __pyx_n_s_rsplit); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 693, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_4 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_kp_s__13) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_kp_s__13);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 693, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_4, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 693, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyNumber_Add(__pyx_t_2, __pyx_kp_s_wav); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 693, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_audio_file_path, __pyx_t_4};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 693, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_audio_file_path, __pyx_t_4};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 693, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    {
      __pyx_t_3 = PyTuple_New(2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 693, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      if (__pyx_t_2) {
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2); __pyx_t_2 = NULL;
      }
      __Pyx_INCREF(__pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_v_audio_file_path);
      PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_11, __pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_11, __pyx_t_4);
      __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_3, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 693, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_audio_file_path, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":692
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 * 	if save_file:             # <<<<<<<<<<<<<<
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":694
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):             # <<<<<<<<<<<<<<
 * 		save_file = False
 * 		return_audio = True
 */
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_v_save_file); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 694, __pyx_L1_error)
  if (!__pyx_t_9) {
    goto __pyx_L10_next_or;
  } else {
  }
  __pyx_t_6 = PyObject_RichCompare(__pyx_v_normalize_audio, Py_None, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 694, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_9) {
  } else {
    __pyx_t_10 = __pyx_t_9;
    goto __pyx_L9_bool_binop_done;
  }
  __pyx_L10_next_or:;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_v_save_file); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 694, __pyx_L1_error)
  if (__pyx_t_9) {
  } else {
    __pyx_t_10 = __pyx_t_9;
    goto __pyx_L9_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = PyObject_RichCompare(__pyx_v_sr, __pyx_t_6, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_10 = __pyx_t_9;
  __pyx_L9_bool_binop_done:;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":695
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):
 * 		save_file = False             # <<<<<<<<<<<<<<
 * 		return_audio = True
 * 	if save_file == False:
 */
    __Pyx_INCREF(Py_False);
    __Pyx_DECREF_SET(__pyx_v_save_file, Py_False);

    /* "VocalTractLab/VocalTractLabApi.pyx":696
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):
 * 		save_file = False
 * 		return_audio = True             # <<<<<<<<<<<<<<
 * 	if save_file == False:
 * 		wavFileName = ''.encode()
 */
    __pyx_v_return_audio = 1;

    /* "VocalTractLab/VocalTractLabApi.pyx":694
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, ges_file_path.rsplit( '.' )[0] + '.wav' )
 * 	if ( save_file and normalize_audio != None ) or ( save_file and sr != constants[ 'samplerate_audio' ] ):             # <<<<<<<<<<<<<<
 * 		save_file = False
 * 		return_audio = True
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":697
 * 		save_file = False
 * 		return_audio = True
 * 	if save_file == False:             # <<<<<<<<<<<<<<
 * 		wavFileName = ''.encode()
 * 	else:
 */
  __pyx_t_5 = PyObject_RichCompare(__pyx_v_save_file, Py_False, Py_EQ); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 697, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 697, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":698
 * 		return_audio = True
 * 	if save_file == False:
 * 		wavFileName = ''.encode()             # <<<<<<<<<<<<<<
 * 	else:
 * 		wavFileName = audio_file_path.encode()
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s__5, __pyx_n_s_encode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 698, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    __pyx_t_5 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 698, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_wavFileName = __pyx_t_5;
    __pyx_t_5 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":697
 * 		save_file = False
 * 		return_audio = True
 * 	if save_file == False:             # <<<<<<<<<<<<<<
 * 		wavFileName = ''.encode()
 * 	else:
 */
    goto __pyx_L13;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":700
 * 		wavFileName = ''.encode()
 * 	else:
 * 		wavFileName = audio_file_path.encode()             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio
 */
  /*else*/ {
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_audio_file_path, __pyx_n_s_encode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    __pyx_t_5 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_wavFileName = __pyx_t_5;
    __pyx_t_5 = 0;
  }
  __pyx_L13:;

  /* "VocalTractLab/VocalTractLabApi.pyx":701
 * 	else:
 * 		wavFileName = audio_file_path.encode()
 * 	gesFileName = ges_file_path.encode()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio
 * 	cdef bool enableConsoleOutput = verbose
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_ges_file_path, __pyx_n_s_encode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 701, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_5 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 701, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_gesFileName = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":703
 * 	gesFileName = ges_file_path.encode()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio
 * 	cdef bool enableConsoleOutput = verbose             # <<<<<<<<<<<<<<
 * 	audio = np.zeros( get_gestural_score_audio_duration( ges_file_path, return_samples = True ), dtype='float64' )
 * 	time_synth_start = time.time()
 */
  __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_v_verbose); if (unlikely((__pyx_t_12 == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 703, __pyx_L1_error)
  __pyx_v_enableConsoleOutput = __pyx_t_12;

  /* "VocalTractLab/VocalTractLabApi.pyx":704
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio
 * 	cdef bool enableConsoleOutput = verbose
 * 	audio = np.zeros( get_gestural_score_audio_duration( ges_file_path, return_samples = True ), dtype='float64' )             # <<<<<<<<<<<<<<
 * 	time_synth_start = time.time()
 * 	cdef int numS = 0
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_zeros); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_get_gestural_score_audio_duratio); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_v_ges_file_path);
  __Pyx_GIVEREF(__pyx_v_ges_file_path);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_ges_file_path);
  __pyx_t_4 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_return_samples, Py_True) < 0) __PYX_ERR(0, 704, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_2);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 704, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_4, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 704, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 704, __pyx_L1_error)
  __pyx_t_13 = ((PyArrayObject *)__pyx_t_3);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
    __pyx_t_11 = __Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_t_13, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack);
    if (unlikely(__pyx_t_11 < 0)) {
      PyErr_Fetch(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
      if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_v_audio, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
        Py_XDECREF(__pyx_t_14); Py_XDECREF(__pyx_t_15); Py_XDECREF(__pyx_t_16);
        __Pyx_RaiseBufferFallbackError();
      } else {
        PyErr_Restore(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      }
      __pyx_t_14 = __pyx_t_15 = __pyx_t_16 = 0;
    }
    __pyx_pybuffernd_audio.diminfo[0].strides = __pyx_pybuffernd_audio.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_audio.diminfo[0].shape = __pyx_pybuffernd_audio.rcbuffer->pybuffer.shape[0];
    if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 704, __pyx_L1_error)
  }
  __pyx_t_13 = 0;
  __pyx_v_audio = ((PyArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":705
 * 	cdef bool enableConsoleOutput = verbose
 * 	audio = np.zeros( get_gestural_score_audio_duration( ges_file_path, return_samples = True ), dtype='float64' )
 * 	time_synth_start = time.time()             # <<<<<<<<<<<<<<
 * 	cdef int numS = 0
 * 	value = vtlGesturalScoreToAudio( gesFileName, wavFileName, &audio[0], &numS, enableConsoleOutput )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_time); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 705, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_time); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 705, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_3 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 705, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_time_synth_start = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":706
 * 	audio = np.zeros( get_gestural_score_audio_duration( ges_file_path, return_samples = True ), dtype='float64' )
 * 	time_synth_start = time.time()
 * 	cdef int numS = 0             # <<<<<<<<<<<<<<
 * 	value = vtlGesturalScoreToAudio( gesFileName, wavFileName, &audio[0], &numS, enableConsoleOutput )
 * 	time_synth_end = time.time()
 */
  __pyx_v_numS = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":707
 * 	time_synth_start = time.time()
 * 	cdef int numS = 0
 * 	value = vtlGesturalScoreToAudio( gesFileName, wavFileName, &audio[0], &numS, enableConsoleOutput )             # <<<<<<<<<<<<<<
 * 	time_synth_end = time.time()
 * 	#print( 'elapsed synthesis time {}'.format( time_synth_end-time_synth_start ) )
 */
  __pyx_t_17 = __Pyx_PyObject_AsString(__pyx_v_gesFileName); if (unlikely((!__pyx_t_17) && PyErr_Occurred())) __PYX_ERR(0, 707, __pyx_L1_error)
  __pyx_t_18 = __Pyx_PyObject_AsString(__pyx_v_wavFileName); if (unlikely((!__pyx_t_18) && PyErr_Occurred())) __PYX_ERR(0, 707, __pyx_L1_error)
  __pyx_t_19 = 0;
  __pyx_t_11 = -1;
  if (__pyx_t_19 < 0) {
    __pyx_t_19 += __pyx_pybuffernd_audio.diminfo[0].shape;
    if (unlikely(__pyx_t_19 < 0)) __pyx_t_11 = 0;
  } else if (unlikely(__pyx_t_19 >= __pyx_pybuffernd_audio.diminfo[0].shape)) __pyx_t_11 = 0;
  if (unlikely(__pyx_t_11 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_11);
    __PYX_ERR(0, 707, __pyx_L1_error)
  }
  __pyx_v_value = vtlGesturalScoreToAudio(__pyx_t_17, __pyx_t_18, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_audio.rcbuffer->pybuffer.buf, __pyx_t_19, __pyx_pybuffernd_audio.diminfo[0].strides))), (&__pyx_v_numS), __pyx_v_enableConsoleOutput);

  /* "VocalTractLab/VocalTractLabApi.pyx":708
 * 	cdef int numS = 0
 * 	value = vtlGesturalScoreToAudio( gesFileName, wavFileName, &audio[0], &numS, enableConsoleOutput )
 * 	time_synth_end = time.time()             # <<<<<<<<<<<<<<
 * 	#print( 'elapsed synthesis time {}'.format( time_synth_end-time_synth_start ) )
 * 	if value != 0:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_time); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 708, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_time); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 708, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 708, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_time_synth_end = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":710
 * 	time_synth_end = time.time()
 * 	#print( 'elapsed synthesis time {}'.format( time_synth_end-time_synth_start ) )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )
 */
  __pyx_t_10 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_10)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":712
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )             # <<<<<<<<<<<<<<
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlGesturalScor, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 712, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 712, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_t_4, __pyx_v_ges_file_path, __pyx_v_audio_file_path};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 712, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_t_4, __pyx_v_ges_file_path, __pyx_v_audio_file_path};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 712, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 712, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_11, __pyx_t_4);
      __Pyx_INCREF(__pyx_v_ges_file_path);
      __Pyx_GIVEREF(__pyx_v_ges_file_path);
      PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_11, __pyx_v_ges_file_path);
      __Pyx_INCREF(__pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_v_audio_file_path);
      PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_11, __pyx_v_audio_file_path);
      __pyx_t_4 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 712, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":711
 * 	#print( 'elapsed synthesis time {}'.format( time_synth_end-time_synth_start ) )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \             # <<<<<<<<<<<<<<
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )
 * 	if sr != constants[ 'samplerate_audio' ]:
 */
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 711, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 711, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":710
 * 	time_synth_end = time.time()
 * 	#print( 'elapsed synthesis time {}'.format( time_synth_end-time_synth_start ) )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":713
 * 		raise ValueError('VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )
 * 	if sr != constants[ 'samplerate_audio' ]:             # <<<<<<<<<<<<<<
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )
 * 	if normalize_audio != None:
 */
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 713, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_sr, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 713, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 713, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":714
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )             # <<<<<<<<<<<<<<
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_librosa); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 714, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_resample); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 714, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 714, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[4] = {__pyx_t_4, ((PyObject *)__pyx_v_audio), __pyx_t_2, __pyx_v_sr};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 714, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[4] = {__pyx_t_4, ((PyObject *)__pyx_v_audio), __pyx_t_2, __pyx_v_sr};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 714, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    } else
    #endif
    {
      __pyx_t_6 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 714, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      if (__pyx_t_4) {
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_audio));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_audio));
      PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_11, ((PyObject *)__pyx_v_audio));
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_11, __pyx_t_2);
      __Pyx_INCREF(__pyx_v_sr);
      __Pyx_GIVEREF(__pyx_v_sr);
      PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_11, __pyx_v_sr);
      __pyx_t_2 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 714, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 714, __pyx_L1_error)
    __pyx_t_13 = ((PyArrayObject *)__pyx_t_3);
    {
      __Pyx_BufFmt_StackElem __pyx_stack[1];
      __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
      __pyx_t_11 = __Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_t_13, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack);
      if (unlikely(__pyx_t_11 < 0)) {
        PyErr_Fetch(&__pyx_t_16, &__pyx_t_15, &__pyx_t_14);
        if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_v_audio, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
          Py_XDECREF(__pyx_t_16); Py_XDECREF(__pyx_t_15); Py_XDECREF(__pyx_t_14);
          __Pyx_RaiseBufferFallbackError();
        } else {
          PyErr_Restore(__pyx_t_16, __pyx_t_15, __pyx_t_14);
        }
        __pyx_t_16 = __pyx_t_15 = __pyx_t_14 = 0;
      }
      __pyx_pybuffernd_audio.diminfo[0].strides = __pyx_pybuffernd_audio.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_audio.diminfo[0].shape = __pyx_pybuffernd_audio.rcbuffer->pybuffer.shape[0];
      if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 714, __pyx_L1_error)
    }
    __pyx_t_13 = 0;
    __Pyx_DECREF_SET(__pyx_v_audio, ((PyArrayObject *)__pyx_t_3));
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":713
 * 		raise ValueError('VTL API function vtlGesturalScoreToAudio returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, audio file (output): {}'.format(value, ges_file_path, audio_file_path) )
 * 	if sr != constants[ 'samplerate_audio' ]:             # <<<<<<<<<<<<<<
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )
 * 	if normalize_audio != None:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":715
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )
 * 	if normalize_audio != None:             # <<<<<<<<<<<<<<
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if verbose:
 */
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_normalize_audio, Py_None, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 715, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 715, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":716
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )             # <<<<<<<<<<<<<<
 * 	if verbose:
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_AT); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 716, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_normalize); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 716, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, ((PyObject *)__pyx_v_audio), __pyx_v_normalize_audio};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, ((PyObject *)__pyx_v_audio), __pyx_v_normalize_audio};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_2 = PyTuple_New(2+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (__pyx_t_5) {
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_5); __pyx_t_5 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_audio));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_audio));
      PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_11, ((PyObject *)__pyx_v_audio));
      __Pyx_INCREF(__pyx_v_normalize_audio);
      __Pyx_GIVEREF(__pyx_v_normalize_audio);
      PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_11, __pyx_v_normalize_audio);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 716, __pyx_L1_error)
    __pyx_t_13 = ((PyArrayObject *)__pyx_t_3);
    {
      __Pyx_BufFmt_StackElem __pyx_stack[1];
      __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
      __pyx_t_11 = __Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_t_13, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack);
      if (unlikely(__pyx_t_11 < 0)) {
        PyErr_Fetch(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
        if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_v_audio, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
          Py_XDECREF(__pyx_t_14); Py_XDECREF(__pyx_t_15); Py_XDECREF(__pyx_t_16);
          __Pyx_RaiseBufferFallbackError();
        } else {
          PyErr_Restore(__pyx_t_14, __pyx_t_15, __pyx_t_16);
        }
        __pyx_t_14 = __pyx_t_15 = __pyx_t_16 = 0;
      }
      __pyx_pybuffernd_audio.diminfo[0].strides = __pyx_pybuffernd_audio.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_audio.diminfo[0].shape = __pyx_pybuffernd_audio.rcbuffer->pybuffer.shape[0];
      if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 716, __pyx_L1_error)
    }
    __pyx_t_13 = 0;
    __Pyx_DECREF_SET(__pyx_v_audio, ((PyArrayObject *)__pyx_t_3));
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":715
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample( audio, constants[ 'samplerate_audio' ], sr )
 * 	if normalize_audio != None:             # <<<<<<<<<<<<<<
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if verbose:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":717
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if verbose:             # <<<<<<<<<<<<<<
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )
 * 	if save_file == False and audio_file_path not in ( None, '' ):
 */
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_verbose); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 717, __pyx_L1_error)
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":718
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if verbose:
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )             # <<<<<<<<<<<<<<
 * 	if save_file == False and audio_file_path not in ( None, '' ):
 * 		AT.write( audio, audio_file_path, sr )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_log); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 718, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_info); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 718, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Audio_generated_from_gestural_sc, __pyx_n_s_format); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 718, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_4, __pyx_v_ges_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_ges_file_path);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 718, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_3 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_5, __pyx_t_6) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_6);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 718, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":717
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if verbose:             # <<<<<<<<<<<<<<
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )
 * 	if save_file == False and audio_file_path not in ( None, '' ):
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":719
 * 	if verbose:
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )
 * 	if save_file == False and audio_file_path not in ( None, '' ):             # <<<<<<<<<<<<<<
 * 		AT.write( audio, audio_file_path, sr )
 * 	time_end = time.time()
 */
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_save_file, Py_False, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 719, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_9) {
  } else {
    __pyx_t_10 = __pyx_t_9;
    goto __pyx_L19_bool_binop_done;
  }
  __Pyx_INCREF(__pyx_v_audio_file_path);
  __pyx_t_3 = __pyx_v_audio_file_path;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, Py_None, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_20 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_20 < 0)) __PYX_ERR(0, 719, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_20) {
  } else {
    __pyx_t_9 = __pyx_t_20;
    goto __pyx_L21_bool_binop_done;
  }
  __pyx_t_20 = (__Pyx_PyString_Equals(__pyx_t_3, __pyx_kp_s__5, Py_NE)); if (unlikely(__pyx_t_20 < 0)) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_9 = __pyx_t_20;
  __pyx_L21_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_20 = (__pyx_t_9 != 0);
  __pyx_t_10 = __pyx_t_20;
  __pyx_L19_bool_binop_done:;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":720
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )
 * 	if save_file == False and audio_file_path not in ( None, '' ):
 * 		AT.write( audio, audio_file_path, sr )             # <<<<<<<<<<<<<<
 * 	time_end = time.time()
 * 	#print( 'elapsed total time {}'.format( time_end-time_start ) )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_AT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 720, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_write); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 720, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[4] = {__pyx_t_2, ((PyObject *)__pyx_v_audio), __pyx_v_audio_file_path, __pyx_v_sr};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 720, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[4] = {__pyx_t_2, ((PyObject *)__pyx_v_audio), __pyx_v_audio_file_path, __pyx_v_sr};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 720, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 720, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (__pyx_t_2) {
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_audio));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_audio));
      PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_11, ((PyObject *)__pyx_v_audio));
      __Pyx_INCREF(__pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_v_audio_file_path);
      PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_11, __pyx_v_audio_file_path);
      __Pyx_INCREF(__pyx_v_sr);
      __Pyx_GIVEREF(__pyx_v_sr);
      PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_11, __pyx_v_sr);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 720, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":719
 * 	if verbose:
 * 		log.info( 'Audio generated from gestural score file: {}'.format( ges_file_path ) )
 * 	if save_file == False and audio_file_path not in ( None, '' ):             # <<<<<<<<<<<<<<
 * 		AT.write( audio, audio_file_path, sr )
 * 	time_end = time.time()
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":721
 * 	if save_file == False and audio_file_path not in ( None, '' ):
 * 		AT.write( audio, audio_file_path, sr )
 * 	time_end = time.time()             # <<<<<<<<<<<<<<
 * 	#print( 'elapsed total time {}'.format( time_end-time_start ) )
 * 	return audio
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_time); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_time); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_3 = (__pyx_t_6) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_6) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 721, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_time_end = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":723
 * 	time_end = time.time()
 * 	#print( 'elapsed total time {}'.format( time_end-time_start ) )
 * 	return audio             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_tract_sequence( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_audio));
  __pyx_r = ((PyObject *)__pyx_v_audio);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":682
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	time_start = time.time()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._gestural_score_to_audio", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_time_start);
  __Pyx_XDECREF(__pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_save_file);
  __Pyx_XDECREF(__pyx_v_normalize_audio);
  __Pyx_XDECREF(__pyx_v_sr);
  __Pyx_XDECREF(__pyx_v_verbose);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF(__pyx_v_wavFileName);
  __Pyx_XDECREF(__pyx_v_gesFileName);
  __Pyx_XDECREF((PyObject *)__pyx_v_audio);
  __Pyx_XDECREF(__pyx_v_time_synth_start);
  __Pyx_XDECREF(__pyx_v_time_synth_end);
  __Pyx_XDECREF(__pyx_v_time_end);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":725
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_tract_sequence( args ):             # <<<<<<<<<<<<<<
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_55_gestural_score_to_tract_sequence(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_55_gestural_score_to_tract_sequence = {"_gestural_score_to_tract_sequence", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_55_gestural_score_to_tract_sequence, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_55_gestural_score_to_tract_sequence(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_gestural_score_to_tract_sequence (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_54_gestural_score_to_tract_sequence(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_54_gestural_score_to_tract_sequence(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_ges_file_path = NULL;
  PyObject *__pyx_v_tract_file_path = NULL;
  PyObject *__pyx_v_return_sequence = NULL;
  PyObject *__pyx_v_gesFileName = NULL;
  PyObject *__pyx_v_tractSequenceFileName = NULL;
  int __pyx_v_value;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  char const *__pyx_t_10;
  char const *__pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_gestural_score_to_tract_sequence", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":726
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_tract_sequence( args ):
 * 	ges_file_path, tract_file_path, return_sequence = args             # <<<<<<<<<<<<<<
 * 	if not os.path.exists( ges_file_path ):
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 726, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 726, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 726, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 726, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 726, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 2; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 3) < 0) __PYX_ERR(0, 726, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 726, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_ges_file_path = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_tract_file_path = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_return_sequence = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":727
 * def _gestural_score_to_tract_sequence( args ):
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):             # <<<<<<<<<<<<<<
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_os); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_path); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_exists); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_1, __pyx_v_ges_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = ((!__pyx_t_6) != 0);
  if (__pyx_t_7) {

    /* "VocalTractLab/VocalTractLabApi.pyx":728
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )             # <<<<<<<<<<<<<<
 * 		return
 * 	gesFileName = ges_file_path.encode()
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_warnings); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_warn); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_the_specified_gestural_score_fil, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_8 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_2 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_v_ges_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_ges_file_path);
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":729
 * 	if not os.path.exists( ges_file_path ):
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	tract_file_path = FT.make_output_path( tract_file_path, ges_file_path.rsplit('.')[0] + '.tract' )
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":727
 * def _gestural_score_to_tract_sequence( args ):
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):             # <<<<<<<<<<<<<<
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":730
 * 		warnings.warn( 'the specified gestural score file path does not exist: {}. API call will be skipped.'.format( ges_file_path ) )
 * 		return
 * 	gesFileName = ges_file_path.encode()             # <<<<<<<<<<<<<<
 * 	tract_file_path = FT.make_output_path( tract_file_path, ges_file_path.rsplit('.')[0] + '.tract' )
 * 	tractSequenceFileName = tract_file_path.encode()
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ges_file_path, __pyx_n_s_encode); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 730, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_3 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 730, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_gesFileName = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":731
 * 		return
 * 	gesFileName = ges_file_path.encode()
 * 	tract_file_path = FT.make_output_path( tract_file_path, ges_file_path.rsplit('.')[0] + '.tract' )             # <<<<<<<<<<<<<<
 * 	tractSequenceFileName = tract_file_path.encode()
 * 	value = vtlGesturalScoreToTractSequence( gesFileName, tractSequenceFileName )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_FT); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_make_output_path); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_ges_file_path, __pyx_n_s_rsplit); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_1 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_kp_s__13) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_kp_s__13);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Add(__pyx_t_4, __pyx_kp_s_tract_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_9 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_9 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_tract_file_path, __pyx_t_1};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 731, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_tract_file_path, __pyx_t_1};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 731, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else
  #endif
  {
    __pyx_t_8 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 731, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_tract_file_path);
    __Pyx_GIVEREF(__pyx_v_tract_file_path);
    PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_9, __pyx_v_tract_file_path);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_9, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 731, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF_SET(__pyx_v_tract_file_path, __pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":732
 * 	gesFileName = ges_file_path.encode()
 * 	tract_file_path = FT.make_output_path( tract_file_path, ges_file_path.rsplit('.')[0] + '.tract' )
 * 	tractSequenceFileName = tract_file_path.encode()             # <<<<<<<<<<<<<<
 * 	value = vtlGesturalScoreToTractSequence( gesFileName, tractSequenceFileName )
 * 	if value != 0:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_tract_file_path, __pyx_n_s_encode); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 732, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_8) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_8) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 732, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_tractSequenceFileName = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":733
 * 	tract_file_path = FT.make_output_path( tract_file_path, ges_file_path.rsplit('.')[0] + '.tract' )
 * 	tractSequenceFileName = tract_file_path.encode()
 * 	value = vtlGesturalScoreToTractSequence( gesFileName, tractSequenceFileName )             # <<<<<<<<<<<<<<
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \
 */
  __pyx_t_10 = __Pyx_PyObject_AsString(__pyx_v_gesFileName); if (unlikely((!__pyx_t_10) && PyErr_Occurred())) __PYX_ERR(0, 733, __pyx_L1_error)
  __pyx_t_11 = __Pyx_PyObject_AsString(__pyx_v_tractSequenceFileName); if (unlikely((!__pyx_t_11) && PyErr_Occurred())) __PYX_ERR(0, 733, __pyx_L1_error)
  __pyx_v_value = vtlGesturalScoreToTractSequence(__pyx_t_10, __pyx_t_11);

  /* "VocalTractLab/VocalTractLabApi.pyx":734
 * 	tractSequenceFileName = tract_file_path.encode()
 * 	value = vtlGesturalScoreToTractSequence( gesFileName, tractSequenceFileName )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )
 */
  __pyx_t_7 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_7)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":736
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )             # <<<<<<<<<<<<<<
 * 	log.info( 'Created tractsequence file {} from gestural score file: {}'.format( tract_file_path, ges_file_path ) )
 * 	if return_sequence:
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlGesturalScor_2, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_8, __pyx_v_ges_file_path, __pyx_v_tract_file_path};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 736, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_8, __pyx_v_ges_file_path, __pyx_v_tract_file_path};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 736, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 736, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_9, __pyx_t_8);
      __Pyx_INCREF(__pyx_v_ges_file_path);
      __Pyx_GIVEREF(__pyx_v_ges_file_path);
      PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_9, __pyx_v_ges_file_path);
      __Pyx_INCREF(__pyx_v_tract_file_path);
      __Pyx_GIVEREF(__pyx_v_tract_file_path);
      PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_9, __pyx_v_tract_file_path);
      __pyx_t_8 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 736, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":735
 * 	value = vtlGesturalScoreToTractSequence( gesFileName, tractSequenceFileName )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \             # <<<<<<<<<<<<<<
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )
 * 	log.info( 'Created tractsequence file {} from gestural score file: {}'.format( tract_file_path, ges_file_path ) )
 */
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 735, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 735, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":734
 * 	tractSequenceFileName = tract_file_path.encode()
 * 	value = vtlGesturalScoreToTractSequence( gesFileName, tractSequenceFileName )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":737
 * 		raise ValueError('VTL API function vtlGesturalScoreToTractSequence returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )
 * 	log.info( 'Created tractsequence file {} from gestural score file: {}'.format( tract_file_path, ges_file_path ) )             # <<<<<<<<<<<<<<
 * 	if return_sequence:
 * 		return Motor_Sequence.from_tract_file( tract_file_path )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_log); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 737, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_info); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 737, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Created_tractsequence_file_from, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 737, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = NULL;
  __pyx_t_9 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
      __pyx_t_9 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_8)) {
    PyObject *__pyx_temp[3] = {__pyx_t_1, __pyx_v_tract_file_path, __pyx_v_ges_file_path};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 737, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
    PyObject *__pyx_temp[3] = {__pyx_t_1, __pyx_v_tract_file_path, __pyx_v_ges_file_path};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 737, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
  } else
  #endif
  {
    __pyx_t_12 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 737, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_12);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_12, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_tract_file_path);
    __Pyx_GIVEREF(__pyx_v_tract_file_path);
    PyTuple_SET_ITEM(__pyx_t_12, 0+__pyx_t_9, __pyx_v_tract_file_path);
    __Pyx_INCREF(__pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_v_ges_file_path);
    PyTuple_SET_ITEM(__pyx_t_12, 1+__pyx_t_9, __pyx_v_ges_file_path);
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_12, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 737, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
  }
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_2 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_t_3) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 737, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":738
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )
 * 	log.info( 'Created tractsequence file {} from gestural score file: {}'.format( tract_file_path, ges_file_path ) )
 * 	if return_sequence:             # <<<<<<<<<<<<<<
 * 		return Motor_Sequence.from_tract_file( tract_file_path )
 * 	return
 */
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_v_return_sequence); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 738, __pyx_L1_error)
  if (__pyx_t_7) {

    /* "VocalTractLab/VocalTractLabApi.pyx":739
 * 	log.info( 'Created tractsequence file {} from gestural score file: {}'.format( tract_file_path, ges_file_path ) )
 * 	if return_sequence:
 * 		return Motor_Sequence.from_tract_file( tract_file_path )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 739, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_from_tract_file); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 739, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    __pyx_t_2 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_4, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_tract_file_path);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 739, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":738
 * 			while processing gestural score file (input): {}, tract sequence file (output): {}'.format(value, ges_file_path, tract_file_path) )
 * 	log.info( 'Created tractsequence file {} from gestural score file: {}'.format( tract_file_path, ges_file_path ) )
 * 	if return_sequence:             # <<<<<<<<<<<<<<
 * 		return Motor_Sequence.from_tract_file( tract_file_path )
 * 	return
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":740
 * 	if return_sequence:
 * 		return Motor_Sequence.from_tract_file( tract_file_path )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _segment_sequence_to_gestural_score( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":725
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_tract_sequence( args ):             # <<<<<<<<<<<<<<
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._gestural_score_to_tract_sequence", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_v_tract_file_path);
  __Pyx_XDECREF(__pyx_v_return_sequence);
  __Pyx_XDECREF(__pyx_v_gesFileName);
  __Pyx_XDECREF(__pyx_v_tractSequenceFileName);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":742
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _segment_sequence_to_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_57_segment_sequence_to_gestural_score(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_57_segment_sequence_to_gestural_score = {"_segment_sequence_to_gestural_score", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_57_segment_sequence_to_gestural_score, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_57_segment_sequence_to_gestural_score(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_segment_sequence_to_gestural_score (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_56_segment_sequence_to_gestural_score(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_56_segment_sequence_to_gestural_score(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_seg_file_path = NULL;
  PyObject *__pyx_v_ges_file_path = NULL;
  PyObject *__pyx_v_verbose = NULL;
  PyObject *__pyx_v_segFileName = NULL;
  PyObject *__pyx_v_gesFileName = NULL;
  bool __pyx_v_enableConsoleOutput;
  int __pyx_v_value;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  bool __pyx_t_10;
  char const *__pyx_t_11;
  char const *__pyx_t_12;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_segment_sequence_to_gestural_score", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":743
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _segment_sequence_to_gestural_score( args ):
 * 	seg_file_path, ges_file_path, verbose = args             # <<<<<<<<<<<<<<
 * 	if not os.path.exists( seg_file_path ):
 * 		warnings.warn( 'the specified segment sequence file path does not exist: {}. API call will be skipped.'.format( seg_file_path ) )
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 743, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 743, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 743, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 743, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 743, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 2; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 3) < 0) __PYX_ERR(0, 743, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 743, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_seg_file_path = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_ges_file_path = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_verbose = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":744
 * def _segment_sequence_to_gestural_score( args ):
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):             # <<<<<<<<<<<<<<
 * 		warnings.warn( 'the specified segment sequence file path does not exist: {}. API call will be skipped.'.format( seg_file_path ) )
 * 		return
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_os); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 744, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_path); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 744, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_exists); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 744, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_1, __pyx_v_seg_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_seg_file_path);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 744, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 744, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = ((!__pyx_t_6) != 0);
  if (__pyx_t_7) {

    /* "VocalTractLab/VocalTractLabApi.pyx":745
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):
 * 		warnings.warn( 'the specified segment sequence file path does not exist: {}. API call will be skipped.'.format( seg_file_path ) )             # <<<<<<<<<<<<<<
 * 		return
 * 	ges_file_path = FT.make_output_path( ges_file_path, seg_file_path.rsplit('.')[0] + '.ges' )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_warnings); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 745, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_warn); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 745, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_the_specified_segment_sequence_f, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 745, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_8 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_2 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_v_seg_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_seg_file_path);
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 745, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 745, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":746
 * 	if not os.path.exists( seg_file_path ):
 * 		warnings.warn( 'the specified segment sequence file path does not exist: {}. API call will be skipped.'.format( seg_file_path ) )
 * 		return             # <<<<<<<<<<<<<<
 * 	ges_file_path = FT.make_output_path( ges_file_path, seg_file_path.rsplit('.')[0] + '.ges' )
 * 	segFileName = seg_file_path.encode()
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "VocalTractLab/VocalTractLabApi.pyx":744
 * def _segment_sequence_to_gestural_score( args ):
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):             # <<<<<<<<<<<<<<
 * 		warnings.warn( 'the specified segment sequence file path does not exist: {}. API call will be skipped.'.format( seg_file_path ) )
 * 		return
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":747
 * 		warnings.warn( 'the specified segment sequence file path does not exist: {}. API call will be skipped.'.format( seg_file_path ) )
 * 		return
 * 	ges_file_path = FT.make_output_path( ges_file_path, seg_file_path.rsplit('.')[0] + '.ges' )             # <<<<<<<<<<<<<<
 * 	segFileName = seg_file_path.encode()
 * 	gesFileName = ges_file_path.encode()
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_FT); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 747, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_make_output_path); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 747, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_seg_file_path, __pyx_n_s_rsplit); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 747, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_1 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_kp_s__13) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_kp_s__13);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 747, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 747, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Add(__pyx_t_4, __pyx_kp_s_ges); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 747, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_9 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_9 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_ges_file_path, __pyx_t_1};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 747, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_ges_file_path, __pyx_t_1};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 747, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else
  #endif
  {
    __pyx_t_8 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 747, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_v_ges_file_path);
    PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_9, __pyx_v_ges_file_path);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_9, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 747, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF_SET(__pyx_v_ges_file_path, __pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":748
 * 		return
 * 	ges_file_path = FT.make_output_path( ges_file_path, seg_file_path.rsplit('.')[0] + '.ges' )
 * 	segFileName = seg_file_path.encode()             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	cdef bool enableConsoleOutput = verbose
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_seg_file_path, __pyx_n_s_encode); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 748, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_8) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_8) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 748, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_segFileName = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":749
 * 	ges_file_path = FT.make_output_path( ges_file_path, seg_file_path.rsplit('.')[0] + '.ges' )
 * 	segFileName = seg_file_path.encode()
 * 	gesFileName = ges_file_path.encode()             # <<<<<<<<<<<<<<
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSegmentSequenceToGesturalScore( segFileName, gesFileName, enableConsoleOutput )
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ges_file_path, __pyx_n_s_encode); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_8) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_8) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_gesFileName = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":750
 * 	segFileName = seg_file_path.encode()
 * 	gesFileName = ges_file_path.encode()
 * 	cdef bool enableConsoleOutput = verbose             # <<<<<<<<<<<<<<
 * 	value = vtlSegmentSequenceToGesturalScore( segFileName, gesFileName, enableConsoleOutput )
 * 	if value != 0:
 */
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_verbose); if (unlikely((__pyx_t_10 == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 750, __pyx_L1_error)
  __pyx_v_enableConsoleOutput = __pyx_t_10;

  /* "VocalTractLab/VocalTractLabApi.pyx":751
 * 	gesFileName = ges_file_path.encode()
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSegmentSequenceToGesturalScore( segFileName, gesFileName, enableConsoleOutput )             # <<<<<<<<<<<<<<
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \
 */
  __pyx_t_11 = __Pyx_PyObject_AsString(__pyx_v_segFileName); if (unlikely((!__pyx_t_11) && PyErr_Occurred())) __PYX_ERR(0, 751, __pyx_L1_error)
  __pyx_t_12 = __Pyx_PyObject_AsString(__pyx_v_gesFileName); if (unlikely((!__pyx_t_12) && PyErr_Occurred())) __PYX_ERR(0, 751, __pyx_L1_error)
  __pyx_v_value = vtlSegmentSequenceToGesturalScore(__pyx_t_11, __pyx_t_12, __pyx_v_enableConsoleOutput);

  /* "VocalTractLab/VocalTractLabApi.pyx":752
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSegmentSequenceToGesturalScore( segFileName, gesFileName, enableConsoleOutput )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing segment sequence file (input): {}, gestural score file (output): {}'.format(value, seg_file_path, ges_file_path) )
 */
  __pyx_t_7 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_7)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":754
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing segment sequence file (input): {}, gestural score file (output): {}'.format(value, seg_file_path, ges_file_path) )             # <<<<<<<<<<<<<<
 * 	log.info( 'Created gestural score from segment sequence file: {}'.format( seg_file_path ) )
 * 	return
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlSegmentSeque, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_8, __pyx_v_seg_file_path, __pyx_v_ges_file_path};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_8, __pyx_v_seg_file_path, __pyx_v_ges_file_path};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_9, __pyx_t_8);
      __Pyx_INCREF(__pyx_v_seg_file_path);
      __Pyx_GIVEREF(__pyx_v_seg_file_path);
      PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_9, __pyx_v_seg_file_path);
      __Pyx_INCREF(__pyx_v_ges_file_path);
      __Pyx_GIVEREF(__pyx_v_ges_file_path);
      PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_9, __pyx_v_ges_file_path);
      __pyx_t_8 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":753
 * 	value = vtlSegmentSequenceToGesturalScore( segFileName, gesFileName, enableConsoleOutput )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \             # <<<<<<<<<<<<<<
 * 			while processing segment sequence file (input): {}, gestural score file (output): {}'.format(value, seg_file_path, ges_file_path) )
 * 	log.info( 'Created gestural score from segment sequence file: {}'.format( seg_file_path ) )
 */
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 753, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 753, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":752
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSegmentSequenceToGesturalScore( segFileName, gesFileName, enableConsoleOutput )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError('VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing segment sequence file (input): {}, gestural score file (output): {}'.format(value, seg_file_path, ges_file_path) )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":755
 * 		raise ValueError('VTL API function vtlSegmentSequenceToGesturalScore returned the Errorcode: {}  (See API doc for info.) \
 * 			while processing segment sequence file (input): {}, gestural score file (output): {}'.format(value, seg_file_path, ges_file_path) )
 * 	log.info( 'Created gestural score from segment sequence file: {}'.format( seg_file_path ) )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_log); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 755, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_info); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 755, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Created_gestural_score_from_segm, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 755, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_1, __pyx_v_seg_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_v_seg_file_path);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 755, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_2 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_t_3) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 755, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":756
 * 			while processing segment sequence file (input): {}, gestural score file (output): {}'.format(value, seg_file_path, ges_file_path) )
 * 	log.info( 'Created gestural score from segment sequence file: {}'.format( seg_file_path ) )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _synth_block( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":742
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _segment_sequence_to_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._segment_sequence_to_gestural_score", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_seg_file_path);
  __Pyx_XDECREF(__pyx_v_ges_file_path);
  __Pyx_XDECREF(__pyx_v_verbose);
  __Pyx_XDECREF(__pyx_v_segFileName);
  __Pyx_XDECREF(__pyx_v_gesFileName);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":758
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _synth_block( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_59_synth_block(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_59_synth_block = {"_synth_block", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_59_synth_block, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_59_synth_block(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_synth_block (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_58_synth_block(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_58_synth_block(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_state_samples = NULL;
  PyObject *__pyx_v_verbose = NULL;
  PyObject *__pyx_v_constants = NULL;
  int __pyx_v_numFrames;
  PyArrayObject *__pyx_v_tractParams = 0;
  PyArrayObject *__pyx_v_glottisParams = 0;
  int __pyx_v_frameStep_samples;
  PyArrayObject *__pyx_v_audio = 0;
  bool __pyx_v_enableConsoleOutput;
  int __pyx_v_value;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_audio;
  __Pyx_Buffer __pyx_pybuffer_audio;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_glottisParams;
  __Pyx_Buffer __pyx_pybuffer_glottisParams;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tractParams;
  __Pyx_Buffer __pyx_pybuffer_tractParams;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  int __pyx_t_6;
  int __pyx_t_7;
  PyArrayObject *__pyx_t_8 = NULL;
  PyArrayObject *__pyx_t_9 = NULL;
  PyArrayObject *__pyx_t_10 = NULL;
  bool __pyx_t_11;
  Py_ssize_t __pyx_t_12;
  Py_ssize_t __pyx_t_13;
  Py_ssize_t __pyx_t_14;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_synth_block", 0);
  __pyx_pybuffer_tractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_tractParams.refcount = 0;
  __pyx_pybuffernd_tractParams.data = NULL;
  __pyx_pybuffernd_tractParams.rcbuffer = &__pyx_pybuffer_tractParams;
  __pyx_pybuffer_glottisParams.pybuffer.buf = NULL;
  __pyx_pybuffer_glottisParams.refcount = 0;
  __pyx_pybuffernd_glottisParams.data = NULL;
  __pyx_pybuffernd_glottisParams.rcbuffer = &__pyx_pybuffer_glottisParams;
  __pyx_pybuffer_audio.pybuffer.buf = NULL;
  __pyx_pybuffer_audio.refcount = 0;
  __pyx_pybuffernd_audio.data = NULL;
  __pyx_pybuffernd_audio.rcbuffer = &__pyx_pybuffer_audio;

  /* "VocalTractLab/VocalTractLabApi.pyx":759
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _synth_block( args ):
 * 	motor_sequence, state_samples, verbose = args             # <<<<<<<<<<<<<<
 * 	if state_samples == None:
 * 		constants = get_constants()
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 759, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 759, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 759, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 759, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 759, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 2; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 3) < 0) __PYX_ERR(0, 759, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 759, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_motor_sequence = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_state_samples = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_verbose = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":760
 * def _synth_block( args ):
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:             # <<<<<<<<<<<<<<
 * 		constants = get_constants()
 * 		state_samples = constants[ 'n_samples_per_state' ]
 */
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_state_samples, Py_None, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 760, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 760, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_6) {

    /* "VocalTractLab/VocalTractLabApi.pyx":761
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:
 * 		constants = get_constants()             # <<<<<<<<<<<<<<
 * 		state_samples = constants[ 'n_samples_per_state' ]
 * 	cdef int numFrames = motor_sequence.length
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 761, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 761, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_constants = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":762
 * 	if state_samples == None:
 * 		constants = get_constants()
 * 		state_samples = constants[ 'n_samples_per_state' ]             # <<<<<<<<<<<<<<
 * 	cdef int numFrames = motor_sequence.length
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = motor_sequence.to_supra_glottal_states().ravel()
 */
    __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_samples_per_state); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 762, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF_SET(__pyx_v_state_samples, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":760
 * def _synth_block( args ):
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:             # <<<<<<<<<<<<<<
 * 		constants = get_constants()
 * 		state_samples = constants[ 'n_samples_per_state' ]
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":763
 * 		constants = get_constants()
 * 		state_samples = constants[ 'n_samples_per_state' ]
 * 	cdef int numFrames = motor_sequence.length             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = motor_sequence.to_supra_glottal_states().ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = motor_sequence.to_sub_glottal_states().ravel()
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_length); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 763, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 763, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_numFrames = __pyx_t_7;

  /* "VocalTractLab/VocalTractLabApi.pyx":764
 * 		state_samples = constants[ 'n_samples_per_state' ]
 * 	cdef int numFrames = motor_sequence.length
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = motor_sequence.to_supra_glottal_states().ravel()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = motor_sequence.to_sub_glottal_states().ravel()
 * 	cdef int frameStep_samples = state_samples
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_to_supra_glottal_states); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 764, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_2 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 764, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ravel); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 764, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_3 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 764, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 764, __pyx_L1_error)
  __pyx_t_8 = ((PyArrayObject *)__pyx_t_3);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_8, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 764, __pyx_L1_error)
    } else {__pyx_pybuffernd_tractParams.diminfo[0].strides = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tractParams.diminfo[0].shape = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_8 = 0;
  __pyx_v_tractParams = ((PyArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":765
 * 	cdef int numFrames = motor_sequence.length
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = motor_sequence.to_supra_glottal_states().ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = motor_sequence.to_sub_glottal_states().ravel()             # <<<<<<<<<<<<<<
 * 	cdef int frameStep_samples = state_samples
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio = np.zeros( motor_sequence.length * state_samples, dtype='float64' )
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_to_sub_glottal_states); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ravel); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 765, __pyx_L1_error)
  __pyx_t_9 = ((PyArrayObject *)__pyx_t_3);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_glottisParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_9, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_glottisParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 765, __pyx_L1_error)
    } else {__pyx_pybuffernd_glottisParams.diminfo[0].strides = __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_glottisParams.diminfo[0].shape = __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_9 = 0;
  __pyx_v_glottisParams = ((PyArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":766
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = motor_sequence.to_supra_glottal_states().ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = motor_sequence.to_sub_glottal_states().ravel()
 * 	cdef int frameStep_samples = state_samples             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio = np.zeros( motor_sequence.length * state_samples, dtype='float64' )
 * 	cdef bool enableConsoleOutput = verbose
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_state_samples); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 766, __pyx_L1_error)
  __pyx_v_frameStep_samples = __pyx_t_7;

  /* "VocalTractLab/VocalTractLabApi.pyx":767
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] glottisParams = motor_sequence.to_sub_glottal_states().ravel()
 * 	cdef int frameStep_samples = state_samples
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio = np.zeros( motor_sequence.length * state_samples, dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSynthBlock( &tractParams[0], &glottisParams[0], numFrames, frameStep_samples, &audio[0], enableConsoleOutput )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zeros); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_length); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_3, __pyx_v_state_samples); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 767, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 767, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 767, __pyx_L1_error)
  __pyx_t_10 = ((PyArrayObject *)__pyx_t_4);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_audio.rcbuffer->pybuffer, (PyObject*)__pyx_t_10, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_audio = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_audio.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 767, __pyx_L1_error)
    } else {__pyx_pybuffernd_audio.diminfo[0].strides = __pyx_pybuffernd_audio.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_audio.diminfo[0].shape = __pyx_pybuffernd_audio.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_10 = 0;
  __pyx_v_audio = ((PyArrayObject *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":768
 * 	cdef int frameStep_samples = state_samples
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio = np.zeros( motor_sequence.length * state_samples, dtype='float64' )
 * 	cdef bool enableConsoleOutput = verbose             # <<<<<<<<<<<<<<
 * 	value = vtlSynthBlock( &tractParams[0], &glottisParams[0], numFrames, frameStep_samples, &audio[0], enableConsoleOutput )
 * 	if value != 0:
 */
  __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_v_verbose); if (unlikely((__pyx_t_11 == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 768, __pyx_L1_error)
  __pyx_v_enableConsoleOutput = __pyx_t_11;

  /* "VocalTractLab/VocalTractLabApi.pyx":769
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] audio = np.zeros( motor_sequence.length * state_samples, dtype='float64' )
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSynthBlock( &tractParams[0], &glottisParams[0], numFrames, frameStep_samples, &audio[0], enableConsoleOutput )             # <<<<<<<<<<<<<<
 * 	if value != 0:
 * 		raise ValueError( 'VTL API function vtlSynthBlock returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 */
  __pyx_t_12 = 0;
  __pyx_t_7 = -1;
  if (__pyx_t_12 < 0) {
    __pyx_t_12 += __pyx_pybuffernd_tractParams.diminfo[0].shape;
    if (unlikely(__pyx_t_12 < 0)) __pyx_t_7 = 0;
  } else if (unlikely(__pyx_t_12 >= __pyx_pybuffernd_tractParams.diminfo[0].shape)) __pyx_t_7 = 0;
  if (unlikely(__pyx_t_7 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_7);
    __PYX_ERR(0, 769, __pyx_L1_error)
  }
  __pyx_t_13 = 0;
  __pyx_t_7 = -1;
  if (__pyx_t_13 < 0) {
    __pyx_t_13 += __pyx_pybuffernd_glottisParams.diminfo[0].shape;
    if (unlikely(__pyx_t_13 < 0)) __pyx_t_7 = 0;
  } else if (unlikely(__pyx_t_13 >= __pyx_pybuffernd_glottisParams.diminfo[0].shape)) __pyx_t_7 = 0;
  if (unlikely(__pyx_t_7 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_7);
    __PYX_ERR(0, 769, __pyx_L1_error)
  }
  __pyx_t_14 = 0;
  __pyx_t_7 = -1;
  if (__pyx_t_14 < 0) {
    __pyx_t_14 += __pyx_pybuffernd_audio.diminfo[0].shape;
    if (unlikely(__pyx_t_14 < 0)) __pyx_t_7 = 0;
  } else if (unlikely(__pyx_t_14 >= __pyx_pybuffernd_audio.diminfo[0].shape)) __pyx_t_7 = 0;
  if (unlikely(__pyx_t_7 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_7);
    __PYX_ERR(0, 769, __pyx_L1_error)
  }
  __pyx_v_value = vtlSynthBlock((&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf, __pyx_t_12, __pyx_pybuffernd_tractParams.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_glottisParams.rcbuffer->pybuffer.buf, __pyx_t_13, __pyx_pybuffernd_glottisParams.diminfo[0].strides))), __pyx_v_numFrames, __pyx_v_frameStep_samples, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_audio.rcbuffer->pybuffer.buf, __pyx_t_14, __pyx_pybuffernd_audio.diminfo[0].strides))), __pyx_v_enableConsoleOutput);

  /* "VocalTractLab/VocalTractLabApi.pyx":770
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSynthBlock( &tractParams[0], &glottisParams[0], numFrames, frameStep_samples, &audio[0], enableConsoleOutput )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'VTL API function vtlSynthBlock returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	return audio
 */
  __pyx_t_6 = ((__pyx_v_value != 0) != 0);
  if (unlikely(__pyx_t_6)) {

    /* "VocalTractLab/VocalTractLabApi.pyx":771
 * 	value = vtlSynthBlock( &tractParams[0], &glottisParams[0], numFrames, frameStep_samples, &audio[0], enableConsoleOutput )
 * 	if value != 0:
 * 		raise ValueError( 'VTL API function vtlSynthBlock returned the Errorcode: {}  (See API doc for info.)'.format( value ) )             # <<<<<<<<<<<<<<
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_VTL_API_function_vtlSynthBlock_r, __pyx_n_s_format); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 771, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 771, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_4 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_3);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 771, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 771, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 771, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":770
 * 	cdef bool enableConsoleOutput = verbose
 * 	value = vtlSynthBlock( &tractParams[0], &glottisParams[0], numFrames, frameStep_samples, &audio[0], enableConsoleOutput )
 * 	if value != 0:             # <<<<<<<<<<<<<<
 * 		raise ValueError( 'VTL API function vtlSynthBlock returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	return audio
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":772
 * 	if value != 0:
 * 		raise ValueError( 'VTL API function vtlSynthBlock returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	return audio             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_audio( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_audio));
  __pyx_r = ((PyObject *)__pyx_v_audio);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":758
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _synth_block( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_glottisParams.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._synth_block", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_audio.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_glottisParams.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_state_samples);
  __Pyx_XDECREF(__pyx_v_verbose);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF((PyObject *)__pyx_v_tractParams);
  __Pyx_XDECREF((PyObject *)__pyx_v_glottisParams);
  __Pyx_XDECREF((PyObject *)__pyx_v_audio);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":774
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_61_tract_sequence_to_audio(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_61_tract_sequence_to_audio = {"_tract_sequence_to_audio", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_61_tract_sequence_to_audio, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_61_tract_sequence_to_audio(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_tract_sequence_to_audio (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_60_tract_sequence_to_audio(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_60_tract_sequence_to_audio(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_motor_sequence_data = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_save_file = NULL;
  PyObject *__pyx_v_normalize_audio = NULL;
  PyObject *__pyx_v_sr = NULL;
  PyObject *__pyx_v_verbose = NULL;
  PyObject *__pyx_v_tract_file_path = NULL;
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_motor_score = NULL;
  PyObject *__pyx_v_audio = NULL;
  PyObject *__pyx_v_constants = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *(*__pyx_t_8)(PyObject *);
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tract_sequence_to_audio", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":776
 * def _tract_sequence_to_audio( args ):
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args             # <<<<<<<<<<<<<<
 * 	if isinstance( motor_sequence_data, str ):
 * 		tract_file_path = motor_sequence_data
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 6)) {
      if (size > 6) __Pyx_RaiseTooManyValuesError(6);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 776, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyTuple_GET_ITEM(sequence, 5); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyList_GET_ITEM(sequence, 5); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_6);
    #else
    {
      Py_ssize_t i;
      PyObject** temps[6] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6};
      for (i=0; i < 6; i++) {
        PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 776, __pyx_L1_error)
        __Pyx_GOTREF(item);
        *(temps[i]) = item;
      }
    }
    #endif
  } else {
    Py_ssize_t index = -1;
    PyObject** temps[6] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6};
    __pyx_t_7 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 776, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = Py_TYPE(__pyx_t_7)->tp_iternext;
    for (index=0; index < 6; index++) {
      PyObject* item = __pyx_t_8(__pyx_t_7); if (unlikely(!item)) goto __pyx_L3_unpacking_failed;
      __Pyx_GOTREF(item);
      *(temps[index]) = item;
    }
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_7), 6) < 0) __PYX_ERR(0, 776, __pyx_L1_error)
    __pyx_t_8 = NULL;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_8 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 776, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_motor_sequence_data = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_audio_file_path = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_save_file = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_normalize_audio = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_v_sr = __pyx_t_5;
  __pyx_t_5 = 0;
  __pyx_v_verbose = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":777
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	if isinstance( motor_sequence_data, str ):             # <<<<<<<<<<<<<<
 * 		tract_file_path = motor_sequence_data
 * 		if not os.path.exists( tract_file_path ):
 */
  __pyx_t_9 = PyString_Check(__pyx_v_motor_sequence_data); 
  __pyx_t_10 = (__pyx_t_9 != 0);
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":778
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	if isinstance( motor_sequence_data, str ):
 * 		tract_file_path = motor_sequence_data             # <<<<<<<<<<<<<<
 * 		if not os.path.exists( tract_file_path ):
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 */
    __Pyx_INCREF(__pyx_v_motor_sequence_data);
    __pyx_v_tract_file_path = __pyx_v_motor_sequence_data;

    /* "VocalTractLab/VocalTractLabApi.pyx":779
 * 	if isinstance( motor_sequence_data, str ):
 * 		tract_file_path = motor_sequence_data
 * 		if not os.path.exists( tract_file_path ):             # <<<<<<<<<<<<<<
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_os); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 779, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_path); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 779, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_exists); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 779, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_4, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_tract_file_path);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 779, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 779, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_9 = ((!__pyx_t_10) != 0);
    if (__pyx_t_9) {

      /* "VocalTractLab/VocalTractLabApi.pyx":780
 * 		tract_file_path = motor_sequence_data
 * 		if not os.path.exists( tract_file_path ):
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )             # <<<<<<<<<<<<<<
 * 			return
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 */
      __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_warnings); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 780, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_warn); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 780, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_the_specified_tract_sequence_fil, __pyx_n_s_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 780, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_2)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      __pyx_t_5 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_2, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_tract_file_path);
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 780, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_3)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_3);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      __pyx_t_6 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_3, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5);
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 780, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":781
 * 		if not os.path.exists( tract_file_path ):
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return             # <<<<<<<<<<<<<<
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 * 	elif isinstance( motor_sequence_data, Motor_Score ):
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_r = Py_None; __Pyx_INCREF(Py_None);
      goto __pyx_L0;

      /* "VocalTractLab/VocalTractLabApi.pyx":779
 * 	if isinstance( motor_sequence_data, str ):
 * 		tract_file_path = motor_sequence_data
 * 		if not os.path.exists( tract_file_path ):             # <<<<<<<<<<<<<<
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return
 */
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":782
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )             # <<<<<<<<<<<<<<
 * 	elif isinstance( motor_sequence_data, Motor_Score ):
 * 		motor_score = motor_sequence_data
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 782, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_from_tract_file); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 782, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_4, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_tract_file_path);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 782, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_motor_sequence = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":777
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 * 	if isinstance( motor_sequence_data, str ):             # <<<<<<<<<<<<<<
 * 		tract_file_path = motor_sequence_data
 * 		if not os.path.exists( tract_file_path ):
 */
    goto __pyx_L5;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":783
 * 			return
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 * 	elif isinstance( motor_sequence_data, Motor_Score ):             # <<<<<<<<<<<<<<
 * 		motor_score = motor_sequence_data
 * 		motor_sequence = motor_score.to_motor_sequence()
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_Motor_Score); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 783, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_9 = PyObject_IsInstance(__pyx_v_motor_sequence_data, __pyx_t_6); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 783, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_10 = (__pyx_t_9 != 0);
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":784
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 * 	elif isinstance( motor_sequence_data, Motor_Score ):
 * 		motor_score = motor_sequence_data             # <<<<<<<<<<<<<<
 * 		motor_sequence = motor_score.to_motor_sequence()
 * 	else:
 */
    __Pyx_INCREF(__pyx_v_motor_sequence_data);
    __pyx_v_motor_score = __pyx_v_motor_sequence_data;

    /* "VocalTractLab/VocalTractLabApi.pyx":785
 * 	elif isinstance( motor_sequence_data, Motor_Score ):
 * 		motor_score = motor_sequence_data
 * 		motor_sequence = motor_score.to_motor_sequence()             # <<<<<<<<<<<<<<
 * 	else:
 * 		motor_sequence = motor_sequence_data
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_score, __pyx_n_s_to_motor_sequence); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 785, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 785, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_motor_sequence = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":783
 * 			return
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 * 	elif isinstance( motor_sequence_data, Motor_Score ):             # <<<<<<<<<<<<<<
 * 		motor_score = motor_sequence_data
 * 		motor_sequence = motor_score.to_motor_sequence()
 */
    goto __pyx_L5;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":787
 * 		motor_sequence = motor_score.to_motor_sequence()
 * 	else:
 * 		motor_sequence = motor_sequence_data             # <<<<<<<<<<<<<<
 * 	audio = _synth_block( ( motor_sequence, None, verbose ) )
 * 	constants = get_constants()
 */
  /*else*/ {
    __Pyx_INCREF(__pyx_v_motor_sequence_data);
    __pyx_v_motor_sequence = __pyx_v_motor_sequence_data;
  }
  __pyx_L5:;

  /* "VocalTractLab/VocalTractLabApi.pyx":788
 * 	else:
 * 		motor_sequence = motor_sequence_data
 * 	audio = _synth_block( ( motor_sequence, None, verbose ) )             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	if sr == None:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_synth_block); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 788, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 788, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_motor_sequence);
  __Pyx_GIVEREF(__pyx_v_motor_sequence);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_motor_sequence);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  PyTuple_SET_ITEM(__pyx_t_4, 1, Py_None);
  __Pyx_INCREF(__pyx_v_verbose);
  __Pyx_GIVEREF(__pyx_v_verbose);
  PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_v_verbose);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_6 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_3, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_4);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 788, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_audio = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":789
 * 		motor_sequence = motor_sequence_data
 * 	audio = _synth_block( ( motor_sequence, None, verbose ) )
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 789, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 789, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_constants = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":790
 * 	audio = _synth_block( ( motor_sequence, None, verbose ) )
 * 	constants = get_constants()
 * 	if sr == None:             # <<<<<<<<<<<<<<
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if save_file:
 */
  __pyx_t_6 = PyObject_RichCompare(__pyx_v_sr, Py_None, Py_EQ); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 790, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 790, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":791
 * 	constants = get_constants()
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]             # <<<<<<<<<<<<<<
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 */
    __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 791, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF_SET(__pyx_v_sr, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":790
 * 	audio = _synth_block( ( motor_sequence, None, verbose ) )
 * 	constants = get_constants()
 * 	if sr == None:             # <<<<<<<<<<<<<<
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if save_file:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":792
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if save_file:             # <<<<<<<<<<<<<<
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 * 	if sr != constants[ 'samplerate_audio' ]:
 */
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_save_file); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 792, __pyx_L1_error)
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":793
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )             # <<<<<<<<<<<<<<
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample(
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_FT); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_make_output_path); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_name); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_rsplit); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_5 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_kp_s__13) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_kp_s__13);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyNumber_Add(__pyx_t_2, __pyx_kp_s_wav); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 793, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_audio_file_path, __pyx_t_5};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 793, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_audio_file_path, __pyx_t_5};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 793, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_3 = PyTuple_New(2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 793, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      if (__pyx_t_2) {
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2); __pyx_t_2 = NULL;
      }
      __Pyx_INCREF(__pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_v_audio_file_path);
      PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_11, __pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_11, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_3, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 793, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_audio_file_path, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":792
 * 	if sr == None:
 * 		sr = constants[ 'samplerate_audio' ]
 * 	if save_file:             # <<<<<<<<<<<<<<
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 * 	if sr != constants[ 'samplerate_audio' ]:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":794
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 * 	if sr != constants[ 'samplerate_audio' ]:             # <<<<<<<<<<<<<<
 * 		audio = librosa.resample(
 * 			y = audio,
 */
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = PyObject_RichCompare(__pyx_v_sr, __pyx_t_6, Py_NE); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":795
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample(             # <<<<<<<<<<<<<<
 * 			y = audio,
 * 			orig_sr = constants[ 'samplerate_audio' ],
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_librosa); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 795, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_resample); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 795, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":796
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample(
 * 			y = audio,             # <<<<<<<<<<<<<<
 * 			orig_sr = constants[ 'samplerate_audio' ],
 * 			target_sr = sr,
 */
    __pyx_t_4 = __Pyx_PyDict_NewPresized(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 796, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_y, __pyx_v_audio) < 0) __PYX_ERR(0, 796, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":797
 * 		audio = librosa.resample(
 * 			y = audio,
 * 			orig_sr = constants[ 'samplerate_audio' ],             # <<<<<<<<<<<<<<
 * 			target_sr = sr,
 * 			)
 */
    __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_samplerate_audio); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 797, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_orig_sr, __pyx_t_3) < 0) __PYX_ERR(0, 796, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":798
 * 			y = audio,
 * 			orig_sr = constants[ 'samplerate_audio' ],
 * 			target_sr = sr,             # <<<<<<<<<<<<<<
 * 			)
 * 	if normalize_audio != None:
 */
    if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_target_sr, __pyx_v_sr) < 0) __PYX_ERR(0, 796, __pyx_L1_error)

    /* "VocalTractLab/VocalTractLabApi.pyx":795
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 * 	if sr != constants[ 'samplerate_audio' ]:
 * 		audio = librosa.resample(             # <<<<<<<<<<<<<<
 * 			y = audio,
 * 			orig_sr = constants[ 'samplerate_audio' ],
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_empty_tuple, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 795, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_audio, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":794
 * 	if save_file:
 * 		audio_file_path = FT.make_output_path( audio_file_path, motor_sequence.name.rsplit( '.' )[0] + '.wav' )
 * 	if sr != constants[ 'samplerate_audio' ]:             # <<<<<<<<<<<<<<
 * 		audio = librosa.resample(
 * 			y = audio,
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":800
 * 			target_sr = sr,
 * 			)
 * 	if normalize_audio != None:             # <<<<<<<<<<<<<<
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if save_file:
 */
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_normalize_audio, Py_None, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 800, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 800, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":801
 * 			)
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )             # <<<<<<<<<<<<<<
 * 	if save_file:
 * 		AT.write( audio, audio_file_path, sr )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_AT); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 801, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_normalize); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 801, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_audio, __pyx_v_normalize_audio};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 801, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_audio, __pyx_v_normalize_audio};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 801, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(2+__pyx_t_11); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 801, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (__pyx_t_4) {
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
      }
      __Pyx_INCREF(__pyx_v_audio);
      __Pyx_GIVEREF(__pyx_v_audio);
      PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_11, __pyx_v_audio);
      __Pyx_INCREF(__pyx_v_normalize_audio);
      __Pyx_GIVEREF(__pyx_v_normalize_audio);
      PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_11, __pyx_v_normalize_audio);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 801, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_audio, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":800
 * 			target_sr = sr,
 * 			)
 * 	if normalize_audio != None:             # <<<<<<<<<<<<<<
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if save_file:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":802
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if save_file:             # <<<<<<<<<<<<<<
 * 		AT.write( audio, audio_file_path, sr )
 * 	log.info( 'Audio generated from motor_sequence: {}'.format( motor_sequence.name ) )
 */
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_save_file); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 802, __pyx_L1_error)
  if (__pyx_t_10) {

    /* "VocalTractLab/VocalTractLabApi.pyx":803
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if save_file:
 * 		AT.write( audio, audio_file_path, sr )             # <<<<<<<<<<<<<<
 * 	log.info( 'Audio generated from motor_sequence: {}'.format( motor_sequence.name ) )
 * 	return audio
 */
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_AT); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 803, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_write); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 803, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    __pyx_t_11 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_11 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_v_audio, __pyx_v_audio_file_path, __pyx_v_sr};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 803, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_v_audio, __pyx_v_audio_file_path, __pyx_v_sr};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 803, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 803, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_INCREF(__pyx_v_audio);
      __Pyx_GIVEREF(__pyx_v_audio);
      PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_11, __pyx_v_audio);
      __Pyx_INCREF(__pyx_v_audio_file_path);
      __Pyx_GIVEREF(__pyx_v_audio_file_path);
      PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_11, __pyx_v_audio_file_path);
      __Pyx_INCREF(__pyx_v_sr);
      __Pyx_GIVEREF(__pyx_v_sr);
      PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_11, __pyx_v_sr);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 803, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":802
 * 	if normalize_audio != None:
 * 		audio = AT.normalize( audio, normalize_audio )
 * 	if save_file:             # <<<<<<<<<<<<<<
 * 		AT.write( audio, audio_file_path, sr )
 * 	log.info( 'Audio generated from motor_sequence: {}'.format( motor_sequence.name ) )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":804
 * 	if save_file:
 * 		AT.write( audio, audio_file_path, sr )
 * 	log.info( 'Audio generated from motor_sequence: {}'.format( motor_sequence.name ) )             # <<<<<<<<<<<<<<
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_log); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_info); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Audio_generated_from_motor_seque, __pyx_n_s_format); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_name); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_5 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_1, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_2);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_3 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_6, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 804, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":805
 * 		AT.write( audio, audio_file_path, sr )
 * 	log.info( 'Audio generated from motor_sequence: {}'.format( motor_sequence.name ) )
 * 	return audio             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_spectrogram( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_audio);
  __pyx_r = __pyx_v_audio;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":774
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._tract_sequence_to_audio", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_motor_sequence_data);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_save_file);
  __Pyx_XDECREF(__pyx_v_normalize_audio);
  __Pyx_XDECREF(__pyx_v_sr);
  __Pyx_XDECREF(__pyx_v_verbose);
  __Pyx_XDECREF(__pyx_v_tract_file_path);
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_motor_score);
  __Pyx_XDECREF(__pyx_v_audio);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":807
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_spectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_63_motor_sequence_to_spectrogram(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_63_motor_sequence_to_spectrogram = {"_motor_sequence_to_spectrogram", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_63_motor_sequence_to_spectrogram, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_63_motor_sequence_to_spectrogram(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_motor_sequence_to_spectrogram (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_62_motor_sequence_to_spectrogram(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_62_motor_sequence_to_spectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_motor_sequence_data = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_spectrogram_file_path = NULL;
  PyObject *__pyx_v_save_file = NULL;
  PyObject *__pyx_v_normalize_audio = NULL;
  PyObject *__pyx_v_sr = NULL;
  PyObject *__pyx_v_spectrogram_kwargs = NULL;
  PyObject *__pyx_v_verbose = NULL;
  PyObject *__pyx_v_audio_args = NULL;
  PyObject *__pyx_v_audio = NULL;
  PyObject *__pyx_v_spectrogram = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_motor_sequence_to_spectrogram", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":817
 * 		spectrogram_kwargs,
 * 		verbose,
 * 	) = args             # <<<<<<<<<<<<<<
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )
 * 	audio = _tract_sequence_to_audio( audio_args )
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 8)) {
      if (size > 8) __Pyx_RaiseTooManyValuesError(8);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 809, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyTuple_GET_ITEM(sequence, 5); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 6); 
      __pyx_t_8 = PyTuple_GET_ITEM(sequence, 7); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyList_GET_ITEM(sequence, 5); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 6); 
      __pyx_t_8 = PyList_GET_ITEM(sequence, 7); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_t_7);
    __Pyx_INCREF(__pyx_t_8);
    #else
    {
      Py_ssize_t i;
      PyObject** temps[8] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6,&__pyx_t_7,&__pyx_t_8};
      for (i=0; i < 8; i++) {
        PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 809, __pyx_L1_error)
        __Pyx_GOTREF(item);
        *(temps[i]) = item;
      }
    }
    #endif
  } else {
    Py_ssize_t index = -1;
    PyObject** temps[8] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6,&__pyx_t_7,&__pyx_t_8};
    __pyx_t_9 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 809, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_10 = Py_TYPE(__pyx_t_9)->tp_iternext;
    for (index=0; index < 8; index++) {
      PyObject* item = __pyx_t_10(__pyx_t_9); if (unlikely(!item)) goto __pyx_L3_unpacking_failed;
      __Pyx_GOTREF(item);
      *(temps[index]) = item;
    }
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_9), 8) < 0) __PYX_ERR(0, 809, __pyx_L1_error)
    __pyx_t_10 = NULL;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __pyx_t_10 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 809, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":809
 * def _motor_sequence_to_spectrogram( args ):
 * 	(
 * 		motor_sequence_data,             # <<<<<<<<<<<<<<
 * 		audio_file_path,
 * 		spectrogram_file_path,
 */
  __pyx_v_motor_sequence_data = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_audio_file_path = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_spectrogram_file_path = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_save_file = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_v_normalize_audio = __pyx_t_5;
  __pyx_t_5 = 0;
  __pyx_v_sr = __pyx_t_6;
  __pyx_t_6 = 0;
  __pyx_v_spectrogram_kwargs = __pyx_t_7;
  __pyx_t_7 = 0;
  __pyx_v_verbose = __pyx_t_8;
  __pyx_t_8 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":818
 * 		verbose,
 * 	) = args
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )             # <<<<<<<<<<<<<<
 * 	audio = _tract_sequence_to_audio( audio_args )
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 */
  __pyx_t_8 = PyTuple_New(6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 818, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_INCREF(__pyx_v_motor_sequence_data);
  __Pyx_GIVEREF(__pyx_v_motor_sequence_data);
  PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_motor_sequence_data);
  __Pyx_INCREF(__pyx_v_audio_file_path);
  __Pyx_GIVEREF(__pyx_v_audio_file_path);
  PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_v_audio_file_path);
  __Pyx_INCREF(__pyx_v_save_file);
  __Pyx_GIVEREF(__pyx_v_save_file);
  PyTuple_SET_ITEM(__pyx_t_8, 2, __pyx_v_save_file);
  __Pyx_INCREF(__pyx_v_normalize_audio);
  __Pyx_GIVEREF(__pyx_v_normalize_audio);
  PyTuple_SET_ITEM(__pyx_t_8, 3, __pyx_v_normalize_audio);
  __Pyx_INCREF(__pyx_v_sr);
  __Pyx_GIVEREF(__pyx_v_sr);
  PyTuple_SET_ITEM(__pyx_t_8, 4, __pyx_v_sr);
  __Pyx_INCREF(__pyx_v_verbose);
  __Pyx_GIVEREF(__pyx_v_verbose);
  PyTuple_SET_ITEM(__pyx_t_8, 5, __pyx_v_verbose);
  __pyx_v_audio_args = ((PyObject*)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":819
 * 	) = args
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )
 * 	audio = _tract_sequence_to_audio( audio_args )             # <<<<<<<<<<<<<<
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	if spectrogram_file_path != None: # TODO: replace with saveFile
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_tract_sequence_to_audio); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 819, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
    }
  }
  __pyx_t_8 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_7, __pyx_t_6, __pyx_v_audio_args) : __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_v_audio_args);
  __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 819, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_audio = __pyx_t_8;
  __pyx_t_8 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":820
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )
 * 	audio = _tract_sequence_to_audio( audio_args )
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2             # <<<<<<<<<<<<<<
 * 	if spectrogram_file_path != None: # TODO: replace with saveFile
 * 		spectrogram_file_path = FT.make_output_path( spectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_np); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_abs); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_librosa); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_stft); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_y, __pyx_v_audio) < 0) __PYX_ERR(0, 820, __pyx_L1_error)
  __pyx_t_7 = __pyx_t_4;
  __pyx_t_4 = 0;
  if (unlikely(__pyx_v_spectrogram_kwargs == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "argument after ** must be a mapping, not NoneType");
    __PYX_ERR(0, 820, __pyx_L1_error)
  }
  if (__Pyx_MergeKeywords(__pyx_t_7, __pyx_v_spectrogram_kwargs) < 0) __PYX_ERR(0, 820, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_empty_tuple, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_8 = (__pyx_t_7) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_7, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyNumber_Power(__pyx_t_8, __pyx_int_2, Py_None); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_spectrogram = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":821
 * 	audio = _tract_sequence_to_audio( audio_args )
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	if spectrogram_file_path != None: # TODO: replace with saveFile             # <<<<<<<<<<<<<<
 * 		spectrogram_file_path = FT.make_output_path( spectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( spectrogram, spectrogram_file_path )
 */
  __pyx_t_6 = PyObject_RichCompare(__pyx_v_spectrogram_file_path, Py_None, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 821, __pyx_L1_error)
  __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 821, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {

    /* "VocalTractLab/VocalTractLabApi.pyx":822
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	if spectrogram_file_path != None: # TODO: replace with saveFile
 * 		spectrogram_file_path = FT.make_output_path( spectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +             # <<<<<<<<<<<<<<
 * 		save( spectrogram, spectrogram_file_path )
 * 	return spectrogram
 */
    __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_FT); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 822, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_make_output_path); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 822, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = NULL;
    __pyx_t_12 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_12 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_v_spectrogram_file_path, __pyx_kp_s_spectrogram_pkl_gzip};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 822, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_v_spectrogram_file_path, __pyx_kp_s_spectrogram_pkl_gzip};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 822, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(2+__pyx_t_12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 822, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      if (__pyx_t_8) {
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_8); __pyx_t_8 = NULL;
      }
      __Pyx_INCREF(__pyx_v_spectrogram_file_path);
      __Pyx_GIVEREF(__pyx_v_spectrogram_file_path);
      PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_12, __pyx_v_spectrogram_file_path);
      __Pyx_INCREF(__pyx_kp_s_spectrogram_pkl_gzip);
      __Pyx_GIVEREF(__pyx_kp_s_spectrogram_pkl_gzip);
      PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_12, __pyx_kp_s_spectrogram_pkl_gzip);
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_7, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 822, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_spectrogram_file_path, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":823
 * 	if spectrogram_file_path != None: # TODO: replace with saveFile
 * 		spectrogram_file_path = FT.make_output_path( spectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( spectrogram, spectrogram_file_path )             # <<<<<<<<<<<<<<
 * 	return spectrogram
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_save); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = NULL;
    __pyx_t_12 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_12 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_spectrogram, __pyx_v_spectrogram_file_path};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 823, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_spectrogram, __pyx_v_spectrogram_file_path};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 823, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_12); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 823, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_7) {
        __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_7); __pyx_t_7 = NULL;
      }
      __Pyx_INCREF(__pyx_v_spectrogram);
      __Pyx_GIVEREF(__pyx_v_spectrogram);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_12, __pyx_v_spectrogram);
      __Pyx_INCREF(__pyx_v_spectrogram_file_path);
      __Pyx_GIVEREF(__pyx_v_spectrogram_file_path);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_12, __pyx_v_spectrogram_file_path);
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 823, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":821
 * 	audio = _tract_sequence_to_audio( audio_args )
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	if spectrogram_file_path != None: # TODO: replace with saveFile             # <<<<<<<<<<<<<<
 * 		spectrogram_file_path = FT.make_output_path( spectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( spectrogram, spectrogram_file_path )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":824
 * 		spectrogram_file_path = FT.make_output_path( spectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( spectrogram, spectrogram_file_path )
 * 	return spectrogram             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_melspectrogram( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_spectrogram);
  __pyx_r = __pyx_v_spectrogram;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":807
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_spectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._motor_sequence_to_spectrogram", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_motor_sequence_data);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_spectrogram_file_path);
  __Pyx_XDECREF(__pyx_v_save_file);
  __Pyx_XDECREF(__pyx_v_normalize_audio);
  __Pyx_XDECREF(__pyx_v_sr);
  __Pyx_XDECREF(__pyx_v_spectrogram_kwargs);
  __Pyx_XDECREF(__pyx_v_verbose);
  __Pyx_XDECREF(__pyx_v_audio_args);
  __Pyx_XDECREF(__pyx_v_audio);
  __Pyx_XDECREF(__pyx_v_spectrogram);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":826
 * 	return spectrogram
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_melspectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_65_motor_sequence_to_melspectrogram(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_65_motor_sequence_to_melspectrogram = {"_motor_sequence_to_melspectrogram", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_65_motor_sequence_to_melspectrogram, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_65_motor_sequence_to_melspectrogram(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_motor_sequence_to_melspectrogram (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_64_motor_sequence_to_melspectrogram(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_64_motor_sequence_to_melspectrogram(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_motor_sequence_data = NULL;
  PyObject *__pyx_v_audio_file_path = NULL;
  PyObject *__pyx_v_melspectrogram_file_path = NULL;
  PyObject *__pyx_v_save_file = NULL;
  PyObject *__pyx_v_normalize_audio = NULL;
  PyObject *__pyx_v_sr = NULL;
  PyObject *__pyx_v_log_scale = NULL;
  PyObject *__pyx_v_spectrogram_kwargs = NULL;
  PyObject *__pyx_v_melspectrogram_kwargs = NULL;
  PyObject *__pyx_v_verbose = NULL;
  PyObject *__pyx_v_audio_args = NULL;
  PyObject *__pyx_v_audio = NULL;
  PyObject *__pyx_v_spectrogram = NULL;
  PyObject *__pyx_v_melspectrogram = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *(*__pyx_t_12)(PyObject *);
  int __pyx_t_13;
  int __pyx_t_14;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_motor_sequence_to_melspectrogram", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":838
 * 		melspectrogram_kwargs,
 * 		verbose,
 * 	) = args             # <<<<<<<<<<<<<<
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )
 * 	audio = _tract_sequence_to_audio( audio_args )
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 10)) {
      if (size > 10) __Pyx_RaiseTooManyValuesError(10);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 828, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyTuple_GET_ITEM(sequence, 5); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 6); 
      __pyx_t_8 = PyTuple_GET_ITEM(sequence, 7); 
      __pyx_t_9 = PyTuple_GET_ITEM(sequence, 8); 
      __pyx_t_10 = PyTuple_GET_ITEM(sequence, 9); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyList_GET_ITEM(sequence, 5); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 6); 
      __pyx_t_8 = PyList_GET_ITEM(sequence, 7); 
      __pyx_t_9 = PyList_GET_ITEM(sequence, 8); 
      __pyx_t_10 = PyList_GET_ITEM(sequence, 9); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_t_7);
    __Pyx_INCREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_t_9);
    __Pyx_INCREF(__pyx_t_10);
    #else
    {
      Py_ssize_t i;
      PyObject** temps[10] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6,&__pyx_t_7,&__pyx_t_8,&__pyx_t_9,&__pyx_t_10};
      for (i=0; i < 10; i++) {
        PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 828, __pyx_L1_error)
        __Pyx_GOTREF(item);
        *(temps[i]) = item;
      }
    }
    #endif
  } else {
    Py_ssize_t index = -1;
    PyObject** temps[10] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6,&__pyx_t_7,&__pyx_t_8,&__pyx_t_9,&__pyx_t_10};
    __pyx_t_11 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 828, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_12 = Py_TYPE(__pyx_t_11)->tp_iternext;
    for (index=0; index < 10; index++) {
      PyObject* item = __pyx_t_12(__pyx_t_11); if (unlikely(!item)) goto __pyx_L3_unpacking_failed;
      __Pyx_GOTREF(item);
      *(temps[index]) = item;
    }
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_12(__pyx_t_11), 10) < 0) __PYX_ERR(0, 828, __pyx_L1_error)
    __pyx_t_12 = NULL;
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_12 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 828, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":828
 * def _motor_sequence_to_melspectrogram( args ):
 * 	(
 * 		motor_sequence_data,             # <<<<<<<<<<<<<<
 * 		audio_file_path,
 * 		melspectrogram_file_path,
 */
  __pyx_v_motor_sequence_data = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_audio_file_path = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_melspectrogram_file_path = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_save_file = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_v_normalize_audio = __pyx_t_5;
  __pyx_t_5 = 0;
  __pyx_v_sr = __pyx_t_6;
  __pyx_t_6 = 0;
  __pyx_v_log_scale = __pyx_t_7;
  __pyx_t_7 = 0;
  __pyx_v_spectrogram_kwargs = __pyx_t_8;
  __pyx_t_8 = 0;
  __pyx_v_melspectrogram_kwargs = __pyx_t_9;
  __pyx_t_9 = 0;
  __pyx_v_verbose = __pyx_t_10;
  __pyx_t_10 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":839
 * 		verbose,
 * 	) = args
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )             # <<<<<<<<<<<<<<
 * 	audio = _tract_sequence_to_audio( audio_args )
 * 	#spectrogram_kwargs = dict()
 */
  __pyx_t_10 = PyTuple_New(6); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 839, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_INCREF(__pyx_v_motor_sequence_data);
  __Pyx_GIVEREF(__pyx_v_motor_sequence_data);
  PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_v_motor_sequence_data);
  __Pyx_INCREF(__pyx_v_audio_file_path);
  __Pyx_GIVEREF(__pyx_v_audio_file_path);
  PyTuple_SET_ITEM(__pyx_t_10, 1, __pyx_v_audio_file_path);
  __Pyx_INCREF(__pyx_v_save_file);
  __Pyx_GIVEREF(__pyx_v_save_file);
  PyTuple_SET_ITEM(__pyx_t_10, 2, __pyx_v_save_file);
  __Pyx_INCREF(__pyx_v_normalize_audio);
  __Pyx_GIVEREF(__pyx_v_normalize_audio);
  PyTuple_SET_ITEM(__pyx_t_10, 3, __pyx_v_normalize_audio);
  __Pyx_INCREF(__pyx_v_sr);
  __Pyx_GIVEREF(__pyx_v_sr);
  PyTuple_SET_ITEM(__pyx_t_10, 4, __pyx_v_sr);
  __Pyx_INCREF(__pyx_v_verbose);
  __Pyx_GIVEREF(__pyx_v_verbose);
  PyTuple_SET_ITEM(__pyx_t_10, 5, __pyx_v_verbose);
  __pyx_v_audio_args = ((PyObject*)__pyx_t_10);
  __pyx_t_10 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":840
 * 	) = args
 * 	audio_args = ( motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose )
 * 	audio = _tract_sequence_to_audio( audio_args )             # <<<<<<<<<<<<<<
 * 	#spectrogram_kwargs = dict()
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 */
  __Pyx_GetModuleGlobalName(__pyx_t_9, __pyx_n_s_tract_sequence_to_audio); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 840, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_9))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_9);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_9, function);
    }
  }
  __pyx_t_10 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_9, __pyx_t_8, __pyx_v_audio_args) : __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_v_audio_args);
  __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 840, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_v_audio = __pyx_t_10;
  __pyx_t_10 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":842
 * 	audio = _tract_sequence_to_audio( audio_args )
 * 	#spectrogram_kwargs = dict()
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2             # <<<<<<<<<<<<<<
 * 	melspectrogram = librosa.feature.melspectrogram( S = spectrogram, **melspectrogram_kwargs )
 * 	if log_scale == True:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_9, __pyx_n_s_np); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_9, __pyx_n_s_abs); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_9, __pyx_n_s_librosa); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_9, __pyx_n_s_stft); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_t_6 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  if (PyDict_SetItem(__pyx_t_6, __pyx_n_s_y, __pyx_v_audio) < 0) __PYX_ERR(0, 842, __pyx_L1_error)
  __pyx_t_9 = __pyx_t_6;
  __pyx_t_6 = 0;
  if (unlikely(__pyx_v_spectrogram_kwargs == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "argument after ** must be a mapping, not NoneType");
    __PYX_ERR(0, 842, __pyx_L1_error)
  }
  if (__Pyx_MergeKeywords(__pyx_t_9, __pyx_v_spectrogram_kwargs) < 0) __PYX_ERR(0, 842, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_empty_tuple, __pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_t_9 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_9)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_9);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_10 = (__pyx_t_9) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_9, __pyx_t_6) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_6);
  __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = PyNumber_Power(__pyx_t_10, __pyx_int_2, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_spectrogram = __pyx_t_8;
  __pyx_t_8 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":843
 * 	#spectrogram_kwargs = dict()
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	melspectrogram = librosa.feature.melspectrogram( S = spectrogram, **melspectrogram_kwargs )             # <<<<<<<<<<<<<<
 * 	if log_scale == True:
 * 		melspectrogram = librosa.power_to_db( melspectrogram )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_librosa); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 843, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_feature); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 843, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_melspectrogram); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 843, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_6 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 843, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  if (PyDict_SetItem(__pyx_t_6, __pyx_n_s_S, __pyx_v_spectrogram) < 0) __PYX_ERR(0, 843, __pyx_L1_error)
  __pyx_t_10 = __pyx_t_6;
  __pyx_t_6 = 0;
  if (unlikely(__pyx_v_melspectrogram_kwargs == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "argument after ** must be a mapping, not NoneType");
    __PYX_ERR(0, 843, __pyx_L1_error)
  }
  if (__Pyx_MergeKeywords(__pyx_t_10, __pyx_v_melspectrogram_kwargs) < 0) __PYX_ERR(0, 843, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_empty_tuple, __pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 843, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_melspectrogram = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":844
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	melspectrogram = librosa.feature.melspectrogram( S = spectrogram, **melspectrogram_kwargs )
 * 	if log_scale == True:             # <<<<<<<<<<<<<<
 * 		melspectrogram = librosa.power_to_db( melspectrogram )
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile
 */
  __pyx_t_6 = PyObject_RichCompare(__pyx_v_log_scale, Py_True, Py_EQ); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 844, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_13 < 0)) __PYX_ERR(0, 844, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_13) {

    /* "VocalTractLab/VocalTractLabApi.pyx":845
 * 	melspectrogram = librosa.feature.melspectrogram( S = spectrogram, **melspectrogram_kwargs )
 * 	if log_scale == True:
 * 		melspectrogram = librosa.power_to_db( melspectrogram )             # <<<<<<<<<<<<<<
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile
 * 		melspectrogram_file_path = FT.make_output_path( melspectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 */
    __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_n_s_librosa); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_power_to_db); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    __pyx_t_6 = (__pyx_t_10) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_10, __pyx_v_melspectrogram) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_v_melspectrogram);
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF_SET(__pyx_v_melspectrogram, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":844
 * 	spectrogram = np.abs( librosa.stft( y = audio, **spectrogram_kwargs ) )**2
 * 	melspectrogram = librosa.feature.melspectrogram( S = spectrogram, **melspectrogram_kwargs )
 * 	if log_scale == True:             # <<<<<<<<<<<<<<
 * 		melspectrogram = librosa.power_to_db( melspectrogram )
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":846
 * 	if log_scale == True:
 * 		melspectrogram = librosa.power_to_db( melspectrogram )
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile             # <<<<<<<<<<<<<<
 * 		melspectrogram_file_path = FT.make_output_path( melspectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( melspectrogram, melspectrogram_file_path )
 */
  __pyx_t_6 = PyObject_RichCompare(__pyx_v_melspectrogram_file_path, Py_None, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 846, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_13 < 0)) __PYX_ERR(0, 846, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_13) {

    /* "VocalTractLab/VocalTractLabApi.pyx":847
 * 		melspectrogram = librosa.power_to_db( melspectrogram )
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile
 * 		melspectrogram_file_path = FT.make_output_path( melspectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +             # <<<<<<<<<<<<<<
 * 		save( melspectrogram, melspectrogram_file_path )
 * 	return melspectrogram
 */
    __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_FT); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 847, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_make_output_path); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 847, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = NULL;
    __pyx_t_14 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_10);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_10, function);
        __pyx_t_14 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_v_melspectrogram_file_path, __pyx_kp_s_spectrogram_pkl_gzip};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_14, 2+__pyx_t_14); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 847, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_v_melspectrogram_file_path, __pyx_kp_s_spectrogram_pkl_gzip};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_14, 2+__pyx_t_14); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 847, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    {
      __pyx_t_9 = PyTuple_New(2+__pyx_t_14); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 847, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      if (__pyx_t_8) {
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
      }
      __Pyx_INCREF(__pyx_v_melspectrogram_file_path);
      __Pyx_GIVEREF(__pyx_v_melspectrogram_file_path);
      PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_14, __pyx_v_melspectrogram_file_path);
      __Pyx_INCREF(__pyx_kp_s_spectrogram_pkl_gzip);
      __Pyx_GIVEREF(__pyx_kp_s_spectrogram_pkl_gzip);
      PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_14, __pyx_kp_s_spectrogram_pkl_gzip);
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_9, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 847, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    }
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF_SET(__pyx_v_melspectrogram_file_path, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":848
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile
 * 		melspectrogram_file_path = FT.make_output_path( melspectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( melspectrogram, melspectrogram_file_path )             # <<<<<<<<<<<<<<
 * 	return melspectrogram
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_n_s_save); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 848, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_9 = NULL;
    __pyx_t_14 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_10);
      if (likely(__pyx_t_9)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_9);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_10, function);
        __pyx_t_14 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[3] = {__pyx_t_9, __pyx_v_melspectrogram, __pyx_v_melspectrogram_file_path};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_14, 2+__pyx_t_14); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[3] = {__pyx_t_9, __pyx_v_melspectrogram, __pyx_v_melspectrogram_file_path};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_14, 2+__pyx_t_14); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_6);
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_14); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_9) {
        __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_9); __pyx_t_9 = NULL;
      }
      __Pyx_INCREF(__pyx_v_melspectrogram);
      __Pyx_GIVEREF(__pyx_v_melspectrogram);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_14, __pyx_v_melspectrogram);
      __Pyx_INCREF(__pyx_v_melspectrogram_file_path);
      __Pyx_GIVEREF(__pyx_v_melspectrogram_file_path);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_14, __pyx_v_melspectrogram_file_path);
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":846
 * 	if log_scale == True:
 * 		melspectrogram = librosa.power_to_db( melspectrogram )
 * 	if melspectrogram_file_path != None: # TODO: replace with saveFile             # <<<<<<<<<<<<<<
 * 		melspectrogram_file_path = FT.make_output_path( melspectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( melspectrogram, melspectrogram_file_path )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":849
 * 		melspectrogram_file_path = FT.make_output_path( melspectrogram_file_path, '_spectrogram.pkl.gzip' )#motor_sequence.name.rsplit( '.' )[0] +
 * 		save( melspectrogram, melspectrogram_file_path )
 * 	return melspectrogram             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * #def _motor_sequence_to_melspectrogram( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_melspectrogram);
  __pyx_r = __pyx_v_melspectrogram;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":826
 * 	return spectrogram
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_melspectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._motor_sequence_to_melspectrogram", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_motor_sequence_data);
  __Pyx_XDECREF(__pyx_v_audio_file_path);
  __Pyx_XDECREF(__pyx_v_melspectrogram_file_path);
  __Pyx_XDECREF(__pyx_v_save_file);
  __Pyx_XDECREF(__pyx_v_normalize_audio);
  __Pyx_XDECREF(__pyx_v_sr);
  __Pyx_XDECREF(__pyx_v_log_scale);
  __Pyx_XDECREF(__pyx_v_spectrogram_kwargs);
  __Pyx_XDECREF(__pyx_v_melspectrogram_kwargs);
  __Pyx_XDECREF(__pyx_v_verbose);
  __Pyx_XDECREF(__pyx_v_audio_args);
  __Pyx_XDECREF(__pyx_v_audio);
  __Pyx_XDECREF(__pyx_v_spectrogram);
  __Pyx_XDECREF(__pyx_v_melspectrogram);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":902
 * #	return mfcc
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_limited_tract_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state = args
 * 	constants = get_constants()
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_67_tract_state_to_limited_tract_state(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_67_tract_state_to_limited_tract_state = {"_tract_state_to_limited_tract_state", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_67_tract_state_to_limited_tract_state, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_67_tract_state_to_limited_tract_state(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_tract_state_to_limited_tract_state (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_66_tract_state_to_limited_tract_state(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_66_tract_state_to_limited_tract_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_tract_state = NULL;
  PyObject *__pyx_v_constants = NULL;
  PyArrayObject *__pyx_v_inTractParams = 0;
  PyArrayObject *__pyx_v_outTractParams = 0;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_inTractParams;
  __Pyx_Buffer __pyx_pybuffer_inTractParams;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_outTractParams;
  __Pyx_Buffer __pyx_pybuffer_outTractParams;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyArrayObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyArrayObject *__pyx_t_6 = NULL;
  Py_ssize_t __pyx_t_7;
  int __pyx_t_8;
  Py_ssize_t __pyx_t_9;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tract_state_to_limited_tract_state", 0);
  __pyx_pybuffer_inTractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_inTractParams.refcount = 0;
  __pyx_pybuffernd_inTractParams.data = NULL;
  __pyx_pybuffernd_inTractParams.rcbuffer = &__pyx_pybuffer_inTractParams;
  __pyx_pybuffer_outTractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_outTractParams.refcount = 0;
  __pyx_pybuffernd_outTractParams.data = NULL;
  __pyx_pybuffernd_outTractParams.rcbuffer = &__pyx_pybuffer_outTractParams;

  /* "VocalTractLab/VocalTractLabApi.pyx":903
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_limited_tract_state( args ):
 * 	tract_state = args             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] inTractParams = tract_state.ravel()
 */
  __Pyx_INCREF(__pyx_v_args);
  __pyx_v_tract_state = __pyx_v_args;

  /* "VocalTractLab/VocalTractLabApi.pyx":904
 * def _tract_state_to_limited_tract_state( args ):
 * 	tract_state = args
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] inTractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] outTractParams = np.zeros( constants[ 'n_tract_params' ], dtype='float64' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 904, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 904, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_constants = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":905
 * 	tract_state = args
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] inTractParams = tract_state.ravel()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] outTractParams = np.zeros( constants[ 'n_tract_params' ], dtype='float64' )
 * 	vtlInputTractToLimitedTract( &inTractParams[0], &outTractParams[0] )
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_tract_state, __pyx_n_s_ravel); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 905, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 905, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 905, __pyx_L1_error)
  __pyx_t_4 = ((PyArrayObject *)__pyx_t_1);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_inTractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_4, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_inTractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_inTractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 905, __pyx_L1_error)
    } else {__pyx_pybuffernd_inTractParams.diminfo[0].strides = __pyx_pybuffernd_inTractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_inTractParams.diminfo[0].shape = __pyx_pybuffernd_inTractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_4 = 0;
  __pyx_v_inTractParams = ((PyArrayObject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":906
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] inTractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] outTractParams = np.zeros( constants[ 'n_tract_params' ], dtype='float64' )             # <<<<<<<<<<<<<<
 * 	vtlInputTractToLimitedTract( &inTractParams[0], &outTractParams[0] )
 * 	return outTractParams
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_tract_params); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 906, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!(likely(((__pyx_t_5) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_5, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 906, __pyx_L1_error)
  __pyx_t_6 = ((PyArrayObject *)__pyx_t_5);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_outTractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_6, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_outTractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_outTractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 906, __pyx_L1_error)
    } else {__pyx_pybuffernd_outTractParams.diminfo[0].strides = __pyx_pybuffernd_outTractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_outTractParams.diminfo[0].shape = __pyx_pybuffernd_outTractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_6 = 0;
  __pyx_v_outTractParams = ((PyArrayObject *)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":907
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] inTractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] outTractParams = np.zeros( constants[ 'n_tract_params' ], dtype='float64' )
 * 	vtlInputTractToLimitedTract( &inTractParams[0], &outTractParams[0] )             # <<<<<<<<<<<<<<
 * 	return outTractParams
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_7 = 0;
  __pyx_t_8 = -1;
  if (__pyx_t_7 < 0) {
    __pyx_t_7 += __pyx_pybuffernd_inTractParams.diminfo[0].shape;
    if (unlikely(__pyx_t_7 < 0)) __pyx_t_8 = 0;
  } else if (unlikely(__pyx_t_7 >= __pyx_pybuffernd_inTractParams.diminfo[0].shape)) __pyx_t_8 = 0;
  if (unlikely(__pyx_t_8 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_8);
    __PYX_ERR(0, 907, __pyx_L1_error)
  }
  __pyx_t_9 = 0;
  __pyx_t_8 = -1;
  if (__pyx_t_9 < 0) {
    __pyx_t_9 += __pyx_pybuffernd_outTractParams.diminfo[0].shape;
    if (unlikely(__pyx_t_9 < 0)) __pyx_t_8 = 0;
  } else if (unlikely(__pyx_t_9 >= __pyx_pybuffernd_outTractParams.diminfo[0].shape)) __pyx_t_8 = 0;
  if (unlikely(__pyx_t_8 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_8);
    __PYX_ERR(0, 907, __pyx_L1_error)
  }
  (void)(vtlInputTractToLimitedTract((&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_inTractParams.rcbuffer->pybuffer.buf, __pyx_t_7, __pyx_pybuffernd_inTractParams.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_outTractParams.rcbuffer->pybuffer.buf, __pyx_t_9, __pyx_pybuffernd_outTractParams.diminfo[0].strides)))));

  /* "VocalTractLab/VocalTractLabApi.pyx":908
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] outTractParams = np.zeros( constants[ 'n_tract_params' ], dtype='float64' )
 * 	vtlInputTractToLimitedTract( &inTractParams[0], &outTractParams[0] )
 * 	return outTractParams             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_svg( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_outTractParams));
  __pyx_r = ((PyObject *)__pyx_v_outTractParams);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":902
 * #	return mfcc
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_limited_tract_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state = args
 * 	constants = get_constants()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_inTractParams.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_outTractParams.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._tract_state_to_limited_tract_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_inTractParams.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_outTractParams.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_tract_state);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF((PyObject *)__pyx_v_inTractParams);
  __Pyx_XDECREF((PyObject *)__pyx_v_outTractParams);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":910
 * 	return outTractParams
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_svg( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_69_tract_sequence_to_svg(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_69_tract_sequence_to_svg = {"_tract_sequence_to_svg", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_69_tract_sequence_to_svg, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_69_tract_sequence_to_svg(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_tract_sequence_to_svg (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_68_tract_sequence_to_svg(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_68_tract_sequence_to_svg(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_motor_sequence = NULL;
  PyObject *__pyx_v_svg_dir = NULL;
  PyObject *__pyx_v_fps = NULL;
  PyObject *__pyx_v_tract_file_path = NULL;
  PyObject *__pyx_v_constants = NULL;
  PyArrayObject *__pyx_v_tractParams = 0;
  PyObject *__pyx_v_resampled_index = NULL;
  PyObject *__pyx_v_resampled_tract_states = NULL;
  PyObject *__pyx_v_pair = NULL;
  PyObject *__pyx_v_index = NULL;
  PyObject *__pyx_v_tract_state = NULL;
  PyObject *__pyx_v_fileName = NULL;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tractParams;
  __Pyx_Buffer __pyx_pybuffer_tractParams;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyArrayObject *__pyx_t_10 = NULL;
  Py_ssize_t __pyx_t_11;
  PyObject *(*__pyx_t_12)(PyObject *);
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  Py_ssize_t __pyx_t_16;
  char const *__pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tract_sequence_to_svg", 0);
  __pyx_pybuffer_tractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_tractParams.refcount = 0;
  __pyx_pybuffernd_tractParams.data = NULL;
  __pyx_pybuffernd_tractParams.rcbuffer = &__pyx_pybuffer_tractParams;

  /* "VocalTractLab/VocalTractLabApi.pyx":911
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_svg( args ):
 * 	motor_sequence, svg_dir, fps = args             # <<<<<<<<<<<<<<
 * 	if isinstance( motor_sequence, str ) :
 * 		tract_file_path = motor_sequence
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 911, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 2; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 3) < 0) __PYX_ERR(0, 911, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 911, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_motor_sequence = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_svg_dir = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_fps = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":912
 * def _tract_sequence_to_svg( args ):
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :             # <<<<<<<<<<<<<<
 * 		tract_file_path = motor_sequence
 * 		if not os.path.exists( tract_file_path ) :
 */
  __pyx_t_6 = PyString_Check(__pyx_v_motor_sequence); 
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "VocalTractLab/VocalTractLabApi.pyx":913
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :
 * 		tract_file_path = motor_sequence             # <<<<<<<<<<<<<<
 * 		if not os.path.exists( tract_file_path ) :
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 */
    __Pyx_INCREF(__pyx_v_motor_sequence);
    __pyx_v_tract_file_path = __pyx_v_motor_sequence;

    /* "VocalTractLab/VocalTractLabApi.pyx":914
 * 	if isinstance( motor_sequence, str ) :
 * 		tract_file_path = motor_sequence
 * 		if not os.path.exists( tract_file_path ) :             # <<<<<<<<<<<<<<
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return
 */
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_os); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 914, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_path); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 914, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_exists); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 914, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_1, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_tract_file_path);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 914, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 914, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_6 = ((!__pyx_t_7) != 0);
    if (__pyx_t_6) {

      /* "VocalTractLab/VocalTractLabApi.pyx":915
 * 		tract_file_path = motor_sequence
 * 		if not os.path.exists( tract_file_path ) :
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )             # <<<<<<<<<<<<<<
 * 			return
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 */
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_warnings); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_warn); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_the_specified_tract_sequence_fil, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_8 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_8)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_8);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      __pyx_t_2 = (__pyx_t_8) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_8, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_tract_file_path);
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
        }
      }
      __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2);
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":916
 * 		if not os.path.exists( tract_file_path ) :
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return             # <<<<<<<<<<<<<<
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )
 * 	#elif isinstance( motor_sequence, ts.Target_Sequence ) :
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_r = Py_None; __Pyx_INCREF(Py_None);
      goto __pyx_L0;

      /* "VocalTractLab/VocalTractLabApi.pyx":914
 * 	if isinstance( motor_sequence, str ) :
 * 		tract_file_path = motor_sequence
 * 		if not os.path.exists( tract_file_path ) :             # <<<<<<<<<<<<<<
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return
 */
    }

    /* "VocalTractLab/VocalTractLabApi.pyx":917
 * 			warnings.warn( 'the specified tract sequence file path does not exist: {}. API call will be skipped.'.format( tract_file_path ) )
 * 			return
 * 		motor_sequence = Motor_Sequence.from_tract_file( tract_file_path )             # <<<<<<<<<<<<<<
 * 	#elif isinstance( motor_sequence, ts.Target_Sequence ) :
 * 	#	target_sequence = motor_sequence
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_from_tract_file); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_1, __pyx_v_tract_file_path) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_tract_file_path);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF_SET(__pyx_v_motor_sequence, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":912
 * def _tract_sequence_to_svg( args ):
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :             # <<<<<<<<<<<<<<
 * 		tract_file_path = motor_sequence
 * 		if not os.path.exists( tract_file_path ) :
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":924
 * 	#	#pass
 * 	#	#motor_sequence = motor_sequence_data
 * 	svg_dir = FT.make_output_dir( svg_dir, motor_sequence.name.rsplit('.')[0] + '_svg' )             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	cdef np.ndarray[np.float64_t, ndim = 1] tractParams = np.zeros( constants['n_tract_params'], dtype = 'float64' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_FT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_make_output_dir); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_name); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_rsplit); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_2 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_8, __pyx_t_4, __pyx_kp_s__13) : __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_kp_s__13);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Add(__pyx_t_8, __pyx_n_s_svg); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 924, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_8 = NULL;
  __pyx_t_9 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_9 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_1)) {
    PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_v_svg_dir, __pyx_t_2};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 924, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
    PyObject *__pyx_temp[3] = {__pyx_t_8, __pyx_v_svg_dir, __pyx_t_2};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 924, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  {
    __pyx_t_4 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 924, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (__pyx_t_8) {
      __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_8); __pyx_t_8 = NULL;
    }
    __Pyx_INCREF(__pyx_v_svg_dir);
    __Pyx_GIVEREF(__pyx_v_svg_dir);
    PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_9, __pyx_v_svg_dir);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_9, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 924, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF_SET(__pyx_v_svg_dir, __pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":925
 * 	#	#motor_sequence = motor_sequence_data
 * 	svg_dir = FT.make_output_dir( svg_dir, motor_sequence.name.rsplit('.')[0] + '_svg' )
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[np.float64_t, ndim = 1] tractParams = np.zeros( constants['n_tract_params'], dtype = 'float64' )
 * 	resampled_index = [ round(index * (44100 / 110) / fps) for index in range( 0, motor_sequence.length ) ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 925, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 925, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_constants = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":926
 * 	svg_dir = FT.make_output_dir( svg_dir, motor_sequence.name.rsplit('.')[0] + '_svg' )
 * 	constants = get_constants()
 * 	cdef np.ndarray[np.float64_t, ndim = 1] tractParams = np.zeros( constants['n_tract_params'], dtype = 'float64' )             # <<<<<<<<<<<<<<
 * 	resampled_index = [ round(index * (44100 / 110) / fps) for index in range( 0, motor_sequence.length ) ]
 * 	resampled_tract_states = [ [ index, tract_state ] for index, tract_state in enumerate( motor_sequence.states.to_numpy() ) if index in resampled_index ]
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_zeros); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_tract_params); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 926, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 926, __pyx_L1_error)
  __pyx_t_10 = ((PyArrayObject *)__pyx_t_2);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_10, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 926, __pyx_L1_error)
    } else {__pyx_pybuffernd_tractParams.diminfo[0].strides = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tractParams.diminfo[0].shape = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_10 = 0;
  __pyx_v_tractParams = ((PyArrayObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":927
 * 	constants = get_constants()
 * 	cdef np.ndarray[np.float64_t, ndim = 1] tractParams = np.zeros( constants['n_tract_params'], dtype = 'float64' )
 * 	resampled_index = [ round(index * (44100 / 110) / fps) for index in range( 0, motor_sequence.length ) ]             # <<<<<<<<<<<<<<
 * 	resampled_tract_states = [ [ index, tract_state ] for index, tract_state in enumerate( motor_sequence.states.to_numpy() ) if index in resampled_index ]
 * 	for pair in resampled_tract_states:
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_length); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_int_0);
  __Pyx_GIVEREF(__pyx_int_0);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_int_0);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
    __pyx_t_4 = __pyx_t_3; __Pyx_INCREF(__pyx_t_4); __pyx_t_11 = 0;
    __pyx_t_12 = NULL;
  } else {
    __pyx_t_11 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 927, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_12 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 927, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  for (;;) {
    if (likely(!__pyx_t_12)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_11 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_11); __Pyx_INCREF(__pyx_t_3); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 927, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_4, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      } else {
        if (__pyx_t_11 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_11); __Pyx_INCREF(__pyx_t_3); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 927, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_4, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      }
    } else {
      __pyx_t_3 = __pyx_t_12(__pyx_t_4);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 927, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = PyNumber_Multiply(__pyx_v_index, __pyx_int_400); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __Pyx_PyNumber_Divide(__pyx_t_3, __pyx_v_fps); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_round, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_3))) __PYX_ERR(0, 927, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_resampled_index = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":928
 * 	cdef np.ndarray[np.float64_t, ndim = 1] tractParams = np.zeros( constants['n_tract_params'], dtype = 'float64' )
 * 	resampled_index = [ round(index * (44100 / 110) / fps) for index in range( 0, motor_sequence.length ) ]
 * 	resampled_tract_states = [ [ index, tract_state ] for index, tract_state in enumerate( motor_sequence.states.to_numpy() ) if index in resampled_index ]             # <<<<<<<<<<<<<<
 * 	for pair in resampled_tract_states:
 * 		index, tract_state = pair
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_4 = __pyx_int_0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_motor_sequence, __pyx_n_s_states); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_to_numpy); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
    }
  }
  __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_1) : __Pyx_PyObject_CallNoArg(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
    __pyx_t_8 = __pyx_t_3; __Pyx_INCREF(__pyx_t_8); __pyx_t_11 = 0;
    __pyx_t_12 = NULL;
  } else {
    __pyx_t_11 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 928, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_12 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 928, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  for (;;) {
    if (likely(!__pyx_t_12)) {
      if (likely(PyList_CheckExact(__pyx_t_8))) {
        if (__pyx_t_11 >= PyList_GET_SIZE(__pyx_t_8)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_11); __Pyx_INCREF(__pyx_t_3); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 928, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_8, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 928, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      } else {
        if (__pyx_t_11 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_11); __Pyx_INCREF(__pyx_t_3); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 928, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_8, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 928, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      }
    } else {
      __pyx_t_3 = __pyx_t_12(__pyx_t_8);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 928, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_tract_state, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_4);
    __pyx_t_3 = __Pyx_PyInt_AddObjC(__pyx_t_4, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 928, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4);
    __pyx_t_4 = __pyx_t_3;
    __pyx_t_3 = 0;
    __pyx_t_6 = (__Pyx_PySequence_ContainsTF(__pyx_v_index, __pyx_v_resampled_index, Py_EQ)); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 928, __pyx_L1_error)
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {
      __pyx_t_3 = PyList_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 928, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_v_index);
      __Pyx_GIVEREF(__pyx_v_index);
      PyList_SET_ITEM(__pyx_t_3, 0, __pyx_v_index);
      __Pyx_INCREF(__pyx_v_tract_state);
      __Pyx_GIVEREF(__pyx_v_tract_state);
      PyList_SET_ITEM(__pyx_t_3, 1, __pyx_v_tract_state);
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_3))) __PYX_ERR(0, 928, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_resampled_tract_states = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":929
 * 	resampled_index = [ round(index * (44100 / 110) / fps) for index in range( 0, motor_sequence.length ) ]
 * 	resampled_tract_states = [ [ index, tract_state ] for index, tract_state in enumerate( motor_sequence.states.to_numpy() ) if index in resampled_index ]
 * 	for pair in resampled_tract_states:             # <<<<<<<<<<<<<<
 * 		index, tract_state = pair
 * 		tractParams = tract_state.ravel()
 */
  __pyx_t_2 = __pyx_v_resampled_tract_states; __Pyx_INCREF(__pyx_t_2); __pyx_t_11 = 0;
  for (;;) {
    if (__pyx_t_11 >= PyList_GET_SIZE(__pyx_t_2)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_4 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_11); __Pyx_INCREF(__pyx_t_4); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 929, __pyx_L1_error)
    #else
    __pyx_t_4 = PySequence_ITEM(__pyx_t_2, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 929, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_pair, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":930
 * 	resampled_tract_states = [ [ index, tract_state ] for index, tract_state in enumerate( motor_sequence.states.to_numpy() ) if index in resampled_index ]
 * 	for pair in resampled_tract_states:
 * 		index, tract_state = pair             # <<<<<<<<<<<<<<
 * 		tractParams = tract_state.ravel()
 * 		fileName = ( svg_dir + '/tract_{}.svg'.format( index ) ).encode()
 */
    if ((likely(PyTuple_CheckExact(__pyx_v_pair))) || (PyList_CheckExact(__pyx_v_pair))) {
      PyObject* sequence = __pyx_v_pair;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 930, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_8);
      #else
      __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 930, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 930, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      #endif
    } else {
      Py_ssize_t index = -1;
      __pyx_t_3 = PyObject_GetIter(__pyx_v_pair); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 930, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext;
      index = 0; __pyx_t_4 = __pyx_t_5(__pyx_t_3); if (unlikely(!__pyx_t_4)) goto __pyx_L14_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_4);
      index = 1; __pyx_t_8 = __pyx_t_5(__pyx_t_3); if (unlikely(!__pyx_t_8)) goto __pyx_L14_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_3), 2) < 0) __PYX_ERR(0, 930, __pyx_L1_error)
      __pyx_t_5 = NULL;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      goto __pyx_L15_unpacking_done;
      __pyx_L14_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 930, __pyx_L1_error)
      __pyx_L15_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_XDECREF_SET(__pyx_v_tract_state, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":931
 * 	for pair in resampled_tract_states:
 * 		index, tract_state = pair
 * 		tractParams = tract_state.ravel()             # <<<<<<<<<<<<<<
 * 		fileName = ( svg_dir + '/tract_{}.svg'.format( index ) ).encode()
 * 		vtlExportTractSvg( &tractParams[0], fileName )
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_tract_state, __pyx_n_s_ravel); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 931, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_8 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 931, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 931, __pyx_L1_error)
    __pyx_t_10 = ((PyArrayObject *)__pyx_t_8);
    {
      __Pyx_BufFmt_StackElem __pyx_stack[1];
      __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
      __pyx_t_9 = __Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_10, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack);
      if (unlikely(__pyx_t_9 < 0)) {
        PyErr_Fetch(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
        if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_v_tractParams, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
          Py_XDECREF(__pyx_t_13); Py_XDECREF(__pyx_t_14); Py_XDECREF(__pyx_t_15);
          __Pyx_RaiseBufferFallbackError();
        } else {
          PyErr_Restore(__pyx_t_13, __pyx_t_14, __pyx_t_15);
        }
        __pyx_t_13 = __pyx_t_14 = __pyx_t_15 = 0;
      }
      __pyx_pybuffernd_tractParams.diminfo[0].strides = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tractParams.diminfo[0].shape = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.shape[0];
      if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 931, __pyx_L1_error)
    }
    __pyx_t_10 = 0;
    __Pyx_DECREF_SET(__pyx_v_tractParams, ((PyArrayObject *)__pyx_t_8));
    __pyx_t_8 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":932
 * 		index, tract_state = pair
 * 		tractParams = tract_state.ravel()
 * 		fileName = ( svg_dir + '/tract_{}.svg'.format( index ) ).encode()             # <<<<<<<<<<<<<<
 * 		vtlExportTractSvg( &tractParams[0], fileName )
 * 	return
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_tract__svg, __pyx_n_s_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    __pyx_t_4 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_1, __pyx_v_index) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_index);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyNumber_Add(__pyx_v_svg_dir, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_encode); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_8 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF_SET(__pyx_v_fileName, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":933
 * 		tractParams = tract_state.ravel()
 * 		fileName = ( svg_dir + '/tract_{}.svg'.format( index ) ).encode()
 * 		vtlExportTractSvg( &tractParams[0], fileName )             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __pyx_t_16 = 0;
    __pyx_t_9 = -1;
    if (__pyx_t_16 < 0) {
      __pyx_t_16 += __pyx_pybuffernd_tractParams.diminfo[0].shape;
      if (unlikely(__pyx_t_16 < 0)) __pyx_t_9 = 0;
    } else if (unlikely(__pyx_t_16 >= __pyx_pybuffernd_tractParams.diminfo[0].shape)) __pyx_t_9 = 0;
    if (unlikely(__pyx_t_9 != -1)) {
      __Pyx_RaiseBufferIndexError(__pyx_t_9);
      __PYX_ERR(0, 933, __pyx_L1_error)
    }
    __pyx_t_17 = __Pyx_PyObject_AsString(__pyx_v_fileName); if (unlikely((!__pyx_t_17) && PyErr_Occurred())) __PYX_ERR(0, 933, __pyx_L1_error)
    (void)(vtlExportTractSvg((&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf, __pyx_t_16, __pyx_pybuffernd_tractParams.diminfo[0].strides))), __pyx_t_17));

    /* "VocalTractLab/VocalTractLabApi.pyx":929
 * 	resampled_index = [ round(index * (44100 / 110) / fps) for index in range( 0, motor_sequence.length ) ]
 * 	resampled_tract_states = [ [ index, tract_state ] for index, tract_state in enumerate( motor_sequence.states.to_numpy() ) if index in resampled_index ]
 * 	for pair in resampled_tract_states:             # <<<<<<<<<<<<<<
 * 		index, tract_state = pair
 * 		tractParams = tract_state.ravel()
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":934
 * 		fileName = ( svg_dir + '/tract_{}.svg'.format( index ) ).encode()
 * 		vtlExportTractSvg( &tractParams[0], fileName )
 * 	return             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_transfer_function( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":910
 * 	return outTractParams
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_svg( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._tract_sequence_to_svg", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_motor_sequence);
  __Pyx_XDECREF(__pyx_v_svg_dir);
  __Pyx_XDECREF(__pyx_v_fps);
  __Pyx_XDECREF(__pyx_v_tract_file_path);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF((PyObject *)__pyx_v_tractParams);
  __Pyx_XDECREF(__pyx_v_resampled_index);
  __Pyx_XDECREF(__pyx_v_resampled_tract_states);
  __Pyx_XDECREF(__pyx_v_pair);
  __Pyx_XDECREF(__pyx_v_index);
  __Pyx_XDECREF(__pyx_v_tract_state);
  __Pyx_XDECREF(__pyx_v_fileName);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":936
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_transfer_function( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args
 * 	magnitude_spectrum = None
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_71_tract_state_to_transfer_function(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_71_tract_state_to_transfer_function = {"_tract_state_to_transfer_function", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_71_tract_state_to_transfer_function, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_71_tract_state_to_transfer_function(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_tract_state_to_transfer_function (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_70_tract_state_to_transfer_function(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_70_tract_state_to_transfer_function(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_tract_state = NULL;
  PyObject *__pyx_v_n_spectrum_samples = NULL;
  PyObject *__pyx_v_save_magnitude_spectrum = NULL;
  PyObject *__pyx_v_save_phase_spectrum = NULL;
  PyObject *__pyx_v_magnitude_spectrum = NULL;
  PyObject *__pyx_v_phase_spectrum = NULL;
  int __pyx_v_numSpectrumSamples;
  PyArrayObject *__pyx_v_tractParams = 0;
  PyArrayObject *__pyx_v_magnitude = 0;
  PyArrayObject *__pyx_v_phase_rad = 0;
  CYTHON_UNUSED int __pyx_v_value;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_magnitude;
  __Pyx_Buffer __pyx_pybuffer_magnitude;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_phase_rad;
  __Pyx_Buffer __pyx_pybuffer_phase_rad;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tractParams;
  __Pyx_Buffer __pyx_pybuffer_tractParams;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  int __pyx_t_7;
  PyArrayObject *__pyx_t_8 = NULL;
  PyArrayObject *__pyx_t_9 = NULL;
  PyArrayObject *__pyx_t_10 = NULL;
  Py_ssize_t __pyx_t_11;
  Py_ssize_t __pyx_t_12;
  Py_ssize_t __pyx_t_13;
  int __pyx_t_14;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tract_state_to_transfer_function", 0);
  __pyx_pybuffer_tractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_tractParams.refcount = 0;
  __pyx_pybuffernd_tractParams.data = NULL;
  __pyx_pybuffernd_tractParams.rcbuffer = &__pyx_pybuffer_tractParams;
  __pyx_pybuffer_magnitude.pybuffer.buf = NULL;
  __pyx_pybuffer_magnitude.refcount = 0;
  __pyx_pybuffernd_magnitude.data = NULL;
  __pyx_pybuffernd_magnitude.rcbuffer = &__pyx_pybuffer_magnitude;
  __pyx_pybuffer_phase_rad.pybuffer.buf = NULL;
  __pyx_pybuffer_phase_rad.refcount = 0;
  __pyx_pybuffernd_phase_rad.data = NULL;
  __pyx_pybuffernd_phase_rad.rcbuffer = &__pyx_pybuffer_phase_rad;

  /* "VocalTractLab/VocalTractLabApi.pyx":937
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_transfer_function( args ):
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args             # <<<<<<<<<<<<<<
 * 	magnitude_spectrum = None
 * 	phase_spectrum = None
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 4)) {
      if (size > 4) __Pyx_RaiseTooManyValuesError(4);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 937, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 3); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 3); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    #else
    {
      Py_ssize_t i;
      PyObject** temps[4] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4};
      for (i=0; i < 4; i++) {
        PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 937, __pyx_L1_error)
        __Pyx_GOTREF(item);
        *(temps[i]) = item;
      }
    }
    #endif
  } else {
    Py_ssize_t index = -1;
    PyObject** temps[4] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4};
    __pyx_t_5 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 937, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = Py_TYPE(__pyx_t_5)->tp_iternext;
    for (index=0; index < 4; index++) {
      PyObject* item = __pyx_t_6(__pyx_t_5); if (unlikely(!item)) goto __pyx_L3_unpacking_failed;
      __Pyx_GOTREF(item);
      *(temps[index]) = item;
    }
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 4) < 0) __PYX_ERR(0, 937, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 937, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_tract_state = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_n_spectrum_samples = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_save_magnitude_spectrum = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_save_phase_spectrum = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":938
 * def _tract_state_to_transfer_function( args ):
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args
 * 	magnitude_spectrum = None             # <<<<<<<<<<<<<<
 * 	phase_spectrum = None
 * 	cdef int numSpectrumSamples = n_spectrum_samples
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_magnitude_spectrum = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":939
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args
 * 	magnitude_spectrum = None
 * 	phase_spectrum = None             # <<<<<<<<<<<<<<
 * 	cdef int numSpectrumSamples = n_spectrum_samples
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_phase_spectrum = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":940
 * 	magnitude_spectrum = None
 * 	phase_spectrum = None
 * 	cdef int numSpectrumSamples = n_spectrum_samples             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] magnitude = np.zeros( n_spectrum_samples, dtype='float64' )
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_n_spectrum_samples); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 940, __pyx_L1_error)
  __pyx_v_numSpectrumSamples = __pyx_t_7;

  /* "VocalTractLab/VocalTractLabApi.pyx":941
 * 	phase_spectrum = None
 * 	cdef int numSpectrumSamples = n_spectrum_samples
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] magnitude = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] phase_rad = np.zeros( n_spectrum_samples, dtype='float64' )
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_tract_state, __pyx_n_s_ravel); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 941, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_4 = (__pyx_t_2) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 941, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 941, __pyx_L1_error)
  __pyx_t_8 = ((PyArrayObject *)__pyx_t_4);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_8, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 941, __pyx_L1_error)
    } else {__pyx_pybuffernd_tractParams.diminfo[0].strides = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tractParams.diminfo[0].shape = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_8 = 0;
  __pyx_v_tractParams = ((PyArrayObject *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":942
 * 	cdef int numSpectrumSamples = n_spectrum_samples
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] magnitude = np.zeros( n_spectrum_samples, dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] phase_rad = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	value = vtlGetTransferFunction( &tractParams[0],
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_n_spectrum_samples);
  __Pyx_GIVEREF(__pyx_v_n_spectrum_samples);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_n_spectrum_samples);
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 942, __pyx_L1_error)
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 942, __pyx_L1_error)
  __pyx_t_9 = ((PyArrayObject *)__pyx_t_1);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_magnitude.rcbuffer->pybuffer, (PyObject*)__pyx_t_9, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_magnitude = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_magnitude.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 942, __pyx_L1_error)
    } else {__pyx_pybuffernd_magnitude.diminfo[0].strides = __pyx_pybuffernd_magnitude.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_magnitude.diminfo[0].shape = __pyx_pybuffernd_magnitude.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_9 = 0;
  __pyx_v_magnitude = ((PyArrayObject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":943
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] magnitude = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] phase_rad = np.zeros( n_spectrum_samples, dtype='float64' )             # <<<<<<<<<<<<<<
 * 	value = vtlGetTransferFunction( &tractParams[0],
 * 	                                numSpectrumSamples,
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 943, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 943, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 943, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_n_spectrum_samples);
  __Pyx_GIVEREF(__pyx_v_n_spectrum_samples);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_n_spectrum_samples);
  __pyx_t_4 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 943, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 943, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_1, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 943, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 943, __pyx_L1_error)
  __pyx_t_10 = ((PyArrayObject *)__pyx_t_3);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_phase_rad.rcbuffer->pybuffer, (PyObject*)__pyx_t_10, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_phase_rad = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_phase_rad.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 943, __pyx_L1_error)
    } else {__pyx_pybuffernd_phase_rad.diminfo[0].strides = __pyx_pybuffernd_phase_rad.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_phase_rad.diminfo[0].shape = __pyx_pybuffernd_phase_rad.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_10 = 0;
  __pyx_v_phase_rad = ((PyArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":944
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] magnitude = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] phase_rad = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	value = vtlGetTransferFunction( &tractParams[0],             # <<<<<<<<<<<<<<
 * 	                                numSpectrumSamples,
 * 	                                NULL,
 */
  __pyx_t_11 = 0;
  __pyx_t_7 = -1;
  if (__pyx_t_11 < 0) {
    __pyx_t_11 += __pyx_pybuffernd_tractParams.diminfo[0].shape;
    if (unlikely(__pyx_t_11 < 0)) __pyx_t_7 = 0;
  } else if (unlikely(__pyx_t_11 >= __pyx_pybuffernd_tractParams.diminfo[0].shape)) __pyx_t_7 = 0;
  if (unlikely(__pyx_t_7 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_7);
    __PYX_ERR(0, 944, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":947
 * 	                                numSpectrumSamples,
 * 	                                NULL,
 * 	                                &magnitude[0],             # <<<<<<<<<<<<<<
 * 	                                &phase_rad[0],
 * 	                              )
 */
  __pyx_t_12 = 0;
  __pyx_t_7 = -1;
  if (__pyx_t_12 < 0) {
    __pyx_t_12 += __pyx_pybuffernd_magnitude.diminfo[0].shape;
    if (unlikely(__pyx_t_12 < 0)) __pyx_t_7 = 0;
  } else if (unlikely(__pyx_t_12 >= __pyx_pybuffernd_magnitude.diminfo[0].shape)) __pyx_t_7 = 0;
  if (unlikely(__pyx_t_7 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_7);
    __PYX_ERR(0, 947, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":948
 * 	                                NULL,
 * 	                                &magnitude[0],
 * 	                                &phase_rad[0],             # <<<<<<<<<<<<<<
 * 	                              )
 * 	if save_magnitude_spectrum:
 */
  __pyx_t_13 = 0;
  __pyx_t_7 = -1;
  if (__pyx_t_13 < 0) {
    __pyx_t_13 += __pyx_pybuffernd_phase_rad.diminfo[0].shape;
    if (unlikely(__pyx_t_13 < 0)) __pyx_t_7 = 0;
  } else if (unlikely(__pyx_t_13 >= __pyx_pybuffernd_phase_rad.diminfo[0].shape)) __pyx_t_7 = 0;
  if (unlikely(__pyx_t_7 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_7);
    __PYX_ERR(0, 948, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":944
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] magnitude = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] phase_rad = np.zeros( n_spectrum_samples, dtype='float64' )
 * 	value = vtlGetTransferFunction( &tractParams[0],             # <<<<<<<<<<<<<<
 * 	                                numSpectrumSamples,
 * 	                                NULL,
 */
  __pyx_v_value = vtlGetTransferFunction((&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf, __pyx_t_11, __pyx_pybuffernd_tractParams.diminfo[0].strides))), __pyx_v_numSpectrumSamples, NULL, (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_magnitude.rcbuffer->pybuffer.buf, __pyx_t_12, __pyx_pybuffernd_magnitude.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_phase_rad.rcbuffer->pybuffer.buf, __pyx_t_13, __pyx_pybuffernd_phase_rad.diminfo[0].strides))));

  /* "VocalTractLab/VocalTractLabApi.pyx":950
 * 	                                &phase_rad[0],
 * 	                              )
 * 	if save_magnitude_spectrum:             # <<<<<<<<<<<<<<
 * 		magnitude_spectrum = np.array( magnitude )
 * 	if save_phase_spectrum:
 */
  __pyx_t_14 = __Pyx_PyObject_IsTrue(__pyx_v_save_magnitude_spectrum); if (unlikely(__pyx_t_14 < 0)) __PYX_ERR(0, 950, __pyx_L1_error)
  if (__pyx_t_14) {

    /* "VocalTractLab/VocalTractLabApi.pyx":951
 * 	                              )
 * 	if save_magnitude_spectrum:
 * 		magnitude_spectrum = np.array( magnitude )             # <<<<<<<<<<<<<<
 * 	if save_phase_spectrum:
 * 		phase_spectrum = np.array( phase_rad )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 951, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_array); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 951, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_4, ((PyObject *)__pyx_v_magnitude)) : __Pyx_PyObject_CallOneArg(__pyx_t_1, ((PyObject *)__pyx_v_magnitude));
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 951, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_magnitude_spectrum, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":950
 * 	                                &phase_rad[0],
 * 	                              )
 * 	if save_magnitude_spectrum:             # <<<<<<<<<<<<<<
 * 		magnitude_spectrum = np.array( magnitude )
 * 	if save_phase_spectrum:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":952
 * 	if save_magnitude_spectrum:
 * 		magnitude_spectrum = np.array( magnitude )
 * 	if save_phase_spectrum:             # <<<<<<<<<<<<<<
 * 		phase_spectrum = np.array( phase_rad )
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 */
  __pyx_t_14 = __Pyx_PyObject_IsTrue(__pyx_v_save_phase_spectrum); if (unlikely(__pyx_t_14 < 0)) __PYX_ERR(0, 952, __pyx_L1_error)
  if (__pyx_t_14) {

    /* "VocalTractLab/VocalTractLabApi.pyx":953
 * 		magnitude_spectrum = np.array( magnitude )
 * 	if save_phase_spectrum:
 * 		phase_spectrum = np.array( phase_rad )             # <<<<<<<<<<<<<<
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 953, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_array); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 953, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_3 = (__pyx_t_1) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_1, ((PyObject *)__pyx_v_phase_rad)) : __Pyx_PyObject_CallOneArg(__pyx_t_4, ((PyObject *)__pyx_v_phase_rad));
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 953, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_phase_spectrum, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":952
 * 	if save_magnitude_spectrum:
 * 		magnitude_spectrum = np.array( magnitude )
 * 	if save_phase_spectrum:             # <<<<<<<<<<<<<<
 * 		phase_spectrum = np.array( phase_rad )
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":954
 * 	if save_phase_spectrum:
 * 		phase_spectrum = np.array( phase_rad )
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_tube_state( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_Transfer_Function); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 954, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_1 = NULL;
  __pyx_t_7 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
      __pyx_t_7 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_4)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_magnitude_spectrum, __pyx_v_phase_spectrum, __pyx_v_n_spectrum_samples};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 3+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 954, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_magnitude_spectrum, __pyx_v_phase_spectrum, __pyx_v_n_spectrum_samples};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 3+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 954, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
  } else
  #endif
  {
    __pyx_t_2 = PyTuple_New(3+__pyx_t_7); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 954, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_magnitude_spectrum);
    __Pyx_GIVEREF(__pyx_v_magnitude_spectrum);
    PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_7, __pyx_v_magnitude_spectrum);
    __Pyx_INCREF(__pyx_v_phase_spectrum);
    __Pyx_GIVEREF(__pyx_v_phase_spectrum);
    PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_7, __pyx_v_phase_spectrum);
    __Pyx_INCREF(__pyx_v_n_spectrum_samples);
    __Pyx_GIVEREF(__pyx_v_n_spectrum_samples);
    PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_7, __pyx_v_n_spectrum_samples);
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 954, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":936
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_transfer_function( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args
 * 	magnitude_spectrum = None
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_magnitude.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_phase_rad.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._tract_state_to_transfer_function", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_magnitude.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_phase_rad.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_tract_state);
  __Pyx_XDECREF(__pyx_v_n_spectrum_samples);
  __Pyx_XDECREF(__pyx_v_save_magnitude_spectrum);
  __Pyx_XDECREF(__pyx_v_save_phase_spectrum);
  __Pyx_XDECREF(__pyx_v_magnitude_spectrum);
  __Pyx_XDECREF(__pyx_v_phase_spectrum);
  __Pyx_XDECREF((PyObject *)__pyx_v_tractParams);
  __Pyx_XDECREF((PyObject *)__pyx_v_magnitude);
  __Pyx_XDECREF((PyObject *)__pyx_v_phase_rad);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":956
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_tube_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args
 * 	tube_length = None
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_73_tract_state_to_tube_state(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_73_tract_state_to_tube_state = {"_tract_state_to_tube_state", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_73_tract_state_to_tube_state, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_73_tract_state_to_tube_state(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_tract_state_to_tube_state (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_72_tract_state_to_tube_state(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_72_tract_state_to_tube_state(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_tract_state = NULL;
  PyObject *__pyx_v_save_tube_length = NULL;
  PyObject *__pyx_v_save_tube_area = NULL;
  PyObject *__pyx_v_save_tube_articulator = NULL;
  PyObject *__pyx_v_save_incisor_position = NULL;
  PyObject *__pyx_v_save_tongue_tip_side_elevation = NULL;
  PyObject *__pyx_v_save_velum_opening = NULL;
  PyObject *__pyx_v_tube_length = NULL;
  PyObject *__pyx_v_tube_area = NULL;
  PyObject *__pyx_v_tube_articulator = NULL;
  PyObject *__pyx_v_incisor_position = NULL;
  PyObject *__pyx_v_tongue_tip_side_elevation = NULL;
  PyObject *__pyx_v_velum_opening = NULL;
  PyObject *__pyx_v_constants = NULL;
  PyArrayObject *__pyx_v_tractParams = 0;
  PyArrayObject *__pyx_v_tubeLength_cm = 0;
  PyArrayObject *__pyx_v_tubeArea_cm2 = 0;
  PyArrayObject *__pyx_v_tubeArticulator = 0;
  double __pyx_v_incisorPos_cm;
  double __pyx_v_tongueTipSideElevation;
  double __pyx_v_velumOpening_cm2;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tractParams;
  __Pyx_Buffer __pyx_pybuffer_tractParams;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tubeArea_cm2;
  __Pyx_Buffer __pyx_pybuffer_tubeArea_cm2;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tubeArticulator;
  __Pyx_Buffer __pyx_pybuffer_tubeArticulator;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_tubeLength_cm;
  __Pyx_Buffer __pyx_pybuffer_tubeLength_cm;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *(*__pyx_t_9)(PyObject *);
  PyArrayObject *__pyx_t_10 = NULL;
  PyArrayObject *__pyx_t_11 = NULL;
  PyArrayObject *__pyx_t_12 = NULL;
  PyArrayObject *__pyx_t_13 = NULL;
  Py_ssize_t __pyx_t_14;
  int __pyx_t_15;
  Py_ssize_t __pyx_t_16;
  Py_ssize_t __pyx_t_17;
  Py_ssize_t __pyx_t_18;
  int __pyx_t_19;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_tract_state_to_tube_state", 0);
  __pyx_pybuffer_tractParams.pybuffer.buf = NULL;
  __pyx_pybuffer_tractParams.refcount = 0;
  __pyx_pybuffernd_tractParams.data = NULL;
  __pyx_pybuffernd_tractParams.rcbuffer = &__pyx_pybuffer_tractParams;
  __pyx_pybuffer_tubeLength_cm.pybuffer.buf = NULL;
  __pyx_pybuffer_tubeLength_cm.refcount = 0;
  __pyx_pybuffernd_tubeLength_cm.data = NULL;
  __pyx_pybuffernd_tubeLength_cm.rcbuffer = &__pyx_pybuffer_tubeLength_cm;
  __pyx_pybuffer_tubeArea_cm2.pybuffer.buf = NULL;
  __pyx_pybuffer_tubeArea_cm2.refcount = 0;
  __pyx_pybuffernd_tubeArea_cm2.data = NULL;
  __pyx_pybuffernd_tubeArea_cm2.rcbuffer = &__pyx_pybuffer_tubeArea_cm2;
  __pyx_pybuffer_tubeArticulator.pybuffer.buf = NULL;
  __pyx_pybuffer_tubeArticulator.refcount = 0;
  __pyx_pybuffernd_tubeArticulator.data = NULL;
  __pyx_pybuffernd_tubeArticulator.rcbuffer = &__pyx_pybuffer_tubeArticulator;

  /* "VocalTractLab/VocalTractLabApi.pyx":957
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_tube_state( args ):
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args             # <<<<<<<<<<<<<<
 * 	tube_length = None
 * 	tube_area = None
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 7)) {
      if (size > 7) __Pyx_RaiseTooManyValuesError(7);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 957, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyTuple_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyTuple_GET_ITEM(sequence, 5); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 6); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 3); 
      __pyx_t_5 = PyList_GET_ITEM(sequence, 4); 
      __pyx_t_6 = PyList_GET_ITEM(sequence, 5); 
      __pyx_t_7 = PyList_GET_ITEM(sequence, 6); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_t_7);
    #else
    {
      Py_ssize_t i;
      PyObject** temps[7] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6,&__pyx_t_7};
      for (i=0; i < 7; i++) {
        PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 957, __pyx_L1_error)
        __Pyx_GOTREF(item);
        *(temps[i]) = item;
      }
    }
    #endif
  } else {
    Py_ssize_t index = -1;
    PyObject** temps[7] = {&__pyx_t_1,&__pyx_t_2,&__pyx_t_3,&__pyx_t_4,&__pyx_t_5,&__pyx_t_6,&__pyx_t_7};
    __pyx_t_8 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 957, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = Py_TYPE(__pyx_t_8)->tp_iternext;
    for (index=0; index < 7; index++) {
      PyObject* item = __pyx_t_9(__pyx_t_8); if (unlikely(!item)) goto __pyx_L3_unpacking_failed;
      __Pyx_GOTREF(item);
      *(temps[index]) = item;
    }
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_9(__pyx_t_8), 7) < 0) __PYX_ERR(0, 957, __pyx_L1_error)
    __pyx_t_9 = NULL;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 957, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_tract_state = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_save_tube_length = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_save_tube_area = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_save_tube_articulator = __pyx_t_4;
  __pyx_t_4 = 0;
  __pyx_v_save_incisor_position = __pyx_t_5;
  __pyx_t_5 = 0;
  __pyx_v_save_tongue_tip_side_elevation = __pyx_t_6;
  __pyx_t_6 = 0;
  __pyx_v_save_velum_opening = __pyx_t_7;
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":958
 * def _tract_state_to_tube_state( args ):
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args
 * 	tube_length = None             # <<<<<<<<<<<<<<
 * 	tube_area = None
 * 	tube_articulator = None
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_tube_length = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":959
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args
 * 	tube_length = None
 * 	tube_area = None             # <<<<<<<<<<<<<<
 * 	tube_articulator = None
 * 	incisor_position = None
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_tube_area = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":960
 * 	tube_length = None
 * 	tube_area = None
 * 	tube_articulator = None             # <<<<<<<<<<<<<<
 * 	incisor_position = None
 * 	tongue_tip_side_elevation = None
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_tube_articulator = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":961
 * 	tube_area = None
 * 	tube_articulator = None
 * 	incisor_position = None             # <<<<<<<<<<<<<<
 * 	tongue_tip_side_elevation = None
 * 	velum_opening = None
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_incisor_position = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":962
 * 	tube_articulator = None
 * 	incisor_position = None
 * 	tongue_tip_side_elevation = None             # <<<<<<<<<<<<<<
 * 	velum_opening = None
 * 	constants = get_constants()
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_tongue_tip_side_elevation = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":963
 * 	incisor_position = None
 * 	tongue_tip_side_elevation = None
 * 	velum_opening = None             # <<<<<<<<<<<<<<
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_velum_opening = Py_None;

  /* "VocalTractLab/VocalTractLabApi.pyx":964
 * 	tongue_tip_side_elevation = None
 * 	velum_opening = None
 * 	constants = get_constants()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeLength_cm = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_get_constants); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 964, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_7 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 964, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_constants = __pyx_t_7;
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":965
 * 	velum_opening = None
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeLength_cm = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeArea_cm2 = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_tract_state, __pyx_n_s_ravel); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 965, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_7 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 965, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!(likely(((__pyx_t_7) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_7, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 965, __pyx_L1_error)
  __pyx_t_10 = ((PyArrayObject *)__pyx_t_7);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer, (PyObject*)__pyx_t_10, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tractParams = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 965, __pyx_L1_error)
    } else {__pyx_pybuffernd_tractParams.diminfo[0].strides = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tractParams.diminfo[0].shape = __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_10 = 0;
  __pyx_v_tractParams = ((PyArrayObject *)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":966
 * 	constants = get_constants()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeLength_cm = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeArea_cm2 = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 * 	cdef np.ndarray[ int, ndim=1 ] tubeArticulator = np.zeros( constants[ 'n_tube_sections' ], dtype='i' )
 */
  __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_np); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_zeros); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_tube_sections); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_7);
  PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_7);
  __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 966, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 966, __pyx_L1_error)
  __pyx_t_11 = ((PyArrayObject *)__pyx_t_4);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer, (PyObject*)__pyx_t_11, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tubeLength_cm = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 966, __pyx_L1_error)
    } else {__pyx_pybuffernd_tubeLength_cm.diminfo[0].strides = __pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tubeLength_cm.diminfo[0].shape = __pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_11 = 0;
  __pyx_v_tubeLength_cm = ((PyArrayObject *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":967
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tractParams = tract_state.ravel()
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeLength_cm = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeArea_cm2 = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )             # <<<<<<<<<<<<<<
 * 	cdef np.ndarray[ int, ndim=1 ] tubeArticulator = np.zeros( constants[ 'n_tube_sections' ], dtype='i' )
 * 	cdef double incisorPos_cm = 0.0
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 967, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_zeros); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 967, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_tube_sections); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 967, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 967, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 967, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_dtype, __pyx_n_s_float64) < 0) __PYX_ERR(0, 967, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_5, __pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 967, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (!(likely(((__pyx_t_6) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_6, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 967, __pyx_L1_error)
  __pyx_t_12 = ((PyArrayObject *)__pyx_t_6);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer, (PyObject*)__pyx_t_12, &__Pyx_TypeInfo_nn___pyx_t_5numpy_float64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tubeArea_cm2 = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 967, __pyx_L1_error)
    } else {__pyx_pybuffernd_tubeArea_cm2.diminfo[0].strides = __pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tubeArea_cm2.diminfo[0].shape = __pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_12 = 0;
  __pyx_v_tubeArea_cm2 = ((PyArrayObject *)__pyx_t_6);
  __pyx_t_6 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":968
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeLength_cm = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeArea_cm2 = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 * 	cdef np.ndarray[ int, ndim=1 ] tubeArticulator = np.zeros( constants[ 'n_tube_sections' ], dtype='i' )             # <<<<<<<<<<<<<<
 * 	cdef double incisorPos_cm = 0.0
 * 	cdef double tongueTipSideElevation = 0.0
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_zeros); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_v_constants, __pyx_n_s_n_tube_sections); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_6);
  PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_6);
  __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  if (PyDict_SetItem(__pyx_t_6, __pyx_n_s_dtype, __pyx_n_s_i) < 0) __PYX_ERR(0, 968, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_5, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!(likely(((__pyx_t_7) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_7, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 968, __pyx_L1_error)
  __pyx_t_13 = ((PyArrayObject *)__pyx_t_7);
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer, (PyObject*)__pyx_t_13, &__Pyx_TypeInfo_int, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) {
      __pyx_v_tubeArticulator = ((PyArrayObject *)Py_None); __Pyx_INCREF(Py_None); __pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer.buf = NULL;
      __PYX_ERR(0, 968, __pyx_L1_error)
    } else {__pyx_pybuffernd_tubeArticulator.diminfo[0].strides = __pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_tubeArticulator.diminfo[0].shape = __pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer.shape[0];
    }
  }
  __pyx_t_13 = 0;
  __pyx_v_tubeArticulator = ((PyArrayObject *)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":969
 * 	cdef np.ndarray[ np.float64_t, ndim=1 ] tubeArea_cm2 = np.zeros( constants[ 'n_tube_sections' ], dtype='float64' )
 * 	cdef np.ndarray[ int, ndim=1 ] tubeArticulator = np.zeros( constants[ 'n_tube_sections' ], dtype='i' )
 * 	cdef double incisorPos_cm = 0.0             # <<<<<<<<<<<<<<
 * 	cdef double tongueTipSideElevation = 0.0
 * 	cdef double velumOpening_cm2 = 0.0
 */
  __pyx_v_incisorPos_cm = 0.0;

  /* "VocalTractLab/VocalTractLabApi.pyx":970
 * 	cdef np.ndarray[ int, ndim=1 ] tubeArticulator = np.zeros( constants[ 'n_tube_sections' ], dtype='i' )
 * 	cdef double incisorPos_cm = 0.0
 * 	cdef double tongueTipSideElevation = 0.0             # <<<<<<<<<<<<<<
 * 	cdef double velumOpening_cm2 = 0.0
 * 	vtlTractToTube( &tractParams[0],
 */
  __pyx_v_tongueTipSideElevation = 0.0;

  /* "VocalTractLab/VocalTractLabApi.pyx":971
 * 	cdef double incisorPos_cm = 0.0
 * 	cdef double tongueTipSideElevation = 0.0
 * 	cdef double velumOpening_cm2 = 0.0             # <<<<<<<<<<<<<<
 * 	vtlTractToTube( &tractParams[0],
 * 	                &tubeLength_cm[0],
 */
  __pyx_v_velumOpening_cm2 = 0.0;

  /* "VocalTractLab/VocalTractLabApi.pyx":972
 * 	cdef double tongueTipSideElevation = 0.0
 * 	cdef double velumOpening_cm2 = 0.0
 * 	vtlTractToTube( &tractParams[0],             # <<<<<<<<<<<<<<
 * 	                &tubeLength_cm[0],
 * 	                &tubeArea_cm2[0],
 */
  __pyx_t_14 = 0;
  __pyx_t_15 = -1;
  if (__pyx_t_14 < 0) {
    __pyx_t_14 += __pyx_pybuffernd_tractParams.diminfo[0].shape;
    if (unlikely(__pyx_t_14 < 0)) __pyx_t_15 = 0;
  } else if (unlikely(__pyx_t_14 >= __pyx_pybuffernd_tractParams.diminfo[0].shape)) __pyx_t_15 = 0;
  if (unlikely(__pyx_t_15 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_15);
    __PYX_ERR(0, 972, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":973
 * 	cdef double velumOpening_cm2 = 0.0
 * 	vtlTractToTube( &tractParams[0],
 * 	                &tubeLength_cm[0],             # <<<<<<<<<<<<<<
 * 	                &tubeArea_cm2[0],
 * 	                &tubeArticulator[0],
 */
  __pyx_t_16 = 0;
  __pyx_t_15 = -1;
  if (__pyx_t_16 < 0) {
    __pyx_t_16 += __pyx_pybuffernd_tubeLength_cm.diminfo[0].shape;
    if (unlikely(__pyx_t_16 < 0)) __pyx_t_15 = 0;
  } else if (unlikely(__pyx_t_16 >= __pyx_pybuffernd_tubeLength_cm.diminfo[0].shape)) __pyx_t_15 = 0;
  if (unlikely(__pyx_t_15 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_15);
    __PYX_ERR(0, 973, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":974
 * 	vtlTractToTube( &tractParams[0],
 * 	                &tubeLength_cm[0],
 * 	                &tubeArea_cm2[0],             # <<<<<<<<<<<<<<
 * 	                &tubeArticulator[0],
 * 	                &incisorPos_cm,
 */
  __pyx_t_17 = 0;
  __pyx_t_15 = -1;
  if (__pyx_t_17 < 0) {
    __pyx_t_17 += __pyx_pybuffernd_tubeArea_cm2.diminfo[0].shape;
    if (unlikely(__pyx_t_17 < 0)) __pyx_t_15 = 0;
  } else if (unlikely(__pyx_t_17 >= __pyx_pybuffernd_tubeArea_cm2.diminfo[0].shape)) __pyx_t_15 = 0;
  if (unlikely(__pyx_t_15 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_15);
    __PYX_ERR(0, 974, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":975
 * 	                &tubeLength_cm[0],
 * 	                &tubeArea_cm2[0],
 * 	                &tubeArticulator[0],             # <<<<<<<<<<<<<<
 * 	                &incisorPos_cm,
 * 	                &tongueTipSideElevation,
 */
  __pyx_t_18 = 0;
  __pyx_t_15 = -1;
  if (__pyx_t_18 < 0) {
    __pyx_t_18 += __pyx_pybuffernd_tubeArticulator.diminfo[0].shape;
    if (unlikely(__pyx_t_18 < 0)) __pyx_t_15 = 0;
  } else if (unlikely(__pyx_t_18 >= __pyx_pybuffernd_tubeArticulator.diminfo[0].shape)) __pyx_t_15 = 0;
  if (unlikely(__pyx_t_15 != -1)) {
    __Pyx_RaiseBufferIndexError(__pyx_t_15);
    __PYX_ERR(0, 975, __pyx_L1_error)
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":972
 * 	cdef double tongueTipSideElevation = 0.0
 * 	cdef double velumOpening_cm2 = 0.0
 * 	vtlTractToTube( &tractParams[0],             # <<<<<<<<<<<<<<
 * 	                &tubeLength_cm[0],
 * 	                &tubeArea_cm2[0],
 */
  (void)(vtlTractToTube((&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tractParams.rcbuffer->pybuffer.buf, __pyx_t_14, __pyx_pybuffernd_tractParams.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer.buf, __pyx_t_16, __pyx_pybuffernd_tubeLength_cm.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_float64_t *, __pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer.buf, __pyx_t_17, __pyx_pybuffernd_tubeArea_cm2.diminfo[0].strides))), (&(*__Pyx_BufPtrStrided1d(int *, __pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer.buf, __pyx_t_18, __pyx_pybuffernd_tubeArticulator.diminfo[0].strides))), (&__pyx_v_incisorPos_cm), (&__pyx_v_tongueTipSideElevation), (&__pyx_v_velumOpening_cm2)));

  /* "VocalTractLab/VocalTractLabApi.pyx":980
 * 	                &velumOpening_cm2
 * 	                )
 * 	if save_tube_length:             # <<<<<<<<<<<<<<
 * 		tube_length = np.array( tubeLength_cm )
 * 	if save_tube_area:
 */
  __pyx_t_19 = __Pyx_PyObject_IsTrue(__pyx_v_save_tube_length); if (unlikely(__pyx_t_19 < 0)) __PYX_ERR(0, 980, __pyx_L1_error)
  if (__pyx_t_19) {

    /* "VocalTractLab/VocalTractLabApi.pyx":981
 * 	                )
 * 	if save_tube_length:
 * 		tube_length = np.array( tubeLength_cm )             # <<<<<<<<<<<<<<
 * 	if save_tube_area:
 * 		tube_area = np.array( tubeArea_cm2 )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 981, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_array); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 981, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_7 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, ((PyObject *)__pyx_v_tubeLength_cm)) : __Pyx_PyObject_CallOneArg(__pyx_t_5, ((PyObject *)__pyx_v_tubeLength_cm));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 981, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_tube_length, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":980
 * 	                &velumOpening_cm2
 * 	                )
 * 	if save_tube_length:             # <<<<<<<<<<<<<<
 * 		tube_length = np.array( tubeLength_cm )
 * 	if save_tube_area:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":982
 * 	if save_tube_length:
 * 		tube_length = np.array( tubeLength_cm )
 * 	if save_tube_area:             # <<<<<<<<<<<<<<
 * 		tube_area = np.array( tubeArea_cm2 )
 * 	if save_tube_articulator:
 */
  __pyx_t_19 = __Pyx_PyObject_IsTrue(__pyx_v_save_tube_area); if (unlikely(__pyx_t_19 < 0)) __PYX_ERR(0, 982, __pyx_L1_error)
  if (__pyx_t_19) {

    /* "VocalTractLab/VocalTractLabApi.pyx":983
 * 		tube_length = np.array( tubeLength_cm )
 * 	if save_tube_area:
 * 		tube_area = np.array( tubeArea_cm2 )             # <<<<<<<<<<<<<<
 * 	if save_tube_articulator:
 * 		tube_articulator = np.array( tubeArticulator )
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 983, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_array); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 983, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    __pyx_t_7 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_6, __pyx_t_5, ((PyObject *)__pyx_v_tubeArea_cm2)) : __Pyx_PyObject_CallOneArg(__pyx_t_6, ((PyObject *)__pyx_v_tubeArea_cm2));
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 983, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_tube_area, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":982
 * 	if save_tube_length:
 * 		tube_length = np.array( tubeLength_cm )
 * 	if save_tube_area:             # <<<<<<<<<<<<<<
 * 		tube_area = np.array( tubeArea_cm2 )
 * 	if save_tube_articulator:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":984
 * 	if save_tube_area:
 * 		tube_area = np.array( tubeArea_cm2 )
 * 	if save_tube_articulator:             # <<<<<<<<<<<<<<
 * 		tube_articulator = np.array( tubeArticulator )
 * 	if save_incisor_position:
 */
  __pyx_t_19 = __Pyx_PyObject_IsTrue(__pyx_v_save_tube_articulator); if (unlikely(__pyx_t_19 < 0)) __PYX_ERR(0, 984, __pyx_L1_error)
  if (__pyx_t_19) {

    /* "VocalTractLab/VocalTractLabApi.pyx":985
 * 		tube_area = np.array( tubeArea_cm2 )
 * 	if save_tube_articulator:
 * 		tube_articulator = np.array( tubeArticulator )             # <<<<<<<<<<<<<<
 * 	if save_incisor_position:
 * 		incisor_position = incisorPos_cm
 */
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 985, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_array); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 985, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    __pyx_t_7 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, ((PyObject *)__pyx_v_tubeArticulator)) : __Pyx_PyObject_CallOneArg(__pyx_t_5, ((PyObject *)__pyx_v_tubeArticulator));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 985, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_tube_articulator, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":984
 * 	if save_tube_area:
 * 		tube_area = np.array( tubeArea_cm2 )
 * 	if save_tube_articulator:             # <<<<<<<<<<<<<<
 * 		tube_articulator = np.array( tubeArticulator )
 * 	if save_incisor_position:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":986
 * 	if save_tube_articulator:
 * 		tube_articulator = np.array( tubeArticulator )
 * 	if save_incisor_position:             # <<<<<<<<<<<<<<
 * 		incisor_position = incisorPos_cm
 * 	if save_tongue_tip_side_elevation:
 */
  __pyx_t_19 = __Pyx_PyObject_IsTrue(__pyx_v_save_incisor_position); if (unlikely(__pyx_t_19 < 0)) __PYX_ERR(0, 986, __pyx_L1_error)
  if (__pyx_t_19) {

    /* "VocalTractLab/VocalTractLabApi.pyx":987
 * 		tube_articulator = np.array( tubeArticulator )
 * 	if save_incisor_position:
 * 		incisor_position = incisorPos_cm             # <<<<<<<<<<<<<<
 * 	if save_tongue_tip_side_elevation:
 * 		tongue_tip_side_elevation = tongueTipSideElevation
 */
    __pyx_t_7 = PyFloat_FromDouble(__pyx_v_incisorPos_cm); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 987, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF_SET(__pyx_v_incisor_position, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":986
 * 	if save_tube_articulator:
 * 		tube_articulator = np.array( tubeArticulator )
 * 	if save_incisor_position:             # <<<<<<<<<<<<<<
 * 		incisor_position = incisorPos_cm
 * 	if save_tongue_tip_side_elevation:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":988
 * 	if save_incisor_position:
 * 		incisor_position = incisorPos_cm
 * 	if save_tongue_tip_side_elevation:             # <<<<<<<<<<<<<<
 * 		tongue_tip_side_elevation = tongueTipSideElevation
 * 	if save_velum_opening:
 */
  __pyx_t_19 = __Pyx_PyObject_IsTrue(__pyx_v_save_tongue_tip_side_elevation); if (unlikely(__pyx_t_19 < 0)) __PYX_ERR(0, 988, __pyx_L1_error)
  if (__pyx_t_19) {

    /* "VocalTractLab/VocalTractLabApi.pyx":989
 * 		incisor_position = incisorPos_cm
 * 	if save_tongue_tip_side_elevation:
 * 		tongue_tip_side_elevation = tongueTipSideElevation             # <<<<<<<<<<<<<<
 * 	if save_velum_opening:
 * 		velum_opening = velumOpening_cm2
 */
    __pyx_t_7 = PyFloat_FromDouble(__pyx_v_tongueTipSideElevation); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 989, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF_SET(__pyx_v_tongue_tip_side_elevation, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":988
 * 	if save_incisor_position:
 * 		incisor_position = incisorPos_cm
 * 	if save_tongue_tip_side_elevation:             # <<<<<<<<<<<<<<
 * 		tongue_tip_side_elevation = tongueTipSideElevation
 * 	if save_velum_opening:
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":990
 * 	if save_tongue_tip_side_elevation:
 * 		tongue_tip_side_elevation = tongueTipSideElevation
 * 	if save_velum_opening:             # <<<<<<<<<<<<<<
 * 		velum_opening = velumOpening_cm2
 * 	return Tube_State( tube_length, tube_area, tube_articulator, incisor_position, tongue_tip_side_elevation, velum_opening )
 */
  __pyx_t_19 = __Pyx_PyObject_IsTrue(__pyx_v_save_velum_opening); if (unlikely(__pyx_t_19 < 0)) __PYX_ERR(0, 990, __pyx_L1_error)
  if (__pyx_t_19) {

    /* "VocalTractLab/VocalTractLabApi.pyx":991
 * 		tongue_tip_side_elevation = tongueTipSideElevation
 * 	if save_velum_opening:
 * 		velum_opening = velumOpening_cm2             # <<<<<<<<<<<<<<
 * 	return Tube_State( tube_length, tube_area, tube_articulator, incisor_position, tongue_tip_side_elevation, velum_opening )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
    __pyx_t_7 = PyFloat_FromDouble(__pyx_v_velumOpening_cm2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 991, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF_SET(__pyx_v_velum_opening, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":990
 * 	if save_tongue_tip_side_elevation:
 * 		tongue_tip_side_elevation = tongueTipSideElevation
 * 	if save_velum_opening:             # <<<<<<<<<<<<<<
 * 		velum_opening = velumOpening_cm2
 * 	return Tube_State( tube_length, tube_area, tube_articulator, incisor_position, tongue_tip_side_elevation, velum_opening )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":992
 * 	if save_velum_opening:
 * 		velum_opening = velumOpening_cm2
 * 	return Tube_State( tube_length, tube_area, tube_articulator, incisor_position, tongue_tip_side_elevation, velum_opening )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_Tube_State); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 992, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = NULL;
  __pyx_t_15 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_15 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[7] = {__pyx_t_6, __pyx_v_tube_length, __pyx_v_tube_area, __pyx_v_tube_articulator, __pyx_v_incisor_position, __pyx_v_tongue_tip_side_elevation, __pyx_v_velum_opening};
    __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_15, 6+__pyx_t_15); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[7] = {__pyx_t_6, __pyx_v_tube_length, __pyx_v_tube_area, __pyx_v_tube_articulator, __pyx_v_incisor_position, __pyx_v_tongue_tip_side_elevation, __pyx_v_velum_opening};
    __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_15, 6+__pyx_t_15); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else
  #endif
  {
    __pyx_t_4 = PyTuple_New(6+__pyx_t_15); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 992, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (__pyx_t_6) {
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_6); __pyx_t_6 = NULL;
    }
    __Pyx_INCREF(__pyx_v_tube_length);
    __Pyx_GIVEREF(__pyx_v_tube_length);
    PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_15, __pyx_v_tube_length);
    __Pyx_INCREF(__pyx_v_tube_area);
    __Pyx_GIVEREF(__pyx_v_tube_area);
    PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_15, __pyx_v_tube_area);
    __Pyx_INCREF(__pyx_v_tube_articulator);
    __Pyx_GIVEREF(__pyx_v_tube_articulator);
    PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_15, __pyx_v_tube_articulator);
    __Pyx_INCREF(__pyx_v_incisor_position);
    __Pyx_GIVEREF(__pyx_v_incisor_position);
    PyTuple_SET_ITEM(__pyx_t_4, 3+__pyx_t_15, __pyx_v_incisor_position);
    __Pyx_INCREF(__pyx_v_tongue_tip_side_elevation);
    __Pyx_GIVEREF(__pyx_v_tongue_tip_side_elevation);
    PyTuple_SET_ITEM(__pyx_t_4, 4+__pyx_t_15, __pyx_v_tongue_tip_side_elevation);
    __Pyx_INCREF(__pyx_v_velum_opening);
    __Pyx_GIVEREF(__pyx_v_velum_opening);
    PyTuple_SET_ITEM(__pyx_t_4, 5+__pyx_t_15, __pyx_v_velum_opening);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_4, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_r = __pyx_t_7;
  __pyx_t_7 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":956
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_tube_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args
 * 	tube_length = None
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._tract_state_to_tube_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tractParams.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tubeArea_cm2.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tubeArticulator.rcbuffer->pybuffer);
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_tubeLength_cm.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_tract_state);
  __Pyx_XDECREF(__pyx_v_save_tube_length);
  __Pyx_XDECREF(__pyx_v_save_tube_area);
  __Pyx_XDECREF(__pyx_v_save_tube_articulator);
  __Pyx_XDECREF(__pyx_v_save_incisor_position);
  __Pyx_XDECREF(__pyx_v_save_tongue_tip_side_elevation);
  __Pyx_XDECREF(__pyx_v_save_velum_opening);
  __Pyx_XDECREF(__pyx_v_tube_length);
  __Pyx_XDECREF(__pyx_v_tube_area);
  __Pyx_XDECREF(__pyx_v_tube_articulator);
  __Pyx_XDECREF(__pyx_v_incisor_position);
  __Pyx_XDECREF(__pyx_v_tongue_tip_side_elevation);
  __Pyx_XDECREF(__pyx_v_velum_opening);
  __Pyx_XDECREF(__pyx_v_constants);
  __Pyx_XDECREF((PyObject *)__pyx_v_tractParams);
  __Pyx_XDECREF((PyObject *)__pyx_v_tubeLength_cm);
  __Pyx_XDECREF((PyObject *)__pyx_v_tubeArea_cm2);
  __Pyx_XDECREF((PyObject *)__pyx_v_tubeArticulator);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":1001
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):             # <<<<<<<<<<<<<<
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_75_run_multiprocessing(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_75_run_multiprocessing = {"_run_multiprocessing", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_13VocalTractLab_16VocalTractLabApi_75_run_multiprocessing, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_75_run_multiprocessing(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_function = 0;
  PyObject *__pyx_v_args = 0;
  PyObject *__pyx_v_return_data = 0;
  PyObject *__pyx_v_workers = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_run_multiprocessing (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_function,&__pyx_n_s_args,&__pyx_n_s_return_data,&__pyx_n_s_workers,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_function)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_args)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_run_multiprocessing", 1, 4, 4, 1); __PYX_ERR(0, 1001, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_return_data)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_run_multiprocessing", 1, 4, 4, 2); __PYX_ERR(0, 1001, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_workers)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_run_multiprocessing", 1, 4, 4, 3); __PYX_ERR(0, 1001, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_run_multiprocessing") < 0)) __PYX_ERR(0, 1001, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_function = values[0];
    __pyx_v_args = values[1];
    __pyx_v_return_data = values[2];
    __pyx_v_workers = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_run_multiprocessing", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1001, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._run_multiprocessing", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_74_run_multiprocessing(__pyx_self, __pyx_v_function, __pyx_v_args, __pyx_v_return_data, __pyx_v_workers);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_2generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "VocalTractLab/VocalTractLabApi.pyx":1005
 * 		workers = mp.cpu_count()
 * 	pool = mp.Pool( workers )
 * 	tasks = ( ( function, x ) for x in args)             # <<<<<<<<<<<<<<
 * 	data = None
 * 	if return_data:
 */

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *)__pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr(__pyx_ptype_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1005, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_2generator, NULL, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_run_multiprocessing_locals_gene, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!gen)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._run_multiprocessing.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_2generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *__pyx_cur_scope = ((struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1005, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_args)) { __Pyx_RaiseClosureNameError("args"); __PYX_ERR(0, 1005, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_args)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_args)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_args; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_args); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1005, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1005, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1005, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1005, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1005, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1005, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_x);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_x, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_function)) { __Pyx_RaiseClosureNameError("function"); __PYX_ERR(0, 1005, __pyx_L1_error) }
    __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_function);
    __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_function);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_cur_scope->__pyx_outer_scope->__pyx_v_function);
    __Pyx_INCREF(__pyx_cur_scope->__pyx_v_x);
    __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_x);
    PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_cur_scope->__pyx_v_x);
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    __Pyx_XGIVEREF(__pyx_t_1);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_2;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_3;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_1);
    __pyx_t_2 = __pyx_cur_scope->__pyx_t_1;
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_2;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1005, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  #if !CYTHON_USE_EXC_INFO_STACK
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  #endif
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":1001
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):             # <<<<<<<<<<<<<<
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 */

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_74_run_multiprocessing(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_function, PyObject *__pyx_v_args, PyObject *__pyx_v_return_data, PyObject *__pyx_v_workers) {
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *__pyx_cur_scope;
  PyObject *__pyx_v_pool = NULL;
  PyObject *__pyx_v_tasks = NULL;
  PyObject *__pyx_v_data = NULL;
  PyObject *__pyx_v_x = NULL;
  PyObject *__pyx_gb_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_2generator = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_run_multiprocessing", 0);
  __pyx_cur_scope = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *)__pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing(__pyx_ptype_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1001, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_v_function = __pyx_v_function;
  __Pyx_INCREF(__pyx_cur_scope->__pyx_v_function);
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_function);
  __pyx_cur_scope->__pyx_v_args = __pyx_v_args;
  __Pyx_INCREF(__pyx_cur_scope->__pyx_v_args);
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_args);
  __Pyx_INCREF(__pyx_v_workers);

  /* "VocalTractLab/VocalTractLabApi.pyx":1002
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):
 * 	if workers == None:             # <<<<<<<<<<<<<<
 * 		workers = mp.cpu_count()
 * 	pool = mp.Pool( workers )
 */
  __pyx_t_1 = PyObject_RichCompare(__pyx_v_workers, Py_None, Py_EQ); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1002, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1002, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_2) {

    /* "VocalTractLab/VocalTractLabApi.pyx":1003
 * def _run_multiprocessing( function, args, return_data, workers ):
 * 	if workers == None:
 * 		workers = mp.cpu_count()             # <<<<<<<<<<<<<<
 * 	pool = mp.Pool( workers )
 * 	tasks = ( ( function, x ) for x in args)
 */
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_mp); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1003, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_cpu_count); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1003, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1003, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_workers, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":1002
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):
 * 	if workers == None:             # <<<<<<<<<<<<<<
 * 		workers = mp.cpu_count()
 * 	pool = mp.Pool( workers )
 */
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":1004
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 * 	pool = mp.Pool( workers )             # <<<<<<<<<<<<<<
 * 	tasks = ( ( function, x ) for x in args)
 * 	data = None
 */
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_mp); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1004, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_Pool); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1004, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_4, __pyx_v_workers) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_workers);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1004, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_pool = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1005
 * 		workers = mp.cpu_count()
 * 	pool = mp.Pool( workers )
 * 	tasks = ( ( function, x ) for x in args)             # <<<<<<<<<<<<<<
 * 	data = None
 * 	if return_data:
 */
  __pyx_t_1 = __pyx_pf_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1005, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_tasks = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1006
 * 	pool = mp.Pool( workers )
 * 	tasks = ( ( function, x ) for x in args)
 * 	data = None             # <<<<<<<<<<<<<<
 * 	if return_data:
 * 		data = []
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_data = ((PyObject*)Py_None);

  /* "VocalTractLab/VocalTractLabApi.pyx":1007
 * 	tasks = ( ( function, x ) for x in args)
 * 	data = None
 * 	if return_data:             # <<<<<<<<<<<<<<
 * 		data = []
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_return_data); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1007, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "VocalTractLab/VocalTractLabApi.pyx":1008
 * 	data = None
 * 	if return_data:
 * 		data = []             # <<<<<<<<<<<<<<
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):
 * 			data.append( x )
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_data, ((PyObject*)__pyx_t_1));
    __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":1009
 * 	if return_data:
 * 		data = []
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):             # <<<<<<<<<<<<<<
 * 			data.append( x )
 * 	else:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_tqdm); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_tqdm); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_pool, __pyx_n_s_imap); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_worker); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    __pyx_t_7 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_7 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_5, __pyx_v_tasks};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1009, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_5, __pyx_v_tasks};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1009, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1009, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_5);
      __Pyx_INCREF(__pyx_v_tasks);
      __Pyx_GIVEREF(__pyx_v_tasks);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_v_tasks);
      __pyx_t_5 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_8, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1009, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __pyx_cur_scope->__pyx_v_args;
    __Pyx_INCREF(__pyx_t_8);
    __pyx_t_9 = PyObject_Length(__pyx_t_8); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyInt_FromSsize_t(__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_total, __pyx_t_8) < 0) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1009, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (likely(PyList_CheckExact(__pyx_t_8)) || PyTuple_CheckExact(__pyx_t_8)) {
      __pyx_t_1 = __pyx_t_8; __Pyx_INCREF(__pyx_t_1); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1009, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_10 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1009, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1009, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_1, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1009, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_9); __Pyx_INCREF(__pyx_t_8); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1009, __pyx_L1_error)
          #else
          __pyx_t_8 = PySequence_ITEM(__pyx_t_1, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1009, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          #endif
        }
      } else {
        __pyx_t_8 = __pyx_t_10(__pyx_t_1);
        if (unlikely(!__pyx_t_8)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1009, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_8);
      }
      __Pyx_XDECREF_SET(__pyx_v_x, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "VocalTractLab/VocalTractLabApi.pyx":1010
 * 		data = []
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):
 * 			data.append( x )             # <<<<<<<<<<<<<<
 * 	else:
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):
 */
      __pyx_t_11 = __Pyx_PyList_Append(__pyx_v_data, __pyx_v_x); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(0, 1010, __pyx_L1_error)

      /* "VocalTractLab/VocalTractLabApi.pyx":1009
 * 	if return_data:
 * 		data = []
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):             # <<<<<<<<<<<<<<
 * 			data.append( x )
 * 	else:
 */
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "VocalTractLab/VocalTractLabApi.pyx":1007
 * 	tasks = ( ( function, x ) for x in args)
 * 	data = None
 * 	if return_data:             # <<<<<<<<<<<<<<
 * 		data = []
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):
 */
    goto __pyx_L4;
  }

  /* "VocalTractLab/VocalTractLabApi.pyx":1012
 * 			data.append( x )
 * 	else:
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):             # <<<<<<<<<<<<<<
 * 			pass
 * 	pool.close()
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_tqdm); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_tqdm); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_pool, __pyx_n_s_imap); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_worker); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = NULL;
    __pyx_t_7 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_7 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_3, __pyx_v_tasks};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1012, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_3, __pyx_v_tasks};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1012, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    {
      __pyx_t_6 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1012, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      if (__pyx_t_5) {
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_7, __pyx_t_3);
      __Pyx_INCREF(__pyx_v_tasks);
      __Pyx_GIVEREF(__pyx_v_tasks);
      PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_7, __pyx_v_tasks);
      __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1012, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = __pyx_cur_scope->__pyx_v_args;
    __Pyx_INCREF(__pyx_t_6);
    __pyx_t_9 = PyObject_Length(__pyx_t_6); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyInt_FromSsize_t(__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_total, __pyx_t_6) < 0) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_4, __pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1012, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
      __pyx_t_1 = __pyx_t_6; __Pyx_INCREF(__pyx_t_1); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1012, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_10 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1012, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1012, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_1, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1012, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_9); __Pyx_INCREF(__pyx_t_6); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 1012, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_1, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1012, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_10(__pyx_t_1);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 1012, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_x, __pyx_t_6);
      __pyx_t_6 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L4:;

  /* "VocalTractLab/VocalTractLabApi.pyx":1014
 * 		for x in tqdm.tqdm( pool.imap( _worker, tasks ), total=len( args ) ):
 * 			pass
 * 	pool.close()             # <<<<<<<<<<<<<<
 * 	pool.join()
 * 	return data
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_pool, __pyx_n_s_close_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1014, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1014, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1015
 * 			pass
 * 	pool.close()
 * 	pool.join()             # <<<<<<<<<<<<<<
 * 	return data
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_pool, __pyx_n_s_join); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1015, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1015, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1016
 * 	pool.close()
 * 	pool.join()
 * 	return data             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _worker( args ):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_data);
  __pyx_r = __pyx_v_data;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1001
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):             # <<<<<<<<<<<<<<
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._run_multiprocessing", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_pool);
  __Pyx_XDECREF(__pyx_v_tasks);
  __Pyx_XDECREF(__pyx_v_data);
  __Pyx_XDECREF(__pyx_v_x);
  __Pyx_XDECREF(__pyx_gb_13VocalTractLab_16VocalTractLabApi_20_run_multiprocessing_2generator);
  __Pyx_XDECREF(__pyx_v_workers);
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "VocalTractLab/VocalTractLabApi.pyx":1018
 * 	return data
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _worker( args ):             # <<<<<<<<<<<<<<
 * 	function, arg = args
 * 	return function( arg )
 */

/* Python wrapper */
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_77_worker(PyObject *__pyx_self, PyObject *__pyx_v_args); /*proto*/
static PyMethodDef __pyx_mdef_13VocalTractLab_16VocalTractLabApi_77_worker = {"_worker", (PyCFunction)__pyx_pw_13VocalTractLab_16VocalTractLabApi_77_worker, METH_O, 0};
static PyObject *__pyx_pw_13VocalTractLab_16VocalTractLabApi_77_worker(PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_worker (wrapper)", 0);
  __pyx_r = __pyx_pf_13VocalTractLab_16VocalTractLabApi_76_worker(__pyx_self, ((PyObject *)__pyx_v_args));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_13VocalTractLab_16VocalTractLabApi_76_worker(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_function = NULL;
  PyObject *__pyx_v_arg = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_worker", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":1019
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _worker( args ):
 * 	function, arg = args             # <<<<<<<<<<<<<<
 * 	return function( arg )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 1019, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_2);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1019, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1019, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_3 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1019, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = Py_TYPE(__pyx_t_3)->tp_iternext;
    index = 0; __pyx_t_1 = __pyx_t_4(__pyx_t_3); if (unlikely(!__pyx_t_1)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_1);
    index = 1; __pyx_t_2 = __pyx_t_4(__pyx_t_3); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_4(__pyx_t_3), 2) < 0) __PYX_ERR(0, 1019, __pyx_L1_error)
    __pyx_t_4 = NULL;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 1019, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_function = __pyx_t_1;
  __pyx_t_1 = 0;
  __pyx_v_arg = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1020
 * def _worker( args ):
 * 	function, arg = args
 * 	return function( arg )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * #####################################################################################################################################################
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_function);
  __pyx_t_1 = __pyx_v_function; __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  __pyx_t_2 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_3, __pyx_v_arg) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_arg);
  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1020, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1018
 * 	return data
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _worker( args ):             # <<<<<<<<<<<<<<
 * 	function, arg = args
 * 	return function( arg )
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("VocalTractLab.VocalTractLabApi._worker", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_function);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":735
 * ctypedef npy_cdouble     complex_t
 * 
 * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew1(PyObject *__pyx_v_a) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew1", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":736
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 *     return PyArray_MultiIterNew(1, <void*>a)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(1, ((void *)__pyx_v_a)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 736, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":735
 * ctypedef npy_cdouble     complex_t
 * 
 * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew1", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":738
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew2(PyObject *__pyx_v_a, PyObject *__pyx_v_b) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew2", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":739
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(2, ((void *)__pyx_v_a), ((void *)__pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":738
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew2", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":741
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew3(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew3", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":742
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(3, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 742, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":741
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew3", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":744
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew4(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew4", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":745
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(4, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 745, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":744
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew4", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":747
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew5(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d, PyObject *__pyx_v_e) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew5", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":748
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)             # <<<<<<<<<<<<<<
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(5, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d), ((void *)__pyx_v_e)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 748, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":747
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew5", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":750
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyDataType_SHAPE(PyArray_Descr *__pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("PyDataType_SHAPE", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":751
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
 *         return <tuple>d.subarray.shape
 *     else:
 */
  __pyx_t_1 = (PyDataType_HASSUBARRAY(__pyx_v_d) != 0);
  if (__pyx_t_1) {

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":752
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape             # <<<<<<<<<<<<<<
 *     else:
 *         return ()
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));
    __pyx_r = ((PyObject*)__pyx_v_d->subarray->shape);
    goto __pyx_L0;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":751
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
 *         return <tuple>d.subarray.shape
 *     else:
 */
  }

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":754
 *         return <tuple>d.subarray.shape
 *     else:
 *         return ()             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_empty_tuple);
    __pyx_r = __pyx_empty_tuple;
    goto __pyx_L0;
  }

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":750
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":929
 *     int _import_umath() except -1
 * 
 * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
 *     Py_INCREF(base) # important to do this before stealing the reference below!
 *     PyArray_SetBaseObject(arr, base)
 */

static CYTHON_INLINE void __pyx_f_5numpy_set_array_base(PyArrayObject *__pyx_v_arr, PyObject *__pyx_v_base) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set_array_base", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":930
 * 
 * cdef inline void set_array_base(ndarray arr, object base):
 *     Py_INCREF(base) # important to do this before stealing the reference below!             # <<<<<<<<<<<<<<
 *     PyArray_SetBaseObject(arr, base)
 * 
 */
  Py_INCREF(__pyx_v_base);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":931
 * cdef inline void set_array_base(ndarray arr, object base):
 *     Py_INCREF(base) # important to do this before stealing the reference below!
 *     PyArray_SetBaseObject(arr, base)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object get_array_base(ndarray arr):
 */
  (void)(PyArray_SetBaseObject(__pyx_v_arr, __pyx_v_base));

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":929
 *     int _import_umath() except -1
 * 
 * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
 *     Py_INCREF(base) # important to do this before stealing the reference below!
 *     PyArray_SetBaseObject(arr, base)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":933
 *     PyArray_SetBaseObject(arr, base)
 * 
 * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
 *     base = PyArray_BASE(arr)
 *     if base is NULL:
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_get_array_base(PyArrayObject *__pyx_v_arr) {
  PyObject *__pyx_v_base;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("get_array_base", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":934
 * 
 * cdef inline object get_array_base(ndarray arr):
 *     base = PyArray_BASE(arr)             # <<<<<<<<<<<<<<
 *     if base is NULL:
 *         return None
 */
  __pyx_v_base = PyArray_BASE(__pyx_v_arr);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":935
 * cdef inline object get_array_base(ndarray arr):
 *     base = PyArray_BASE(arr)
 *     if base is NULL:             # <<<<<<<<<<<<<<
 *         return None
 *     return <object>base
 */
  __pyx_t_1 = ((__pyx_v_base == NULL) != 0);
  if (__pyx_t_1) {

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":936
 *     base = PyArray_BASE(arr)
 *     if base is NULL:
 *         return None             # <<<<<<<<<<<<<<
 *     return <object>base
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":935
 * cdef inline object get_array_base(ndarray arr):
 *     base = PyArray_BASE(arr)
 *     if base is NULL:             # <<<<<<<<<<<<<<
 *         return None
 *     return <object>base
 */
  }

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":937
 *     if base is NULL:
 *         return None
 *     return <object>base             # <<<<<<<<<<<<<<
 * 
 * # Versions of the import_* functions which are more suitable for
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_base));
  __pyx_r = ((PyObject *)__pyx_v_base);
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":933
 *     PyArray_SetBaseObject(arr, base)
 * 
 * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
 *     base = PyArray_BASE(arr)
 *     if base is NULL:
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":941
 * # Versions of the import_* functions which are more suitable for
 * # Cython code.
 * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         __pyx_import_array()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_array(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("import_array", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":942
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         __pyx_import_array()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":943
 * cdef inline int import_array() except -1:
 *     try:
 *         __pyx_import_array()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")
 */
      __pyx_t_4 = _import_array(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 943, __pyx_L3_error)

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":942
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         __pyx_import_array()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":944
 *     try:
 *         __pyx_import_array()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 944, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":945
 *         __pyx_import_array()
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_umath() except -1:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__14, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 945, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(1, 945, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":942
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         __pyx_import_array()
 *     except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":941
 * # Versions of the import_* functions which are more suitable for
 * # Cython code.
 * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         __pyx_import_array()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":947
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_umath(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("import_umath", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":948
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":949
 * cdef inline int import_umath() except -1:
 *     try:
 *         _import_umath()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")
 */
      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 949, __pyx_L3_error)

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":948
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":950
 *     try:
 *         _import_umath()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 950, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":951
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_ufunc() except -1:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 951, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(1, 951, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":948
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":947
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":953
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_ufunc(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("import_ufunc", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":954
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":955
 * cdef inline int import_ufunc() except -1:
 *     try:
 *         _import_umath()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")
 */
      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 955, __pyx_L3_error)

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":954
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":956
 *     try:
 *         _import_umath()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 956, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":957
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef extern from *:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 957, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(1, 957, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":954
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":953
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":967
 * 
 * 
 * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.timedelta64)`
 */

static CYTHON_INLINE int __pyx_f_5numpy_is_timedelta64_object(PyObject *__pyx_v_obj) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("is_timedelta64_object", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":979
 *     bool
 *     """
 *     return PyObject_TypeCheck(obj, &PyTimedeltaArrType_Type)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyTimedeltaArrType_Type));
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":967
 * 
 * 
 * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.timedelta64)`
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":982
 * 
 * 
 * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.datetime64)`
 */

static CYTHON_INLINE int __pyx_f_5numpy_is_datetime64_object(PyObject *__pyx_v_obj) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("is_datetime64_object", 0);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":994
 *     bool
 *     """
 *     return PyObject_TypeCheck(obj, &PyDatetimeArrType_Type)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyDatetimeArrType_Type));
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":982
 * 
 * 
 * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.datetime64)`
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":997
 * 
 * 
 * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy datetime64 object
 */

static CYTHON_INLINE npy_datetime __pyx_f_5numpy_get_datetime64_value(PyObject *__pyx_v_obj) {
  npy_datetime __pyx_r;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1004
 *     also needed.  That can be found using `get_datetime64_unit`.
 *     """
 *     return (<PyDatetimeScalarObject*>obj).obval             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = ((PyDatetimeScalarObject *)__pyx_v_obj)->obval;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":997
 * 
 * 
 * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy datetime64 object
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1007
 * 
 * 
 * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy timedelta64 object
 */

static CYTHON_INLINE npy_timedelta __pyx_f_5numpy_get_timedelta64_value(PyObject *__pyx_v_obj) {
  npy_timedelta __pyx_r;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1011
 *     returns the int64 value underlying scalar numpy timedelta64 object
 *     """
 *     return (<PyTimedeltaScalarObject*>obj).obval             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = ((PyTimedeltaScalarObject *)__pyx_v_obj)->obval;
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1007
 * 
 * 
 * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy timedelta64 object
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1014
 * 
 * 
 * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the unit part of the dtype for a numpy datetime64 object.
 */

static CYTHON_INLINE NPY_DATETIMEUNIT __pyx_f_5numpy_get_datetime64_unit(PyObject *__pyx_v_obj) {
  NPY_DATETIMEUNIT __pyx_r;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1018
 *     returns the unit part of the dtype for a numpy datetime64 object.
 *     """
 *     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base             # <<<<<<<<<<<<<<
 */
  __pyx_r = ((NPY_DATETIMEUNIT)((PyDatetimeScalarObject *)__pyx_v_obj)->obmeta.base);
  goto __pyx_L0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1014
 * 
 * 
 * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the unit part of the dtype for a numpy datetime64 object.
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

static struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *__pyx_freelist_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing[8];
static int __pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing = 0;

static PyObject *__pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing)))) {
    o = (PyObject*)__pyx_freelist_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing[--__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing];
    memset(o, 0, sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing(PyObject *o) {
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *p = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_args);
  Py_CLEAR(p->__pyx_v_function);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing)))) {
    __pyx_freelist_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing[__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing++] = ((struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *p = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *)o;
  if (p->__pyx_v_args) {
    e = (*v)(p->__pyx_v_args, a); if (e) return e;
  }
  if (p->__pyx_v_function) {
    e = (*v)(p->__pyx_v_function, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *p = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing *)o;
  tmp = ((PyObject*)p->__pyx_v_args);
  p->__pyx_v_args = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->__pyx_v_function);
  p->__pyx_v_function = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyTypeObject __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing = {
  PyVarObject_HEAD_INIT(0, 0)
  "VocalTractLab.VocalTractLabApi.__pyx_scope_struct___run_multiprocessing", /*tp_name*/
  sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing, /*tp_traverse*/
  __pyx_tp_clear_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *__pyx_freelist_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr[8];
static int __pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr = 0;

static PyObject *__pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr)))) {
    o = (PyObject*)__pyx_freelist_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr[--__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr(PyObject *o) {
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *p = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_x);
  Py_CLEAR(p->__pyx_t_0);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr)))) {
    __pyx_freelist_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr[__pyx_freecount_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr++] = ((struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *p = (struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_x) {
    e = (*v)(p->__pyx_v_x, a); if (e) return e;
  }
  if (p->__pyx_t_0) {
    e = (*v)(p->__pyx_t_0, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "VocalTractLab.VocalTractLabApi.__pyx_scope_struct_1_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec_VocalTractLabApi(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec_VocalTractLabApi},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "VocalTractLabApi",
    0, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif
#ifndef CYTHON_SMALL_CODE
#if defined(__clang__)
    #define CYTHON_SMALL_CODE
#elif defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
    #define CYTHON_SMALL_CODE __attribute__((cold))
#else
    #define CYTHON_SMALL_CODE
#endif
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_n_s_AT, __pyx_k_AT, sizeof(__pyx_k_AT), 0, 0, 1, 1},
  {&__pyx_kp_s_Audio_generated_from_gestural_sc, __pyx_k_Audio_generated_from_gestural_sc, sizeof(__pyx_k_Audio_generated_from_gestural_sc), 0, 0, 1, 0},
  {&__pyx_kp_s_Audio_generated_from_motor_seque, __pyx_k_Audio_generated_from_motor_seque, sizeof(__pyx_k_Audio_generated_from_motor_seque), 0, 0, 1, 0},
  {&__pyx_kp_s_Automatic_calculation_of_the_Ton, __pyx_k_Automatic_calculation_of_the_Ton, sizeof(__pyx_k_Automatic_calculation_of_the_Ton), 0, 0, 1, 0},
  {&__pyx_n_s_BeautifulSoup, __pyx_k_BeautifulSoup, sizeof(__pyx_k_BeautifulSoup), 0, 0, 1, 1},
  {&__pyx_kp_s_Compile_date_of_the_library, __pyx_k_Compile_date_of_the_library, sizeof(__pyx_k_Compile_date_of_the_library), 0, 0, 1, 0},
  {&__pyx_kp_s_Created_gestural_score_from_segm, __pyx_k_Created_gestural_score_from_segm, sizeof(__pyx_k_Created_gestural_score_from_segm), 0, 0, 1, 0},
  {&__pyx_kp_s_Created_tractsequence_file_from, __pyx_k_Created_tractsequence_file_from, sizeof(__pyx_k_Created_tractsequence_file_from), 0, 0, 1, 0},
  {&__pyx_n_s_DataFrame, __pyx_k_DataFrame, sizeof(__pyx_k_DataFrame), 0, 0, 1, 1},
  {&__pyx_kp_s_Error_at_element_element_value_v, __pyx_k_Error_at_element_element_value_v, sizeof(__pyx_k_Error_at_element_element_value_v), 0, 0, 1, 0},
  {&__pyx_n_s_FT, __pyx_k_FT, sizeof(__pyx_k_FT), 0, 0, 1, 1},
  {&__pyx_n_s_ImportError, __pyx_k_ImportError, sizeof(__pyx_k_ImportError), 0, 0, 1, 1},
  {&__pyx_kp_s_Loaded_new_speakerfile_Overwriti, __pyx_k_Loaded_new_speakerfile_Overwriti, sizeof(__pyx_k_Loaded_new_speakerfile_Overwriti), 0, 0, 1, 0},
  {&__pyx_n_s_Motor_Score, __pyx_k_Motor_Score, sizeof(__pyx_k_Motor_Score), 0, 0, 1, 1},
  {&__pyx_n_s_Motor_Sequence, __pyx_k_Motor_Sequence, sizeof(__pyx_k_Motor_Sequence), 0, 0, 1, 1},
  {&__pyx_n_s_Pool, __pyx_k_Pool, sizeof(__pyx_k_Pool), 0, 0, 1, 1},
  {&__pyx_n_s_S, __pyx_k_S, sizeof(__pyx_k_S), 0, 0, 1, 1},
  {&__pyx_kp_s_Specified_shape_was_not_found_in, __pyx_k_Specified_shape_was_not_found_in, sizeof(__pyx_k_Specified_shape_was_not_found_in), 0, 0, 1, 0},
  {&__pyx_n_s_Sub_Glottal_Sequence, __pyx_k_Sub_Glottal_Sequence, sizeof(__pyx_k_Sub_Glottal_Sequence), 0, 0, 1, 1},
  {&__pyx_n_s_Supra_Glottal_Sequence, __pyx_k_Supra_Glottal_Sequence, sizeof(__pyx_k_Supra_Glottal_Sequence), 0, 0, 1, 1},
  {&__pyx_n_s_T, __pyx_k_T, sizeof(__pyx_k_T), 0, 0, 1, 1},
  {&__pyx_n_s_Transfer_Function, __pyx_k_Transfer_Function, sizeof(__pyx_k_Transfer_Function), 0, 0, 1, 1},
  {&__pyx_n_s_Tube_State, __pyx_k_Tube_State, sizeof(__pyx_k_Tube_State), 0, 0, 1, 1},
  {&__pyx_kp_s_Unknown_key_in_get_param_info_Ke, __pyx_k_Unknown_key_in_get_param_info_Ke, sizeof(__pyx_k_Unknown_key_in_get_param_info_Ke), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlCalcTongueRo, __pyx_k_VTL_API_function_vtlCalcTongueRo, sizeof(__pyx_k_VTL_API_function_vtlCalcTongueRo), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlClose_return, __pyx_k_VTL_API_function_vtlClose_return, sizeof(__pyx_k_VTL_API_function_vtlClose_return), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlGesturalScor, __pyx_k_VTL_API_function_vtlGesturalScor, sizeof(__pyx_k_VTL_API_function_vtlGesturalScor), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlGesturalScor_2, __pyx_k_VTL_API_function_vtlGesturalScor_2, sizeof(__pyx_k_VTL_API_function_vtlGesturalScor_2), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlGetConstants, __pyx_k_VTL_API_function_vtlGetConstants, sizeof(__pyx_k_VTL_API_function_vtlGetConstants), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlGetTractPara, __pyx_k_VTL_API_function_vtlGetTractPara, sizeof(__pyx_k_VTL_API_function_vtlGetTractPara), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlGetTractPara_2, __pyx_k_VTL_API_function_vtlGetTractPara_2, sizeof(__pyx_k_VTL_API_function_vtlGetTractPara_2), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlInitialize_r, __pyx_k_VTL_API_function_vtlInitialize_r, sizeof(__pyx_k_VTL_API_function_vtlInitialize_r), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlSegmentSeque, __pyx_k_VTL_API_function_vtlSegmentSeque, sizeof(__pyx_k_VTL_API_function_vtlSegmentSeque), 0, 0, 1, 0},
  {&__pyx_kp_s_VTL_API_function_vtlSynthBlock_r, __pyx_k_VTL_API_function_vtlSynthBlock_r, sizeof(__pyx_k_VTL_API_function_vtlSynthBlock_r), 0, 0, 1, 0},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_n_s_VocalTractLab_VocalTractLabApi, __pyx_k_VocalTractLab_VocalTractLabApi, sizeof(__pyx_k_VocalTractLab_VocalTractLabApi), 0, 0, 1, 1},
  {&__pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_k_VocalTractLab_VocalTractLabApi_p, sizeof(__pyx_k_VocalTractLab_VocalTractLabApi_p), 0, 0, 1, 0},
  {&__pyx_n_s_VocalTractLab_audio_tools, __pyx_k_VocalTractLab_audio_tools, sizeof(__pyx_k_VocalTractLab_audio_tools), 0, 0, 1, 1},
  {&__pyx_n_s_VocalTractLab_frequency_domain, __pyx_k_VocalTractLab_frequency_domain, sizeof(__pyx_k_VocalTractLab_frequency_domain), 0, 0, 1, 1},
  {&__pyx_n_s_VocalTractLab_function_tools, __pyx_k_VocalTractLab_function_tools, sizeof(__pyx_k_VocalTractLab_function_tools), 0, 0, 1, 1},
  {&__pyx_n_s_VocalTractLab_targets, __pyx_k_VocalTractLab_targets, sizeof(__pyx_k_VocalTractLab_targets), 0, 0, 1, 1},
  {&__pyx_n_s_VocalTractLab_tract_sequence, __pyx_k_VocalTractLab_tract_sequence, sizeof(__pyx_k_VocalTractLab_tract_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_VocalTractLab_tube_states, __pyx_k_VocalTractLab_tube_states, sizeof(__pyx_k_VocalTractLab_tube_states), 0, 0, 1, 1},
  {&__pyx_n_s_WARNING, __pyx_k_WARNING, sizeof(__pyx_k_WARNING), 0, 0, 1, 1},
  {&__pyx_kp_s__13, __pyx_k__13, sizeof(__pyx_k__13), 0, 0, 1, 0},
  {&__pyx_n_s__16, __pyx_k__16, sizeof(__pyx_k__16), 0, 0, 1, 1},
  {&__pyx_kp_s__2, __pyx_k__2, sizeof(__pyx_k__2), 0, 0, 1, 0},
  {&__pyx_kp_s__3, __pyx_k__3, sizeof(__pyx_k__3), 0, 0, 1, 0},
  {&__pyx_kp_s__4, __pyx_k__4, sizeof(__pyx_k__4), 0, 0, 1, 0},
  {&__pyx_kp_s__5, __pyx_k__5, sizeof(__pyx_k__5), 0, 0, 1, 0},
  {&__pyx_kp_s__7, __pyx_k__7, sizeof(__pyx_k__7), 0, 0, 1, 0},
  {&__pyx_kp_s__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 0, 1, 0},
  {&__pyx_kp_s__9, __pyx_k__9, sizeof(__pyx_k__9), 0, 0, 1, 0},
  {&__pyx_n_s_abs, __pyx_k_abs, sizeof(__pyx_k_abs), 0, 0, 1, 1},
  {&__pyx_n_s_arg, __pyx_k_arg, sizeof(__pyx_k_arg), 0, 0, 1, 1},
  {&__pyx_n_s_args, __pyx_k_args, sizeof(__pyx_k_args), 0, 0, 1, 1},
  {&__pyx_n_s_array, __pyx_k_array, sizeof(__pyx_k_array), 0, 0, 1, 1},
  {&__pyx_n_s_atexit, __pyx_k_atexit, sizeof(__pyx_k_atexit), 0, 0, 1, 1},
  {&__pyx_n_s_audio, __pyx_k_audio, sizeof(__pyx_k_audio), 0, 0, 1, 1},
  {&__pyx_n_s_audioSamplingRate, __pyx_k_audioSamplingRate, sizeof(__pyx_k_audioSamplingRate), 0, 0, 1, 1},
  {&__pyx_n_s_audio_args, __pyx_k_audio_args, sizeof(__pyx_k_audio_args), 0, 0, 1, 1},
  {&__pyx_n_s_audio_data_list, __pyx_k_audio_data_list, sizeof(__pyx_k_audio_data_list), 0, 0, 1, 1},
  {&__pyx_n_s_audio_file_path, __pyx_k_audio_file_path, sizeof(__pyx_k_audio_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_audio_file_path_list, __pyx_k_audio_file_path_list, sizeof(__pyx_k_audio_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_automaticCalculation, __pyx_k_automaticCalculation, sizeof(__pyx_k_automaticCalculation), 0, 0, 1, 1},
  {&__pyx_n_s_automatic_calculation, __pyx_k_automatic_calculation, sizeof(__pyx_k_automatic_calculation), 0, 0, 1, 1},
  {&__pyx_n_s_automatic_calculation_of_TRX_and, __pyx_k_automatic_calculation_of_TRX_and, sizeof(__pyx_k_automatic_calculation_of_TRX_and), 0, 0, 1, 1},
  {&__pyx_n_s_basicConfig, __pyx_k_basicConfig, sizeof(__pyx_k_basicConfig), 0, 0, 1, 1},
  {&__pyx_n_s_bs4, __pyx_k_bs4, sizeof(__pyx_k_bs4), 0, 0, 1, 1},
  {&__pyx_n_s_change_gestural_score, __pyx_k_change_gestural_score, sizeof(__pyx_k_change_gestural_score), 0, 0, 1, 1},
  {&__pyx_n_s_check_if_input_lists_are_valid, __pyx_k_check_if_input_lists_are_valid, sizeof(__pyx_k_check_if_input_lists_are_valid), 0, 0, 1, 1},
  {&__pyx_n_s_check_if_list_is_valid, __pyx_k_check_if_list_is_valid, sizeof(__pyx_k_check_if_list_is_valid), 0, 0, 1, 1},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_close, __pyx_k_close, sizeof(__pyx_k_close), 0, 0, 1, 1},
  {&__pyx_n_s_close_2, __pyx_k_close_2, sizeof(__pyx_k_close_2), 0, 0, 1, 1},
  {&__pyx_n_s_columns, __pyx_k_columns, sizeof(__pyx_k_columns), 0, 0, 1, 1},
  {&__pyx_n_s_constants, __pyx_k_constants, sizeof(__pyx_k_constants), 0, 0, 1, 1},
  {&__pyx_n_s_copy, __pyx_k_copy, sizeof(__pyx_k_copy), 0, 0, 1, 1},
  {&__pyx_n_s_cpu_count, __pyx_k_cpu_count, sizeof(__pyx_k_cpu_count), 0, 0, 1, 1},
  {&__pyx_n_s_ctypes, __pyx_k_ctypes, sizeof(__pyx_k_ctypes), 0, 0, 1, 1},
  {&__pyx_n_s_data, __pyx_k_data, sizeof(__pyx_k_data), 0, 0, 1, 1},
  {&__pyx_n_s_decode, __pyx_k_decode, sizeof(__pyx_k_decode), 0, 0, 1, 1},
  {&__pyx_n_s_description, __pyx_k_description, sizeof(__pyx_k_description), 0, 0, 1, 1},
  {&__pyx_n_s_descriptions, __pyx_k_descriptions, sizeof(__pyx_k_descriptions), 0, 0, 1, 1},
  {&__pyx_n_s_df, __pyx_k_df, sizeof(__pyx_k_df), 0, 0, 1, 1},
  {&__pyx_n_s_dirname, __pyx_k_dirname, sizeof(__pyx_k_dirname), 0, 0, 1, 1},
  {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_element, __pyx_k_element, sizeof(__pyx_k_element), 0, 0, 1, 1},
  {&__pyx_n_s_empty, __pyx_k_empty, sizeof(__pyx_k_empty), 0, 0, 1, 1},
  {&__pyx_n_s_enableConsoleOutput, __pyx_k_enableConsoleOutput, sizeof(__pyx_k_enableConsoleOutput), 0, 0, 1, 1},
  {&__pyx_n_s_encode, __pyx_k_encode, sizeof(__pyx_k_encode), 0, 0, 1, 1},
  {&__pyx_n_s_enumerate, __pyx_k_enumerate, sizeof(__pyx_k_enumerate), 0, 0, 1, 1},
  {&__pyx_n_s_exists, __pyx_k_exists, sizeof(__pyx_k_exists), 0, 0, 1, 1},
  {&__pyx_n_s_f, __pyx_k_f, sizeof(__pyx_k_f), 0, 0, 1, 1},
  {&__pyx_n_s_feature, __pyx_k_feature, sizeof(__pyx_k_feature), 0, 0, 1, 1},
  {&__pyx_n_s_file, __pyx_k_file, sizeof(__pyx_k_file), 0, 0, 1, 1},
  {&__pyx_n_s_fileName, __pyx_k_fileName, sizeof(__pyx_k_fileName), 0, 0, 1, 1},
  {&__pyx_n_s_find, __pyx_k_find, sizeof(__pyx_k_find), 0, 0, 1, 1},
  {&__pyx_n_s_float64, __pyx_k_float64, sizeof(__pyx_k_float64), 0, 0, 1, 1},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_formatter, __pyx_k_formatter, sizeof(__pyx_k_formatter), 0, 0, 1, 1},
  {&__pyx_n_s_fps, __pyx_k_fps, sizeof(__pyx_k_fps), 0, 0, 1, 1},
  {&__pyx_n_s_frameStep_samples, __pyx_k_frameStep_samples, sizeof(__pyx_k_frameStep_samples), 0, 0, 1, 1},
  {&__pyx_n_s_from_tract_file, __pyx_k_from_tract_file, sizeof(__pyx_k_from_tract_file), 0, 0, 1, 1},
  {&__pyx_n_s_function, __pyx_k_function, sizeof(__pyx_k_function), 0, 0, 1, 1},
  {&__pyx_n_s_genexpr, __pyx_k_genexpr, sizeof(__pyx_k_genexpr), 0, 0, 1, 1},
  {&__pyx_kp_s_ges, __pyx_k_ges, sizeof(__pyx_k_ges), 0, 0, 1, 0},
  {&__pyx_n_s_gesFileName, __pyx_k_gesFileName, sizeof(__pyx_k_gesFileName), 0, 0, 1, 1},
  {&__pyx_n_s_ges_file, __pyx_k_ges_file, sizeof(__pyx_k_ges_file), 0, 0, 1, 1},
  {&__pyx_n_s_ges_file_path, __pyx_k_ges_file_path, sizeof(__pyx_k_ges_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_ges_file_path_list, __pyx_k_ges_file_path_list, sizeof(__pyx_k_ges_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_ges_soup, __pyx_k_ges_soup, sizeof(__pyx_k_ges_soup), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score, __pyx_k_gestural_score, sizeof(__pyx_k_gestural_score), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_change_duration, __pyx_k_gestural_score_change_duration, sizeof(__pyx_k_gestural_score_change_duration), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_change_voice_qua, __pyx_k_gestural_score_change_voice_qua, sizeof(__pyx_k_gestural_score_change_voice_qua), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_soup, __pyx_k_gestural_score_soup, sizeof(__pyx_k_gestural_score_soup), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_to_audio, __pyx_k_gestural_score_to_audio, sizeof(__pyx_k_gestural_score_to_audio), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_to_audio_2, __pyx_k_gestural_score_to_audio_2, sizeof(__pyx_k_gestural_score_to_audio_2), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_to_tract_sequenc, __pyx_k_gestural_score_to_tract_sequenc, sizeof(__pyx_k_gestural_score_to_tract_sequenc), 0, 0, 1, 1},
  {&__pyx_n_s_gestural_score_to_tract_sequence, __pyx_k_gestural_score_to_tract_sequence, sizeof(__pyx_k_gestural_score_to_tract_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_gesture_sequence, __pyx_k_gesture_sequence, sizeof(__pyx_k_gesture_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_getLogger, __pyx_k_getLogger, sizeof(__pyx_k_getLogger), 0, 0, 1, 1},
  {&__pyx_n_s_get_constants, __pyx_k_get_constants, sizeof(__pyx_k_get_constants), 0, 0, 1, 1},
  {&__pyx_n_s_get_gestural_score_audio_duratio, __pyx_k_get_gestural_score_audio_duratio, sizeof(__pyx_k_get_gestural_score_audio_duratio), 0, 0, 1, 1},
  {&__pyx_n_s_get_param_info, __pyx_k_get_param_info, sizeof(__pyx_k_get_param_info), 0, 0, 1, 1},
  {&__pyx_n_s_get_shape, __pyx_k_get_shape, sizeof(__pyx_k_get_shape), 0, 0, 1, 1},
  {&__pyx_n_s_get_shapes, __pyx_k_get_shapes, sizeof(__pyx_k_get_shapes), 0, 0, 1, 1},
  {&__pyx_n_s_get_sub_glottal_state, __pyx_k_get_sub_glottal_state, sizeof(__pyx_k_get_sub_glottal_state), 0, 0, 1, 1},
  {&__pyx_n_s_get_supra_glottal_state, __pyx_k_get_supra_glottal_state, sizeof(__pyx_k_get_supra_glottal_state), 0, 0, 1, 1},
  {&__pyx_n_s_get_version, __pyx_k_get_version, sizeof(__pyx_k_get_version), 0, 0, 1, 1},
  {&__pyx_kp_s_glottal_shape_gestures, __pyx_k_glottal_shape_gestures, sizeof(__pyx_k_glottal_shape_gestures), 0, 0, 1, 0},
  {&__pyx_n_s_glottis, __pyx_k_glottis, sizeof(__pyx_k_glottis), 0, 0, 1, 1},
  {&__pyx_n_s_glottisParams, __pyx_k_glottisParams, sizeof(__pyx_k_glottisParams), 0, 0, 1, 1},
  {&__pyx_n_s_glottis_states, __pyx_k_glottis_states, sizeof(__pyx_k_glottis_states), 0, 0, 1, 1},
  {&__pyx_kp_s_html_parser, __pyx_k_html_parser, sizeof(__pyx_k_html_parser), 0, 0, 1, 0},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_imap, __pyx_k_imap, sizeof(__pyx_k_imap), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_inTractParams, __pyx_k_inTractParams, sizeof(__pyx_k_inTractParams), 0, 0, 1, 1},
  {&__pyx_n_s_in_ges_file_path, __pyx_k_in_ges_file_path, sizeof(__pyx_k_in_ges_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_in_ges_file_path_list, __pyx_k_in_ges_file_path_list, sizeof(__pyx_k_in_ges_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_incisorPos_cm, __pyx_k_incisorPos_cm, sizeof(__pyx_k_incisorPos_cm), 0, 0, 1, 1},
  {&__pyx_n_s_incisor_position, __pyx_k_incisor_position, sizeof(__pyx_k_incisor_position), 0, 0, 1, 1},
  {&__pyx_n_s_index, __pyx_k_index, sizeof(__pyx_k_index), 0, 0, 1, 1},
  {&__pyx_n_s_info, __pyx_k_info, sizeof(__pyx_k_info), 0, 0, 1, 1},
  {&__pyx_n_s_initialize, __pyx_k_initialize, sizeof(__pyx_k_initialize), 0, 0, 1, 1},
  {&__pyx_n_s_internalSamplingRate, __pyx_k_internalSamplingRate, sizeof(__pyx_k_internalSamplingRate), 0, 0, 1, 1},
  {&__pyx_n_s_items, __pyx_k_items, sizeof(__pyx_k_items), 0, 0, 1, 1},
  {&__pyx_n_s_itertools, __pyx_k_itertools, sizeof(__pyx_k_itertools), 0, 0, 1, 1},
  {&__pyx_n_s_join, __pyx_k_join, sizeof(__pyx_k_join), 0, 0, 1, 1},
  {&__pyx_n_s_key, __pyx_k_key, sizeof(__pyx_k_key), 0, 0, 1, 1},
  {&__pyx_n_s_length, __pyx_k_length, sizeof(__pyx_k_length), 0, 0, 1, 1},
  {&__pyx_n_s_librosa, __pyx_k_librosa, sizeof(__pyx_k_librosa), 0, 0, 1, 1},
  {&__pyx_n_s_limited_supra_glottal_sequence, __pyx_k_limited_supra_glottal_sequence, sizeof(__pyx_k_limited_supra_glottal_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_load, __pyx_k_load, sizeof(__pyx_k_load), 0, 0, 1, 1},
  {&__pyx_n_s_load_speaker_file, __pyx_k_load_speaker_file, sizeof(__pyx_k_load_speaker_file), 0, 0, 1, 1},
  {&__pyx_n_s_log, __pyx_k_log, sizeof(__pyx_k_log), 0, 0, 1, 1},
  {&__pyx_n_s_log_scale, __pyx_k_log_scale, sizeof(__pyx_k_log_scale), 0, 0, 1, 1},
  {&__pyx_n_s_logging, __pyx_k_logging, sizeof(__pyx_k_logging), 0, 0, 1, 1},
  {&__pyx_n_s_magnitude, __pyx_k_magnitude, sizeof(__pyx_k_magnitude), 0, 0, 1, 1},
  {&__pyx_n_s_magnitude_spectrum, __pyx_k_magnitude_spectrum, sizeof(__pyx_k_magnitude_spectrum), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_make_output_dir, __pyx_k_make_output_dir, sizeof(__pyx_k_make_output_dir), 0, 0, 1, 1},
  {&__pyx_n_s_make_output_path, __pyx_k_make_output_path, sizeof(__pyx_k_make_output_path), 0, 0, 1, 1},
  {&__pyx_n_s_max, __pyx_k_max, sizeof(__pyx_k_max), 0, 0, 1, 1},
  {&__pyx_n_s_melspectrogram, __pyx_k_melspectrogram, sizeof(__pyx_k_melspectrogram), 0, 0, 1, 1},
  {&__pyx_n_s_melspectrogram_file_path, __pyx_k_melspectrogram_file_path, sizeof(__pyx_k_melspectrogram_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_melspectrogram_kwargs, __pyx_k_melspectrogram_kwargs, sizeof(__pyx_k_melspectrogram_kwargs), 0, 0, 1, 1},
  {&__pyx_n_s_min, __pyx_k_min, sizeof(__pyx_k_min), 0, 0, 1, 1},
  {&__pyx_n_s_modification_kwargs, __pyx_k_modification_kwargs, sizeof(__pyx_k_modification_kwargs), 0, 0, 1, 1},
  {&__pyx_n_s_modify_gestural_score, __pyx_k_modify_gestural_score, sizeof(__pyx_k_modify_gestural_score), 0, 0, 1, 1},
  {&__pyx_n_s_motor_score, __pyx_k_motor_score, sizeof(__pyx_k_motor_score), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence, __pyx_k_motor_sequence, sizeof(__pyx_k_motor_sequence), 0, 0, 1, 1},
  {&__pyx_kp_s_motor_sequence_argument_must_be, __pyx_k_motor_sequence_argument_must_be, sizeof(__pyx_k_motor_sequence_argument_must_be), 0, 0, 1, 0},
  {&__pyx_n_s_motor_sequence_data, __pyx_k_motor_sequence_data, sizeof(__pyx_k_motor_sequence_data), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence_list, __pyx_k_motor_sequence_list, sizeof(__pyx_k_motor_sequence_list), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence_name, __pyx_k_motor_sequence_name, sizeof(__pyx_k_motor_sequence_name), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence_to_melspectrogra, __pyx_k_motor_sequence_to_melspectrogra, sizeof(__pyx_k_motor_sequence_to_melspectrogra), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence_to_melspectrogram, __pyx_k_motor_sequence_to_melspectrogram, sizeof(__pyx_k_motor_sequence_to_melspectrogram), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence_to_spectrogram, __pyx_k_motor_sequence_to_spectrogram, sizeof(__pyx_k_motor_sequence_to_spectrogram), 0, 0, 1, 1},
  {&__pyx_n_s_motor_sequence_to_spectrogram_2, __pyx_k_motor_sequence_to_spectrogram_2, sizeof(__pyx_k_motor_sequence_to_spectrogram_2), 0, 0, 1, 1},
  {&__pyx_n_s_mp, __pyx_k_mp, sizeof(__pyx_k_mp), 0, 0, 1, 1},
  {&__pyx_n_s_multiprocessing, __pyx_k_multiprocessing, sizeof(__pyx_k_multiprocessing), 0, 0, 1, 1},
  {&__pyx_n_s_n_glottis_params, __pyx_k_n_glottis_params, sizeof(__pyx_k_n_glottis_params), 0, 0, 1, 1},
  {&__pyx_n_s_n_samples, __pyx_k_n_samples, sizeof(__pyx_k_n_samples), 0, 0, 1, 1},
  {&__pyx_n_s_n_samples_per_state, __pyx_k_n_samples_per_state, sizeof(__pyx_k_n_samples_per_state), 0, 0, 1, 1},
  {&__pyx_n_s_n_spectrum_samples, __pyx_k_n_spectrum_samples, sizeof(__pyx_k_n_spectrum_samples), 0, 0, 1, 1},
  {&__pyx_n_s_n_tract_params, __pyx_k_n_tract_params, sizeof(__pyx_k_n_tract_params), 0, 0, 1, 1},
  {&__pyx_n_s_n_tube_sections, __pyx_k_n_tube_sections, sizeof(__pyx_k_n_tube_sections), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
  {&__pyx_n_s_names, __pyx_k_names, sizeof(__pyx_k_names), 0, 0, 1, 1},
  {&__pyx_n_s_normalize, __pyx_k_normalize, sizeof(__pyx_k_normalize), 0, 0, 1, 1},
  {&__pyx_n_s_normalize_audio, __pyx_k_normalize_audio, sizeof(__pyx_k_normalize_audio), 0, 0, 1, 1},
  {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
  {&__pyx_n_s_numAudioSamples, __pyx_k_numAudioSamples, sizeof(__pyx_k_numAudioSamples), 0, 0, 1, 1},
  {&__pyx_n_s_numAudioSamplesPerTractState, __pyx_k_numAudioSamplesPerTractState, sizeof(__pyx_k_numAudioSamplesPerTractState), 0, 0, 1, 1},
  {&__pyx_n_s_numFrames, __pyx_k_numFrames, sizeof(__pyx_k_numFrames), 0, 0, 1, 1},
  {&__pyx_n_s_numGestureSamples, __pyx_k_numGestureSamples, sizeof(__pyx_k_numGestureSamples), 0, 0, 1, 1},
  {&__pyx_n_s_numGlottisParams, __pyx_k_numGlottisParams, sizeof(__pyx_k_numGlottisParams), 0, 0, 1, 1},
  {&__pyx_n_s_numS, __pyx_k_numS, sizeof(__pyx_k_numS), 0, 0, 1, 1},
  {&__pyx_n_s_numSpectrumSamples, __pyx_k_numSpectrumSamples, sizeof(__pyx_k_numSpectrumSamples), 0, 0, 1, 1},
  {&__pyx_n_s_numTubeSections, __pyx_k_numTubeSections, sizeof(__pyx_k_numTubeSections), 0, 0, 1, 1},
  {&__pyx_n_s_numVocalTractParams, __pyx_k_numVocalTractParams, sizeof(__pyx_k_numVocalTractParams), 0, 0, 1, 1},
  {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
  {&__pyx_kp_s_numpy_core_multiarray_failed_to, __pyx_k_numpy_core_multiarray_failed_to, sizeof(__pyx_k_numpy_core_multiarray_failed_to), 0, 0, 1, 0},
  {&__pyx_kp_s_numpy_core_umath_failed_to_impor, __pyx_k_numpy_core_umath_failed_to_impor, sizeof(__pyx_k_numpy_core_umath_failed_to_impor), 0, 0, 1, 0},
  {&__pyx_n_s_open, __pyx_k_open, sizeof(__pyx_k_open), 0, 0, 1, 1},
  {&__pyx_n_s_orig_sr, __pyx_k_orig_sr, sizeof(__pyx_k_orig_sr), 0, 0, 1, 1},
  {&__pyx_n_s_os, __pyx_k_os, sizeof(__pyx_k_os), 0, 0, 1, 1},
  {&__pyx_n_s_outTractParams, __pyx_k_outTractParams, sizeof(__pyx_k_outTractParams), 0, 0, 1, 1},
  {&__pyx_n_s_out_ges_file_path, __pyx_k_out_ges_file_path, sizeof(__pyx_k_out_ges_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_out_ges_file_path_list, __pyx_k_out_ges_file_path_list, sizeof(__pyx_k_out_ges_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_pair, __pyx_k_pair, sizeof(__pyx_k_pair), 0, 0, 1, 1},
  {&__pyx_n_s_pandas, __pyx_k_pandas, sizeof(__pyx_k_pandas), 0, 0, 1, 1},
  {&__pyx_n_s_paramMax, __pyx_k_paramMax, sizeof(__pyx_k_paramMax), 0, 0, 1, 1},
  {&__pyx_n_s_paramMin, __pyx_k_paramMin, sizeof(__pyx_k_paramMin), 0, 0, 1, 1},
  {&__pyx_n_s_paramStandard, __pyx_k_paramStandard, sizeof(__pyx_k_paramStandard), 0, 0, 1, 1},
  {&__pyx_n_s_params, __pyx_k_params, sizeof(__pyx_k_params), 0, 0, 1, 1},
  {&__pyx_n_s_path, __pyx_k_path, sizeof(__pyx_k_path), 0, 0, 1, 1},
  {&__pyx_n_s_pd, __pyx_k_pd, sizeof(__pyx_k_pd), 0, 0, 1, 1},
  {&__pyx_n_s_phase_rad, __pyx_k_phase_rad, sizeof(__pyx_k_phase_rad), 0, 0, 1, 1},
  {&__pyx_n_s_phase_spectrum, __pyx_k_phase_spectrum, sizeof(__pyx_k_phase_spectrum), 0, 0, 1, 1},
  {&__pyx_n_s_pool, __pyx_k_pool, sizeof(__pyx_k_pool), 0, 0, 1, 1},
  {&__pyx_n_s_power_to_db, __pyx_k_power_to_db, sizeof(__pyx_k_power_to_db), 0, 0, 1, 1},
  {&__pyx_n_s_prettify, __pyx_k_prettify, sizeof(__pyx_k_prettify), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_ravel, __pyx_k_ravel, sizeof(__pyx_k_ravel), 0, 0, 1, 1},
  {&__pyx_n_s_read, __pyx_k_read, sizeof(__pyx_k_read), 0, 0, 1, 1},
  {&__pyx_n_s_register, __pyx_k_register, sizeof(__pyx_k_register), 0, 0, 1, 1},
  {&__pyx_n_s_replace, __pyx_k_replace, sizeof(__pyx_k_replace), 0, 0, 1, 1},
  {&__pyx_n_s_resample, __pyx_k_resample, sizeof(__pyx_k_resample), 0, 0, 1, 1},
  {&__pyx_n_s_resampled_index, __pyx_k_resampled_index, sizeof(__pyx_k_resampled_index), 0, 0, 1, 1},
  {&__pyx_n_s_resampled_tract_states, __pyx_k_resampled_tract_states, sizeof(__pyx_k_resampled_tract_states), 0, 0, 1, 1},
  {&__pyx_n_s_return_audio, __pyx_k_return_audio, sizeof(__pyx_k_return_audio), 0, 0, 1, 1},
  {&__pyx_n_s_return_data, __pyx_k_return_data, sizeof(__pyx_k_return_data), 0, 0, 1, 1},
  {&__pyx_n_s_return_motor_sequence, __pyx_k_return_motor_sequence, sizeof(__pyx_k_return_motor_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_return_samples, __pyx_k_return_samples, sizeof(__pyx_k_return_samples), 0, 0, 1, 1},
  {&__pyx_n_s_return_sequence, __pyx_k_return_sequence, sizeof(__pyx_k_return_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_round, __pyx_k_round, sizeof(__pyx_k_round), 0, 0, 1, 1},
  {&__pyx_n_s_rsplit, __pyx_k_rsplit, sizeof(__pyx_k_rsplit), 0, 0, 1, 1},
  {&__pyx_n_s_run_multiprocessing, __pyx_k_run_multiprocessing, sizeof(__pyx_k_run_multiprocessing), 0, 0, 1, 1},
  {&__pyx_n_s_run_multiprocessing_locals_gene, __pyx_k_run_multiprocessing_locals_gene, sizeof(__pyx_k_run_multiprocessing_locals_gene), 0, 0, 1, 1},
  {&__pyx_n_s_samplerate_audio, __pyx_k_samplerate_audio, sizeof(__pyx_k_samplerate_audio), 0, 0, 1, 1},
  {&__pyx_n_s_samplerate_internal, __pyx_k_samplerate_internal, sizeof(__pyx_k_samplerate_internal), 0, 0, 1, 1},
  {&__pyx_n_s_save, __pyx_k_save, sizeof(__pyx_k_save), 0, 0, 1, 1},
  {&__pyx_n_s_save_file, __pyx_k_save_file, sizeof(__pyx_k_save_file), 0, 0, 1, 1},
  {&__pyx_n_s_save_incisor_position, __pyx_k_save_incisor_position, sizeof(__pyx_k_save_incisor_position), 0, 0, 1, 1},
  {&__pyx_n_s_save_magnitude_spectrum, __pyx_k_save_magnitude_spectrum, sizeof(__pyx_k_save_magnitude_spectrum), 0, 0, 1, 1},
  {&__pyx_n_s_save_phase_spectrum, __pyx_k_save_phase_spectrum, sizeof(__pyx_k_save_phase_spectrum), 0, 0, 1, 1},
  {&__pyx_n_s_save_tongue_tip_side_elevation, __pyx_k_save_tongue_tip_side_elevation, sizeof(__pyx_k_save_tongue_tip_side_elevation), 0, 0, 1, 1},
  {&__pyx_n_s_save_tube_area, __pyx_k_save_tube_area, sizeof(__pyx_k_save_tube_area), 0, 0, 1, 1},
  {&__pyx_n_s_save_tube_articulator, __pyx_k_save_tube_articulator, sizeof(__pyx_k_save_tube_articulator), 0, 0, 1, 1},
  {&__pyx_n_s_save_tube_length, __pyx_k_save_tube_length, sizeof(__pyx_k_save_tube_length), 0, 0, 1, 1},
  {&__pyx_n_s_save_velum_opening, __pyx_k_save_velum_opening, sizeof(__pyx_k_save_velum_opening), 0, 0, 1, 1},
  {&__pyx_n_s_save_video, __pyx_k_save_video, sizeof(__pyx_k_save_video), 0, 0, 1, 1},
  {&__pyx_n_s_segFileName, __pyx_k_segFileName, sizeof(__pyx_k_segFileName), 0, 0, 1, 1},
  {&__pyx_n_s_seg_file_path, __pyx_k_seg_file_path, sizeof(__pyx_k_seg_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_seg_file_path_list, __pyx_k_seg_file_path_list, sizeof(__pyx_k_seg_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_segment_sequence_to_gestural_sc, __pyx_k_segment_sequence_to_gestural_sc, sizeof(__pyx_k_segment_sequence_to_gestural_sc), 0, 0, 1, 1},
  {&__pyx_n_s_segment_sequence_to_gestural_sco, __pyx_k_segment_sequence_to_gestural_sco, sizeof(__pyx_k_segment_sequence_to_gestural_sco), 0, 0, 1, 1},
  {&__pyx_n_s_send, __pyx_k_send, sizeof(__pyx_k_send), 0, 0, 1, 1},
  {&__pyx_n_s_setLevel, __pyx_k_setLevel, sizeof(__pyx_k_setLevel), 0, 0, 1, 1},
  {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
  {&__pyx_n_s_shapeName, __pyx_k_shapeName, sizeof(__pyx_k_shapeName), 0, 0, 1, 1},
  {&__pyx_n_s_shape_list, __pyx_k_shape_list, sizeof(__pyx_k_shape_list), 0, 0, 1, 1},
  {&__pyx_n_s_speakerFileName, __pyx_k_speakerFileName, sizeof(__pyx_k_speakerFileName), 0, 0, 1, 1},
  {&__pyx_kp_s_speaker_JD3_speaker, __pyx_k_speaker_JD3_speaker, sizeof(__pyx_k_speaker_JD3_speaker), 0, 0, 1, 0},
  {&__pyx_n_s_speaker_file_path, __pyx_k_speaker_file_path, sizeof(__pyx_k_speaker_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_spectrogram, __pyx_k_spectrogram, sizeof(__pyx_k_spectrogram), 0, 0, 1, 1},
  {&__pyx_n_s_spectrogram_file_path, __pyx_k_spectrogram_file_path, sizeof(__pyx_k_spectrogram_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_spectrogram_file_path_list, __pyx_k_spectrogram_file_path_list, sizeof(__pyx_k_spectrogram_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_spectrogram_kwargs, __pyx_k_spectrogram_kwargs, sizeof(__pyx_k_spectrogram_kwargs), 0, 0, 1, 1},
  {&__pyx_kp_s_spectrogram_pkl_gzip, __pyx_k_spectrogram_pkl_gzip, sizeof(__pyx_k_spectrogram_pkl_gzip), 0, 0, 1, 0},
  {&__pyx_n_s_split, __pyx_k_split, sizeof(__pyx_k_split), 0, 0, 1, 1},
  {&__pyx_n_s_sr, __pyx_k_sr, sizeof(__pyx_k_sr), 0, 0, 1, 1},
  {&__pyx_n_s_standard, __pyx_k_standard, sizeof(__pyx_k_standard), 0, 0, 1, 1},
  {&__pyx_n_s_standard_16kHz_melspectrogram_80, __pyx_k_standard_16kHz_melspectrogram_80, sizeof(__pyx_k_standard_16kHz_melspectrogram_80), 0, 0, 1, 1},
  {&__pyx_n_s_standard_16kHz_spectrogram_kwarg, __pyx_k_standard_16kHz_spectrogram_kwarg, sizeof(__pyx_k_standard_16kHz_spectrogram_kwarg), 0, 0, 1, 1},
  {&__pyx_n_s_state, __pyx_k_state, sizeof(__pyx_k_state), 0, 0, 1, 1},
  {&__pyx_n_s_state_samples, __pyx_k_state_samples, sizeof(__pyx_k_state_samples), 0, 0, 1, 1},
  {&__pyx_n_s_states, __pyx_k_states, sizeof(__pyx_k_states), 0, 0, 1, 1},
  {&__pyx_n_s_stft, __pyx_k_stft, sizeof(__pyx_k_stft), 0, 0, 1, 1},
  {&__pyx_n_s_strip, __pyx_k_strip, sizeof(__pyx_k_strip), 0, 0, 1, 1},
  {&__pyx_n_s_sub_glottal_sequence, __pyx_k_sub_glottal_sequence, sizeof(__pyx_k_sub_glottal_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_sub_glottal_sequence_name, __pyx_k_sub_glottal_sequence_name, sizeof(__pyx_k_sub_glottal_sequence_name), 0, 0, 1, 1},
  {&__pyx_n_s_sub_glottal_shape_names, __pyx_k_sub_glottal_shape_names, sizeof(__pyx_k_sub_glottal_shape_names), 0, 0, 1, 1},
  {&__pyx_n_s_sub_glottal_shapes, __pyx_k_sub_glottal_shapes, sizeof(__pyx_k_sub_glottal_shapes), 0, 0, 1, 1},
  {&__pyx_n_s_supra_glottal_sequence, __pyx_k_supra_glottal_sequence, sizeof(__pyx_k_supra_glottal_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_supra_glottal_sequence_name, __pyx_k_supra_glottal_sequence_name, sizeof(__pyx_k_supra_glottal_sequence_name), 0, 0, 1, 1},
  {&__pyx_n_s_supra_glottal_shape_names, __pyx_k_supra_glottal_shape_names, sizeof(__pyx_k_supra_glottal_shape_names), 0, 0, 1, 1},
  {&__pyx_n_s_supra_glottal_shapes, __pyx_k_supra_glottal_shapes, sizeof(__pyx_k_supra_glottal_shapes), 0, 0, 1, 1},
  {&__pyx_n_s_svg, __pyx_k_svg, sizeof(__pyx_k_svg), 0, 0, 1, 1},
  {&__pyx_n_s_svg_dir, __pyx_k_svg_dir, sizeof(__pyx_k_svg_dir), 0, 0, 1, 1},
  {&__pyx_n_s_svg_dir_list, __pyx_k_svg_dir_list, sizeof(__pyx_k_svg_dir_list), 0, 0, 1, 1},
  {&__pyx_n_s_synth_block, __pyx_k_synth_block, sizeof(__pyx_k_synth_block), 0, 0, 1, 1},
  {&__pyx_n_s_target_sr, __pyx_k_target_sr, sizeof(__pyx_k_target_sr), 0, 0, 1, 1},
  {&__pyx_n_s_tasks, __pyx_k_tasks, sizeof(__pyx_k_tasks), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_kp_s_the_specified_gestural_score_fil, __pyx_k_the_specified_gestural_score_fil, sizeof(__pyx_k_the_specified_gestural_score_fil), 0, 0, 1, 0},
  {&__pyx_kp_s_the_specified_segment_sequence_f, __pyx_k_the_specified_segment_sequence_f, sizeof(__pyx_k_the_specified_segment_sequence_f), 0, 0, 1, 0},
  {&__pyx_kp_s_the_specified_tract_sequence_fil, __pyx_k_the_specified_tract_sequence_fil, sizeof(__pyx_k_the_specified_tract_sequence_fil), 0, 0, 1, 0},
  {&__pyx_n_s_throw, __pyx_k_throw, sizeof(__pyx_k_throw), 0, 0, 1, 1},
  {&__pyx_n_s_time, __pyx_k_time, sizeof(__pyx_k_time), 0, 0, 1, 1},
  {&__pyx_n_s_time_end, __pyx_k_time_end, sizeof(__pyx_k_time_end), 0, 0, 1, 1},
  {&__pyx_n_s_time_start, __pyx_k_time_start, sizeof(__pyx_k_time_start), 0, 0, 1, 1},
  {&__pyx_n_s_time_synth_end, __pyx_k_time_synth_end, sizeof(__pyx_k_time_synth_end), 0, 0, 1, 1},
  {&__pyx_n_s_time_synth_start, __pyx_k_time_synth_start, sizeof(__pyx_k_time_synth_start), 0, 0, 1, 1},
  {&__pyx_n_s_to_motor_sequence, __pyx_k_to_motor_sequence, sizeof(__pyx_k_to_motor_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_to_numpy, __pyx_k_to_numpy, sizeof(__pyx_k_to_numpy), 0, 0, 1, 1},
  {&__pyx_n_s_to_sub_glottal_sequence, __pyx_k_to_sub_glottal_sequence, sizeof(__pyx_k_to_sub_glottal_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_to_sub_glottal_states, __pyx_k_to_sub_glottal_states, sizeof(__pyx_k_to_sub_glottal_states), 0, 0, 1, 1},
  {&__pyx_n_s_to_supra_glottal_sequence, __pyx_k_to_supra_glottal_sequence, sizeof(__pyx_k_to_supra_glottal_sequence), 0, 0, 1, 1},
  {&__pyx_n_s_to_supra_glottal_states, __pyx_k_to_supra_glottal_states, sizeof(__pyx_k_to_supra_glottal_states), 0, 0, 1, 1},
  {&__pyx_n_s_tongueTipSideElevation, __pyx_k_tongueTipSideElevation, sizeof(__pyx_k_tongueTipSideElevation), 0, 0, 1, 1},
  {&__pyx_n_s_tongue_tip_side_elevation, __pyx_k_tongue_tip_side_elevation, sizeof(__pyx_k_tongue_tip_side_elevation), 0, 0, 1, 1},
  {&__pyx_n_s_total, __pyx_k_total, sizeof(__pyx_k_total), 0, 0, 1, 1},
  {&__pyx_n_s_tqdm, __pyx_k_tqdm, sizeof(__pyx_k_tqdm), 0, 0, 1, 1},
  {&__pyx_n_s_tract, __pyx_k_tract, sizeof(__pyx_k_tract), 0, 0, 1, 1},
  {&__pyx_n_s_tractParams, __pyx_k_tractParams, sizeof(__pyx_k_tractParams), 0, 0, 1, 1},
  {&__pyx_n_s_tractSequenceFileName, __pyx_k_tractSequenceFileName, sizeof(__pyx_k_tractSequenceFileName), 0, 0, 1, 1},
  {&__pyx_kp_s_tract_2, __pyx_k_tract_2, sizeof(__pyx_k_tract_2), 0, 0, 1, 0},
  {&__pyx_kp_s_tract__svg, __pyx_k_tract__svg, sizeof(__pyx_k_tract__svg), 0, 0, 1, 0},
  {&__pyx_n_s_tract_file_path, __pyx_k_tract_file_path, sizeof(__pyx_k_tract_file_path), 0, 0, 1, 1},
  {&__pyx_n_s_tract_file_path_list, __pyx_k_tract_file_path_list, sizeof(__pyx_k_tract_file_path_list), 0, 0, 1, 1},
  {&__pyx_n_s_tract_param_data, __pyx_k_tract_param_data, sizeof(__pyx_k_tract_param_data), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_list, __pyx_k_tract_sequence_list, sizeof(__pyx_k_tract_sequence_list), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_audio, __pyx_k_tract_sequence_to_audio, sizeof(__pyx_k_tract_sequence_to_audio), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_audio_2, __pyx_k_tract_sequence_to_audio_2, sizeof(__pyx_k_tract_sequence_to_audio_2), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_limited_tract, __pyx_k_tract_sequence_to_limited_tract, sizeof(__pyx_k_tract_sequence_to_limited_tract), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_svg, __pyx_k_tract_sequence_to_svg, sizeof(__pyx_k_tract_sequence_to_svg), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_svg_2, __pyx_k_tract_sequence_to_svg_2, sizeof(__pyx_k_tract_sequence_to_svg_2), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_transfer_funct, __pyx_k_tract_sequence_to_transfer_funct, sizeof(__pyx_k_tract_sequence_to_transfer_funct), 0, 0, 1, 1},
  {&__pyx_n_s_tract_sequence_to_tube_states, __pyx_k_tract_sequence_to_tube_states, sizeof(__pyx_k_tract_sequence_to_tube_states), 0, 0, 1, 1},
  {&__pyx_n_s_tract_state, __pyx_k_tract_state, sizeof(__pyx_k_tract_state), 0, 0, 1, 1},
  {&__pyx_n_s_tract_state_to_limited_tract_st, __pyx_k_tract_state_to_limited_tract_st, sizeof(__pyx_k_tract_state_to_limited_tract_st), 0, 0, 1, 1},
  {&__pyx_n_s_tract_state_to_transfer_functio, __pyx_k_tract_state_to_transfer_functio, sizeof(__pyx_k_tract_state_to_transfer_functio), 0, 0, 1, 1},
  {&__pyx_n_s_tract_state_to_tube_state, __pyx_k_tract_state_to_tube_state, sizeof(__pyx_k_tract_state_to_tube_state), 0, 0, 1, 1},
  {&__pyx_n_s_tract_states, __pyx_k_tract_states, sizeof(__pyx_k_tract_states), 0, 0, 1, 1},
  {&__pyx_n_s_transfer_functions, __pyx_k_transfer_functions, sizeof(__pyx_k_transfer_functions), 0, 0, 1, 1},
  {&__pyx_n_s_tubeArea_cm2, __pyx_k_tubeArea_cm2, sizeof(__pyx_k_tubeArea_cm2), 0, 0, 1, 1},
  {&__pyx_n_s_tubeArticulator, __pyx_k_tubeArticulator, sizeof(__pyx_k_tubeArticulator), 0, 0, 1, 1},
  {&__pyx_n_s_tubeLength_cm, __pyx_k_tubeLength_cm, sizeof(__pyx_k_tubeLength_cm), 0, 0, 1, 1},
  {&__pyx_n_s_tube_area, __pyx_k_tube_area, sizeof(__pyx_k_tube_area), 0, 0, 1, 1},
  {&__pyx_n_s_tube_articulator, __pyx_k_tube_articulator, sizeof(__pyx_k_tube_articulator), 0, 0, 1, 1},
  {&__pyx_n_s_tube_length, __pyx_k_tube_length, sizeof(__pyx_k_tube_length), 0, 0, 1, 1},
  {&__pyx_n_s_tube_states, __pyx_k_tube_states, sizeof(__pyx_k_tube_states), 0, 0, 1, 1},
  {&__pyx_n_s_type, __pyx_k_type, sizeof(__pyx_k_type), 0, 0, 1, 1},
  {&__pyx_n_s_unit, __pyx_k_unit, sizeof(__pyx_k_unit), 0, 0, 1, 1},
  {&__pyx_n_s_units, __pyx_k_units, sizeof(__pyx_k_units), 0, 0, 1, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_velumOpening_cm2, __pyx_k_velumOpening_cm2, sizeof(__pyx_k_velumOpening_cm2), 0, 0, 1, 1},
  {&__pyx_n_s_velum_opening, __pyx_k_velum_opening, sizeof(__pyx_k_velum_opening), 0, 0, 1, 1},
  {&__pyx_n_s_verbose, __pyx_k_verbose, sizeof(__pyx_k_verbose), 0, 0, 1, 1},
  {&__pyx_n_s_version, __pyx_k_version, sizeof(__pyx_k_version), 0, 0, 1, 1},
  {&__pyx_n_s_voice_quality_new, __pyx_k_voice_quality_new, sizeof(__pyx_k_voice_quality_new), 0, 0, 1, 1},
  {&__pyx_n_s_voice_quality_old, __pyx_k_voice_quality_old, sizeof(__pyx_k_voice_quality_old), 0, 0, 1, 1},
  {&__pyx_n_s_w, __pyx_k_w, sizeof(__pyx_k_w), 0, 0, 1, 1},
  {&__pyx_n_s_warn, __pyx_k_warn, sizeof(__pyx_k_warn), 0, 0, 1, 1},
  {&__pyx_n_s_warning, __pyx_k_warning, sizeof(__pyx_k_warning), 0, 0, 1, 1},
  {&__pyx_n_s_warnings, __pyx_k_warnings, sizeof(__pyx_k_warnings), 0, 0, 1, 1},
  {&__pyx_kp_s_wav, __pyx_k_wav, sizeof(__pyx_k_wav), 0, 0, 1, 0},
  {&__pyx_n_s_wavFileName, __pyx_k_wavFileName, sizeof(__pyx_k_wavFileName), 0, 0, 1, 1},
  {&__pyx_n_s_worker, __pyx_k_worker, sizeof(__pyx_k_worker), 0, 0, 1, 1},
  {&__pyx_n_s_workers, __pyx_k_workers, sizeof(__pyx_k_workers), 0, 0, 1, 1},
  {&__pyx_n_s_write, __pyx_k_write, sizeof(__pyx_k_write), 0, 0, 1, 1},
  {&__pyx_n_s_x, __pyx_k_x, sizeof(__pyx_k_x), 0, 0, 1, 1},
  {&__pyx_n_s_y, __pyx_k_y, sizeof(__pyx_k_y), 0, 0, 1, 1},
  {&__pyx_n_s_zeros, __pyx_k_zeros, sizeof(__pyx_k_zeros), 0, 0, 1, 1},
  {&__pyx_n_s_zip_longest, __pyx_k_zip_longest, sizeof(__pyx_k_zip_longest), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 239, __pyx_L1_error)
  __pyx_builtin_open = __Pyx_GetBuiltinName(__pyx_n_s_open); if (!__pyx_builtin_open) __PYX_ERR(0, 661, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 927, __pyx_L1_error)
  __pyx_builtin_round = __Pyx_GetBuiltinName(__pyx_n_s_round); if (!__pyx_builtin_round) __PYX_ERR(0, 927, __pyx_L1_error)
  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(0, 928, __pyx_L1_error)
  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(1, 945, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "VocalTractLab/VocalTractLabApi.pyx":239
 * 	#print( value )
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlCalcTongueRootAutomatically returned the Errorcode: {}  (See API doc for info.)' )             # <<<<<<<<<<<<<<
 * 	warnings.warn( 'Automatic calculation of the Tongue Root parameters was set to {}.'.format(automatic_calculation) )
 * 	return
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_VTL_API_function_vtlCalcTongueRo); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 239, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "VocalTractLab/VocalTractLabApi.pyx":298
 * 	if value != 0:
 * 		raise ValueError('VTL API function vtlGetTractParamInfo or vtlGetGlottisParamInfo returned the Errorcode: {}  (See API doc for info.)'.format( value ) )
 * 	descriptions = descriptions.decode().replace('\x00', '').strip(' ').strip('').split('\t')             # <<<<<<<<<<<<<<
 * 	units = units.decode().replace('\x00', '').strip(' ').strip( '' ).split('\t')
 * 	df = pd.DataFrame( np.array( [ descriptions, units, paramMin, paramMax, paramStandard ] ).T, columns = [ 'description', 'unit', 'min', 'max', 'standard' ] )
 */
  __pyx_tuple__6 = PyTuple_Pack(2, __pyx_kp_s__4, __pyx_kp_s__5); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":945
 *         __pyx_import_array()
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_umath() except -1:
 */
  __pyx_tuple__14 = PyTuple_Pack(1, __pyx_kp_s_numpy_core_multiarray_failed_to); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(1, 945, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__14);
  __Pyx_GIVEREF(__pyx_tuple__14);

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":951
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_ufunc() except -1:
 */
  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_s_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(1, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);

  /* "VocalTractLab/VocalTractLabApi.pyx":234
 * # 		Single core functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def automatic_calculation_of_TRX_and_TRY( bool automatic_calculation = True ):             # <<<<<<<<<<<<<<
 * 	cdef bool automaticCalculation = automatic_calculation
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 */
  __pyx_tuple__17 = PyTuple_Pack(3, __pyx_n_s_automatic_calculation, __pyx_n_s_automaticCalculation, __pyx_n_s_value); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);
  __pyx_codeobj__18 = (PyObject*)__Pyx_PyCode_New(1, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__17, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_automatic_calculation_of_TRX_and, 234, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__18)) __PYX_ERR(0, 234, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":243
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_version():             # <<<<<<<<<<<<<<
 * 	cdef char version[32]
 * 	vtlGetVersion( version )
 */
  __pyx_tuple__19 = PyTuple_Pack(1, __pyx_n_s_version); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 243, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);
  __pyx_codeobj__20 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__19, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_version, 243, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__20)) __PYX_ERR(0, 243, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":251
 * 	return version.decode()
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_constants():             # <<<<<<<<<<<<<<
 * 	cdef int audioSamplingRate = -1
 * 	cdef int numTubeSections = -1
 */
  __pyx_tuple__21 = PyTuple_Pack(8, __pyx_n_s_audioSamplingRate, __pyx_n_s_numTubeSections, __pyx_n_s_numVocalTractParams, __pyx_n_s_numGlottisParams, __pyx_n_s_numAudioSamplesPerTractState, __pyx_n_s_internalSamplingRate, __pyx_n_s_value, __pyx_n_s_constants); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(0, 251, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__21);
  __Pyx_GIVEREF(__pyx_tuple__21);
  __pyx_codeobj__22 = (PyObject*)__Pyx_PyCode_New(0, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__21, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_constants, 251, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__22)) __PYX_ERR(0, 251, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":277
 * 	return constants
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):             # <<<<<<<<<<<<<<
 * 	if params not in [ 'tract', 'glottis' ]:
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 */
  __pyx_tuple__23 = PyTuple_Pack(11, __pyx_n_s_params, __pyx_n_s_key, __pyx_n_s_constants, __pyx_n_s_names, __pyx_n_s_descriptions, __pyx_n_s_units, __pyx_n_s_paramMin, __pyx_n_s_paramMax, __pyx_n_s_paramStandard, __pyx_n_s_value, __pyx_n_s_df); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);
  __pyx_codeobj__24 = (PyObject*)__Pyx_PyCode_New(1, 0, 11, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__23, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_param_info, 277, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__24)) __PYX_ERR(0, 277, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":304
 * 	return df
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shape( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_tuple__25 = PyTuple_Pack(3, __pyx_n_s_shape_list, __pyx_n_s_params, __pyx_n_s_return_motor_sequence); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(0, 304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__25);
  __Pyx_GIVEREF(__pyx_tuple__25);
  __pyx_codeobj__26 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__25, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_shape, 304, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__26)) __PYX_ERR(0, 304, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":307
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )
 * 	constants = get_constants()
 */
  __pyx_tuple__27 = PyTuple_Pack(18, __pyx_n_s_shape_list, __pyx_n_s_params, __pyx_n_s_return_motor_sequence, __pyx_n_s_constants, __pyx_n_s_tractParams, __pyx_n_s_glottisParams, __pyx_n_s_supra_glottal_shapes, __pyx_n_s_sub_glottal_shapes, __pyx_n_s_supra_glottal_shape_names, __pyx_n_s_sub_glottal_shape_names, __pyx_n_s_shape, __pyx_n_s_shapeName, __pyx_n_s_value, __pyx_n_s_supra_glottal_sequence_name, __pyx_n_s_sub_glottal_sequence_name, __pyx_n_s_supra_glottal_sequence, __pyx_n_s_sub_glottal_sequence, __pyx_n_s_motor_sequence_name); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);
  __pyx_codeobj__28 = (PyObject*)__Pyx_PyCode_New(3, 0, 18, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__27, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_shapes, 307, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__28)) __PYX_ERR(0, 307, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":352
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_supra_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_tuple__29 = PyTuple_Pack(1, __pyx_n_s_key); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_GIVEREF(__pyx_tuple__29);
  __pyx_codeobj__30 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__29, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_supra_glottal_state, 352, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__30)) __PYX_ERR(0, 352, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":355
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_sub_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_tuple__31 = PyTuple_Pack(1, __pyx_n_s_key); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_GIVEREF(__pyx_tuple__31);
  __pyx_codeobj__32 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__31, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_sub_glottal_state, 355, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__32)) __PYX_ERR(0, 355, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":358
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def load_speaker_file( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	_close()
 * 	_initialize( speaker_file_path )
 */
  __pyx_tuple__33 = PyTuple_Pack(1, __pyx_n_s_speaker_file_path); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(0, 358, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_GIVEREF(__pyx_tuple__33);
  __pyx_codeobj__34 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__33, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_load_speaker_file, 358, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__34)) __PYX_ERR(0, 358, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":369
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_gestural_score_audio_duration( str ges_file_path, return_samples = True ):             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	cdef int numAudioSamples = 0
 */
  __pyx_tuple__35 = PyTuple_Pack(6, __pyx_n_s_ges_file_path, __pyx_n_s_return_samples, __pyx_n_s_gesFileName, __pyx_n_s_numAudioSamples, __pyx_n_s_numGestureSamples, __pyx_n_s_n_samples); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(0, 369, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);
  __pyx_codeobj__36 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__35, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_get_gestural_score_audio_duratio, 369, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__36)) __PYX_ERR(0, 369, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":385
 * # 		User mp enabled functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def change_gestural_score(             # <<<<<<<<<<<<<<
 * 	in_ges_file_path_list,
 * 	out_ges_file_path_list,
 */
  __pyx_tuple__37 = PyTuple_Pack(4, __pyx_n_s_in_ges_file_path_list, __pyx_n_s_out_ges_file_path_list, __pyx_n_s_modification_kwargs, __pyx_n_s_workers); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(0, 385, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);
  __pyx_codeobj__38 = (PyObject*)__Pyx_PyCode_New(4, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__37, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_change_gestural_score, 385, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__38)) __PYX_ERR(0, 385, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":394
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,
 */
  __pyx_tuple__39 = PyTuple_Pack(12, __pyx_n_s_ges_file_path_list, __pyx_n_s_audio_file_path_list, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_return_data, __pyx_n_s_workers, __pyx_n_s_verbose, __pyx_n_s_args, __pyx_n_s_audio_data_list, __pyx_n_s_ges_file_path, __pyx_n_s_audio_file_path); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(0, 394, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);
  __pyx_codeobj__40 = (PyObject*)__Pyx_PyCode_New(8, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__39, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_gestural_score_to_audio_2, 394, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__40)) __PYX_ERR(0, 394, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":414
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,
 */
  __pyx_tuple__41 = PyTuple_Pack(8, __pyx_n_s_ges_file_path_list, __pyx_n_s_tract_file_path_list, __pyx_n_s_return_data, __pyx_n_s_workers, __pyx_n_s_args, __pyx_n_s_tract_sequence_list, __pyx_n_s_ges_file_path, __pyx_n_s_tract_file_path); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(0, 414, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);
  __pyx_codeobj__42 = (PyObject*)__Pyx_PyCode_New(4, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__41, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_gestural_score_to_tract_sequence, 414, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__42)) __PYX_ERR(0, 414, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":427
 * 	return tract_sequence_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,             # <<<<<<<<<<<<<<
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,
 */
  __pyx_tuple__43 = PyTuple_Pack(7, __pyx_n_s_seg_file_path_list, __pyx_n_s_ges_file_path_list, __pyx_n_s_workers, __pyx_n_s_verbose, __pyx_n_s_args, __pyx_n_s_seg_file_path, __pyx_n_s_ges_file_path); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(0, 427, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);
  __pyx_codeobj__44 = (PyObject*)__Pyx_PyCode_New(4, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__43, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_segment_sequence_to_gestural_sco, 427, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__44)) __PYX_ERR(0, 427, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":440
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                         audio_file_path_list = None,
 * 	                         save_file: bool = True,
 */
  __pyx_tuple__45 = PyTuple_Pack(13, __pyx_n_s_motor_sequence_list, __pyx_n_s_audio_file_path_list, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_return_data, __pyx_n_s_workers, __pyx_n_s_verbose, __pyx_n_s_args, __pyx_n_s_audio_data_list, __pyx_n_s_motor_sequence, __pyx_n_s_audio_file_path, __pyx_n_s_arg); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(0, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__45);
  __Pyx_GIVEREF(__pyx_tuple__45);
  __pyx_codeobj__46 = (PyObject*)__Pyx_PyCode_New(8, 0, 13, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__45, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_audio_2, 440, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__46)) __PYX_ERR(0, 440, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":462
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_spectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */
  __pyx_tuple__47 = PyTuple_Pack(15, __pyx_n_s_motor_sequence_list, __pyx_n_s_audio_file_path_list, __pyx_n_s_spectrogram_file_path_list, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_spectrogram_kwargs, __pyx_n_s_return_data, __pyx_n_s_workers, __pyx_n_s_verbose, __pyx_n_s_args, __pyx_n_s_audio_data_list, __pyx_n_s_motor_sequence, __pyx_n_s_audio_file_path, __pyx_n_s_spectrogram_file_path); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);
  __pyx_codeobj__48 = (PyObject*)__Pyx_PyCode_New(10, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__47, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_motor_sequence_to_spectrogram_2, 462, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__48)) __PYX_ERR(0, 462, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":496
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_melspectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */
  __pyx_tuple__49 = PyTuple_Pack(17, __pyx_n_s_motor_sequence_list, __pyx_n_s_audio_file_path_list, __pyx_n_s_spectrogram_file_path_list, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_log_scale, __pyx_n_s_spectrogram_kwargs, __pyx_n_s_melspectrogram_kwargs, __pyx_n_s_return_data, __pyx_n_s_workers, __pyx_n_s_verbose, __pyx_n_s_args, __pyx_n_s_audio_data_list, __pyx_n_s_motor_sequence, __pyx_n_s_audio_file_path, __pyx_n_s_spectrogram_file_path); if (unlikely(!__pyx_tuple__49)) __PYX_ERR(0, 496, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__49);
  __Pyx_GIVEREF(__pyx_tuple__49);
  __pyx_codeobj__50 = (PyObject*)__Pyx_PyCode_New(12, 0, 17, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__49, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_motor_sequence_to_melspectrogram, 496, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__50)) __PYX_ERR(0, 496, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":534
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                          workers: int = None,
 * 	                                        ):
 */
  __pyx_tuple__51 = PyTuple_Pack(6, __pyx_n_s_motor_sequence, __pyx_n_s_workers, __pyx_n_s_tract_param_data, __pyx_n_s_args, __pyx_n_s_limited_supra_glottal_sequence, __pyx_n_s_state); if (unlikely(!__pyx_tuple__51)) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__51);
  __Pyx_GIVEREF(__pyx_tuple__51);
  __pyx_codeobj__52 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__51, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_limited_tract, 534, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__52)) __PYX_ERR(0, 534, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":548
 * 		return limited_supra_glottal_sequence
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                       svg_dir_list = None,
 * 	                       fps: int = 60,
 */
  __pyx_tuple__53 = PyTuple_Pack(8, __pyx_n_s_motor_sequence_list, __pyx_n_s_svg_dir_list, __pyx_n_s_fps, __pyx_n_s_save_video, __pyx_n_s_workers, __pyx_n_s_args, __pyx_n_s_motor_sequence, __pyx_n_s_svg_dir); if (unlikely(!__pyx_tuple__53)) __PYX_ERR(0, 548, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__53);
  __Pyx_GIVEREF(__pyx_tuple__53);
  __pyx_codeobj__54 = (PyObject*)__Pyx_PyCode_New(5, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__53, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_svg_2, 548, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__54)) __PYX_ERR(0, 548, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":564
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_transfer_functions( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,
 */
  __pyx_tuple__55 = PyTuple_Pack(9, __pyx_n_s_motor_sequence, __pyx_n_s_n_spectrum_samples, __pyx_n_s_save_magnitude_spectrum, __pyx_n_s_save_phase_spectrum, __pyx_n_s_workers, __pyx_n_s_tract_param_data, __pyx_n_s_args, __pyx_n_s_transfer_functions, __pyx_n_s_state); if (unlikely(!__pyx_tuple__55)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__55);
  __Pyx_GIVEREF(__pyx_tuple__55);
  __pyx_codeobj__56 = (PyObject*)__Pyx_PyCode_New(5, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__55, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_transfer_funct, 564, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__56)) __PYX_ERR(0, 564, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":583
 * 	return transfer_functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,
 */
  __pyx_tuple__57 = PyTuple_Pack(13, __pyx_n_s_motor_sequence, __pyx_n_s_save_tube_length, __pyx_n_s_save_tube_area, __pyx_n_s_save_tube_articulator, __pyx_n_s_save_incisor_position, __pyx_n_s_save_tongue_tip_side_elevation, __pyx_n_s_save_velum_opening, __pyx_n_s_workers, __pyx_n_s_tract_param_data, __pyx_n_s_args, __pyx_n_s_tube_states, __pyx_n_s_state, __pyx_n_s_arg); if (unlikely(!__pyx_tuple__57)) __PYX_ERR(0, 583, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__57);
  __Pyx_GIVEREF(__pyx_tuple__57);
  __pyx_codeobj__58 = (PyObject*)__Pyx_PyCode_New(8, 0, 13, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__57, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_tube_states, 583, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__58)) __PYX_ERR(0, 583, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":629
 * # 		constructor / destructor functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _initialize( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )
 */
  __pyx_tuple__59 = PyTuple_Pack(3, __pyx_n_s_speaker_file_path, __pyx_n_s_speakerFileName, __pyx_n_s_value); if (unlikely(!__pyx_tuple__59)) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__59);
  __Pyx_GIVEREF(__pyx_tuple__59);
  __pyx_codeobj__60 = (PyObject*)__Pyx_PyCode_New(1, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__59, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_initialize, 629, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__60)) __PYX_ERR(0, 629, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":637
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _close():             # <<<<<<<<<<<<<<
 * 	value = vtlClose()
 * 	if value != 0:
 */
  __pyx_tuple__61 = PyTuple_Pack(1, __pyx_n_s_value); if (unlikely(!__pyx_tuple__61)) __PYX_ERR(0, 637, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__61);
  __Pyx_GIVEREF(__pyx_tuple__61);
  __pyx_codeobj__62 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__61, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_close, 637, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__62)) __PYX_ERR(0, 637, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":659
 * #	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _modify_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	in_ges_file_path, out_ges_file_path = args
 * 	ges_file = open( in_ges_file_path ).read()
 */
  __pyx_tuple__63 = PyTuple_Pack(6, __pyx_n_s_args, __pyx_n_s_in_ges_file_path, __pyx_n_s_out_ges_file_path, __pyx_n_s_ges_file, __pyx_n_s_ges_soup, __pyx_n_s_f); if (unlikely(!__pyx_tuple__63)) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__63);
  __Pyx_GIVEREF(__pyx_tuple__63);
  __pyx_codeobj__64 = (PyObject*)__Pyx_PyCode_New(1, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__63, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_modify_gestural_score, 659, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__64)) __PYX_ERR(0, 659, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":669
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_voice_quality( args ):             # <<<<<<<<<<<<<<
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 */
  __pyx_tuple__65 = PyTuple_Pack(5, __pyx_n_s_args, __pyx_n_s_gestural_score_soup, __pyx_n_s_voice_quality_new, __pyx_n_s_voice_quality_old, __pyx_n_s_element); if (unlikely(!__pyx_tuple__65)) __PYX_ERR(0, 669, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__65);
  __Pyx_GIVEREF(__pyx_tuple__65);
  __pyx_codeobj__66 = (PyObject*)__Pyx_PyCode_New(1, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__65, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_gestural_score_change_voice_qua, 669, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__66)) __PYX_ERR(0, 669, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":679
 * 	return gestural_score_soup
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_duration():             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_codeobj__67 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_gestural_score_change_duration, 679, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__67)) __PYX_ERR(0, 679, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":682
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	time_start = time.time()
 */
  __pyx_tuple__68 = PyTuple_Pack(19, __pyx_n_s_args, __pyx_n_s_time_start, __pyx_n_s_ges_file_path, __pyx_n_s_audio_file_path, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_verbose, __pyx_n_s_constants, __pyx_n_s_return_audio, __pyx_n_s_wavFileName, __pyx_n_s_gesFileName, __pyx_n_s_audio, __pyx_n_s_enableConsoleOutput, __pyx_n_s_time_synth_start, __pyx_n_s_numS, __pyx_n_s_value, __pyx_n_s_time_synth_end, __pyx_n_s_time_end); if (unlikely(!__pyx_tuple__68)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__68);
  __Pyx_GIVEREF(__pyx_tuple__68);
  __pyx_codeobj__69 = (PyObject*)__Pyx_PyCode_New(1, 0, 19, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__68, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_gestural_score_to_audio, 682, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__69)) __PYX_ERR(0, 682, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":725
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_tract_sequence( args ):             # <<<<<<<<<<<<<<
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):
 */
  __pyx_tuple__70 = PyTuple_Pack(7, __pyx_n_s_args, __pyx_n_s_ges_file_path, __pyx_n_s_tract_file_path, __pyx_n_s_return_sequence, __pyx_n_s_gesFileName, __pyx_n_s_tractSequenceFileName, __pyx_n_s_value); if (unlikely(!__pyx_tuple__70)) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__70);
  __Pyx_GIVEREF(__pyx_tuple__70);
  __pyx_codeobj__71 = (PyObject*)__Pyx_PyCode_New(1, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__70, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_gestural_score_to_tract_sequenc, 725, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__71)) __PYX_ERR(0, 725, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":742
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _segment_sequence_to_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):
 */
  __pyx_tuple__72 = PyTuple_Pack(8, __pyx_n_s_args, __pyx_n_s_seg_file_path, __pyx_n_s_ges_file_path, __pyx_n_s_verbose, __pyx_n_s_segFileName, __pyx_n_s_gesFileName, __pyx_n_s_enableConsoleOutput, __pyx_n_s_value); if (unlikely(!__pyx_tuple__72)) __PYX_ERR(0, 742, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__72);
  __Pyx_GIVEREF(__pyx_tuple__72);
  __pyx_codeobj__73 = (PyObject*)__Pyx_PyCode_New(1, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__72, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_segment_sequence_to_gestural_sc, 742, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__73)) __PYX_ERR(0, 742, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":758
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _synth_block( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:
 */
  __pyx_tuple__74 = PyTuple_Pack(12, __pyx_n_s_args, __pyx_n_s_motor_sequence, __pyx_n_s_state_samples, __pyx_n_s_verbose, __pyx_n_s_constants, __pyx_n_s_numFrames, __pyx_n_s_tractParams, __pyx_n_s_glottisParams, __pyx_n_s_frameStep_samples, __pyx_n_s_audio, __pyx_n_s_enableConsoleOutput, __pyx_n_s_value); if (unlikely(!__pyx_tuple__74)) __PYX_ERR(0, 758, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__74);
  __Pyx_GIVEREF(__pyx_tuple__74);
  __pyx_codeobj__75 = (PyObject*)__Pyx_PyCode_New(1, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__74, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_synth_block, 758, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__75)) __PYX_ERR(0, 758, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":774
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 */
  __pyx_tuple__76 = PyTuple_Pack(12, __pyx_n_s_args, __pyx_n_s_motor_sequence_data, __pyx_n_s_audio_file_path, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_verbose, __pyx_n_s_tract_file_path, __pyx_n_s_motor_sequence, __pyx_n_s_motor_score, __pyx_n_s_audio, __pyx_n_s_constants); if (unlikely(!__pyx_tuple__76)) __PYX_ERR(0, 774, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__76);
  __Pyx_GIVEREF(__pyx_tuple__76);
  __pyx_codeobj__77 = (PyObject*)__Pyx_PyCode_New(1, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__76, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_audio, 774, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__77)) __PYX_ERR(0, 774, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":807
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_spectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */
  __pyx_tuple__78 = PyTuple_Pack(12, __pyx_n_s_args, __pyx_n_s_motor_sequence_data, __pyx_n_s_audio_file_path, __pyx_n_s_spectrogram_file_path, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_spectrogram_kwargs, __pyx_n_s_verbose, __pyx_n_s_audio_args, __pyx_n_s_audio, __pyx_n_s_spectrogram); if (unlikely(!__pyx_tuple__78)) __PYX_ERR(0, 807, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__78);
  __Pyx_GIVEREF(__pyx_tuple__78);
  __pyx_codeobj__79 = (PyObject*)__Pyx_PyCode_New(1, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__78, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_motor_sequence_to_spectrogram, 807, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__79)) __PYX_ERR(0, 807, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":826
 * 	return spectrogram
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_melspectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */
  __pyx_tuple__80 = PyTuple_Pack(15, __pyx_n_s_args, __pyx_n_s_motor_sequence_data, __pyx_n_s_audio_file_path, __pyx_n_s_melspectrogram_file_path, __pyx_n_s_save_file, __pyx_n_s_normalize_audio, __pyx_n_s_sr, __pyx_n_s_log_scale, __pyx_n_s_spectrogram_kwargs, __pyx_n_s_melspectrogram_kwargs, __pyx_n_s_verbose, __pyx_n_s_audio_args, __pyx_n_s_audio, __pyx_n_s_spectrogram, __pyx_n_s_melspectrogram); if (unlikely(!__pyx_tuple__80)) __PYX_ERR(0, 826, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__80);
  __Pyx_GIVEREF(__pyx_tuple__80);
  __pyx_codeobj__81 = (PyObject*)__Pyx_PyCode_New(1, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__80, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_motor_sequence_to_melspectrogra, 826, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__81)) __PYX_ERR(0, 826, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":902
 * #	return mfcc
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_limited_tract_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state = args
 * 	constants = get_constants()
 */
  __pyx_tuple__82 = PyTuple_Pack(5, __pyx_n_s_args, __pyx_n_s_tract_state, __pyx_n_s_constants, __pyx_n_s_inTractParams, __pyx_n_s_outTractParams); if (unlikely(!__pyx_tuple__82)) __PYX_ERR(0, 902, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__82);
  __Pyx_GIVEREF(__pyx_tuple__82);
  __pyx_codeobj__83 = (PyObject*)__Pyx_PyCode_New(1, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__82, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_state_to_limited_tract_st, 902, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__83)) __PYX_ERR(0, 902, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":910
 * 	return outTractParams
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_svg( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :
 */
  __pyx_tuple__84 = PyTuple_Pack(13, __pyx_n_s_args, __pyx_n_s_motor_sequence, __pyx_n_s_svg_dir, __pyx_n_s_fps, __pyx_n_s_tract_file_path, __pyx_n_s_constants, __pyx_n_s_tractParams, __pyx_n_s_resampled_index, __pyx_n_s_resampled_tract_states, __pyx_n_s_pair, __pyx_n_s_index, __pyx_n_s_tract_state, __pyx_n_s_fileName); if (unlikely(!__pyx_tuple__84)) __PYX_ERR(0, 910, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__84);
  __Pyx_GIVEREF(__pyx_tuple__84);
  __pyx_codeobj__85 = (PyObject*)__Pyx_PyCode_New(1, 0, 13, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__84, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_sequence_to_svg, 910, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__85)) __PYX_ERR(0, 910, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":936
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_transfer_function( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args
 * 	magnitude_spectrum = None
 */
  __pyx_tuple__86 = PyTuple_Pack(12, __pyx_n_s_args, __pyx_n_s_tract_state, __pyx_n_s_n_spectrum_samples, __pyx_n_s_save_magnitude_spectrum, __pyx_n_s_save_phase_spectrum, __pyx_n_s_magnitude_spectrum, __pyx_n_s_phase_spectrum, __pyx_n_s_numSpectrumSamples, __pyx_n_s_tractParams, __pyx_n_s_magnitude, __pyx_n_s_phase_rad, __pyx_n_s_value); if (unlikely(!__pyx_tuple__86)) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__86);
  __Pyx_GIVEREF(__pyx_tuple__86);
  __pyx_codeobj__87 = (PyObject*)__Pyx_PyCode_New(1, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__86, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_state_to_transfer_functio, 936, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__87)) __PYX_ERR(0, 936, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":956
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_tube_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args
 * 	tube_length = None
 */
  __pyx_tuple__88 = PyTuple_Pack(22, __pyx_n_s_args, __pyx_n_s_tract_state, __pyx_n_s_save_tube_length, __pyx_n_s_save_tube_area, __pyx_n_s_save_tube_articulator, __pyx_n_s_save_incisor_position, __pyx_n_s_save_tongue_tip_side_elevation, __pyx_n_s_save_velum_opening, __pyx_n_s_tube_length, __pyx_n_s_tube_area, __pyx_n_s_tube_articulator, __pyx_n_s_incisor_position, __pyx_n_s_tongue_tip_side_elevation, __pyx_n_s_velum_opening, __pyx_n_s_constants, __pyx_n_s_tractParams, __pyx_n_s_tubeLength_cm, __pyx_n_s_tubeArea_cm2, __pyx_n_s_tubeArticulator, __pyx_n_s_incisorPos_cm, __pyx_n_s_tongueTipSideElevation, __pyx_n_s_velumOpening_cm2); if (unlikely(!__pyx_tuple__88)) __PYX_ERR(0, 956, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__88);
  __Pyx_GIVEREF(__pyx_tuple__88);
  __pyx_codeobj__89 = (PyObject*)__Pyx_PyCode_New(1, 0, 22, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__88, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_tract_state_to_tube_state, 956, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__89)) __PYX_ERR(0, 956, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":1001
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):             # <<<<<<<<<<<<<<
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 */
  __pyx_tuple__90 = PyTuple_Pack(10, __pyx_n_s_function, __pyx_n_s_args, __pyx_n_s_return_data, __pyx_n_s_workers, __pyx_n_s_pool, __pyx_n_s_tasks, __pyx_n_s_data, __pyx_n_s_x, __pyx_n_s_genexpr, __pyx_n_s_genexpr); if (unlikely(!__pyx_tuple__90)) __PYX_ERR(0, 1001, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__90);
  __Pyx_GIVEREF(__pyx_tuple__90);
  __pyx_codeobj__91 = (PyObject*)__Pyx_PyCode_New(4, 0, 10, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__90, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_run_multiprocessing, 1001, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__91)) __PYX_ERR(0, 1001, __pyx_L1_error)

  /* "VocalTractLab/VocalTractLabApi.pyx":1018
 * 	return data
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _worker( args ):             # <<<<<<<<<<<<<<
 * 	function, arg = args
 * 	return function( arg )
 */
  __pyx_tuple__92 = PyTuple_Pack(3, __pyx_n_s_args, __pyx_n_s_function, __pyx_n_s_arg); if (unlikely(!__pyx_tuple__92)) __PYX_ERR(0, 1018, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__92);
  __Pyx_GIVEREF(__pyx_tuple__92);
  __pyx_codeobj__93 = (PyObject*)__Pyx_PyCode_New(1, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__92, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_VocalTractLab_VocalTractLabApi_p, __pyx_n_s_worker, 1018, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__93)) __PYX_ERR(0, 1018, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void) {
  __pyx_umethod_PyString_Type_encode.type = (PyObject*)&PyString_Type;
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_2 = PyInt_FromLong(2); if (unlikely(!__pyx_int_2)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_60 = PyInt_FromLong(60); if (unlikely(!__pyx_int_60)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_400 = PyInt_FromLong(400); if (unlikely(!__pyx_int_400)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_8192 = PyInt_FromLong(8192); if (unlikely(!__pyx_int_8192)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_16000 = PyInt_FromLong(16000L); if (unlikely(!__pyx_int_16000)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_neg_1 = PyInt_FromLong(-1); if (unlikely(!__pyx_int_neg_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_modinit_global_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_import_code(void); /*proto*/

static int __Pyx_modinit_global_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_global_init_code", 0);
  /*--- Global init code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_export_code", 0);
  /*--- Variable export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_export_code", 0);
  /*--- Function export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_type_init_code(void) {
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
  /*--- Type init code ---*/
  if (PyType_Ready(&__pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing) < 0) __PYX_ERR(0, 1001, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing.tp_dictoffset && __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
  }
  __pyx_ptype_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing = &__pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct___run_multiprocessing;
  if (PyType_Ready(&__pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr) < 0) __PYX_ERR(0, 1005, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr.tp_dictoffset && __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
  }
  __pyx_ptype_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr = &__pyx_type_13VocalTractLab_16VocalTractLabApi___pyx_scope_struct_1_genexpr;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_type_import_code(void) {
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_import_code", 0);
  /*--- Type import code ---*/
  __pyx_t_1 = PyImport_ImportModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_ptype_7cpython_4type_type = __Pyx_ImportType(__pyx_t_1, __Pyx_BUILTIN_MODULE_NAME, "type", 
  #if defined(PYPY_VERSION_NUM) && PYPY_VERSION_NUM < 0x050B0000
  sizeof(PyTypeObject),
  #else
  sizeof(PyHeapTypeObject),
  #endif
  __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_7cpython_4type_type) __PYX_ERR(2, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyImport_ImportModule("numpy"); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_ptype_5numpy_dtype = __Pyx_ImportType(__pyx_t_1, "numpy", "dtype", sizeof(PyArray_Descr), __Pyx_ImportType_CheckSize_Ignore);
   if (!__pyx_ptype_5numpy_dtype) __PYX_ERR(1, 200, __pyx_L1_error)
  __pyx_ptype_5numpy_flatiter = __Pyx_ImportType(__pyx_t_1, "numpy", "flatiter", sizeof(PyArrayIterObject), __Pyx_ImportType_CheckSize_Ignore);
   if (!__pyx_ptype_5numpy_flatiter) __PYX_ERR(1, 223, __pyx_L1_error)
  __pyx_ptype_5numpy_broadcast = __Pyx_ImportType(__pyx_t_1, "numpy", "broadcast", sizeof(PyArrayMultiIterObject), __Pyx_ImportType_CheckSize_Ignore);
   if (!__pyx_ptype_5numpy_broadcast) __PYX_ERR(1, 227, __pyx_L1_error)
  __pyx_ptype_5numpy_ndarray = __Pyx_ImportType(__pyx_t_1, "numpy", "ndarray", sizeof(PyArrayObject), __Pyx_ImportType_CheckSize_Ignore);
   if (!__pyx_ptype_5numpy_ndarray) __PYX_ERR(1, 239, __pyx_L1_error)
  __pyx_ptype_5numpy_generic = __Pyx_ImportType(__pyx_t_1, "numpy", "generic", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_generic) __PYX_ERR(1, 771, __pyx_L1_error)
  __pyx_ptype_5numpy_number = __Pyx_ImportType(__pyx_t_1, "numpy", "number", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_number) __PYX_ERR(1, 773, __pyx_L1_error)
  __pyx_ptype_5numpy_integer = __Pyx_ImportType(__pyx_t_1, "numpy", "integer", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_integer) __PYX_ERR(1, 775, __pyx_L1_error)
  __pyx_ptype_5numpy_signedinteger = __Pyx_ImportType(__pyx_t_1, "numpy", "signedinteger", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_signedinteger) __PYX_ERR(1, 777, __pyx_L1_error)
  __pyx_ptype_5numpy_unsignedinteger = __Pyx_ImportType(__pyx_t_1, "numpy", "unsignedinteger", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_unsignedinteger) __PYX_ERR(1, 779, __pyx_L1_error)
  __pyx_ptype_5numpy_inexact = __Pyx_ImportType(__pyx_t_1, "numpy", "inexact", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_inexact) __PYX_ERR(1, 781, __pyx_L1_error)
  __pyx_ptype_5numpy_floating = __Pyx_ImportType(__pyx_t_1, "numpy", "floating", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_floating) __PYX_ERR(1, 783, __pyx_L1_error)
  __pyx_ptype_5numpy_complexfloating = __Pyx_ImportType(__pyx_t_1, "numpy", "complexfloating", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_complexfloating) __PYX_ERR(1, 785, __pyx_L1_error)
  __pyx_ptype_5numpy_flexible = __Pyx_ImportType(__pyx_t_1, "numpy", "flexible", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_flexible) __PYX_ERR(1, 787, __pyx_L1_error)
  __pyx_ptype_5numpy_character = __Pyx_ImportType(__pyx_t_1, "numpy", "character", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_5numpy_character) __PYX_ERR(1, 789, __pyx_L1_error)
  __pyx_ptype_5numpy_ufunc = __Pyx_ImportType(__pyx_t_1, "numpy", "ufunc", sizeof(PyUFuncObject), __Pyx_ImportType_CheckSize_Ignore);
   if (!__pyx_ptype_5numpy_ufunc) __PYX_ERR(1, 827, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_variable_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_import_code", 0);
  /*--- Variable import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_import_code", 0);
  /*--- Function import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}


#ifndef CYTHON_NO_PYINIT_EXPORT
#define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#elif PY_MAJOR_VERSION < 3
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" void
#else
#define __Pyx_PyMODINIT_FUNC void
#endif
#else
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" PyObject *
#else
#define __Pyx_PyMODINIT_FUNC PyObject *
#endif
#endif


#if PY_MAJOR_VERSION < 3
__Pyx_PyMODINIT_FUNC initVocalTractLabApi(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC initVocalTractLabApi(void)
#else
__Pyx_PyMODINIT_FUNC PyInit_VocalTractLabApi(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC PyInit_VocalTractLabApi(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static CYTHON_SMALL_CODE int __Pyx_check_single_interpreter(void) {
    #if PY_VERSION_HEX >= 0x030700A1
    static PY_INT64_T main_interpreter_id = -1;
    PY_INT64_T current_id = PyInterpreterState_GetID(PyThreadState_Get()->interp);
    if (main_interpreter_id == -1) {
        main_interpreter_id = current_id;
        return (unlikely(current_id == -1)) ? -1 : 0;
    } else if (unlikely(main_interpreter_id != current_id))
    #else
    static PyInterpreterState *main_interpreter = NULL;
    PyInterpreterState *current_interpreter = PyThreadState_Get()->interp;
    if (!main_interpreter) {
        main_interpreter = current_interpreter;
    } else if (unlikely(main_interpreter != current_interpreter))
    #endif
    {
        PyErr_SetString(
            PyExc_ImportError,
            "Interpreter change detected - this module can only be loaded into one interpreter per process.");
        return -1;
    }
    return 0;
}
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name, int allow_none) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        if (allow_none || value != Py_None) {
            result = PyDict_SetItemString(moddict, to_name, value);
        }
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static CYTHON_SMALL_CODE PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__Pyx_check_single_interpreter())
        return NULL;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__", 0) < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static CYTHON_SMALL_CODE int __pyx_pymod_exec_VocalTractLabApi(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m) {
    if (__pyx_m == __pyx_pyinit_module) return 0;
    PyErr_SetString(PyExc_RuntimeError, "Module 'VocalTractLabApi' has already been imported. Re-initialisation is not supported.");
    return -1;
  }
  #elif PY_MAJOR_VERSION >= 3
  if (__pyx_m) return __Pyx_NewRef(__pyx_m);
  #endif
  #if CYTHON_REFNANNY
__Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
if (!__Pyx_RefNanny) {
  PyErr_Clear();
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
  if (!__Pyx_RefNanny)
      Py_FatalError("failed to import 'refnanny' module");
}
#endif
  __Pyx_RefNannySetupContext("__Pyx_PyMODINIT_FUNC PyInit_VocalTractLabApi(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pxy_PyFrame_Initialize_Offsets
  __Pxy_PyFrame_Initialize_Offsets();
  #endif
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(WITH_THREAD) && PY_VERSION_HEX < 0x030700F0 && defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  PyEval_InitThreads();
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("VocalTractLabApi", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_b);
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_cython_runtime);
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_VocalTractLab__VocalTractLabApi) {
    if (PyObject_SetAttr(__pyx_m, __pyx_n_s_name_2, __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "VocalTractLab.VocalTractLabApi")) {
      if (unlikely(PyDict_SetItemString(modules, "VocalTractLab.VocalTractLabApi", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global type/function init code ---*/
  (void)__Pyx_modinit_global_init_code();
  (void)__Pyx_modinit_variable_export_code();
  (void)__Pyx_modinit_function_export_code();
  if (unlikely(__Pyx_modinit_type_init_code() < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
  if (unlikely(__Pyx_modinit_type_import_code() < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
  (void)__Pyx_modinit_variable_import_code();
  (void)__Pyx_modinit_function_import_code();
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "VocalTractLab/VocalTractLabApi.pyx":36
 * #cimport cVocalTractLabApi # Function defs could be placed here
 * 
 * import numpy as np             # <<<<<<<<<<<<<<
 * cimport numpy as np
 * import pandas as pd
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 36, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_1) < 0) __PYX_ERR(0, 36, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":38
 * import numpy as np
 * cimport numpy as np
 * import pandas as pd             # <<<<<<<<<<<<<<
 * import ctypes
 * import os
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_pandas, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_pd, __pyx_t_1) < 0) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":39
 * cimport numpy as np
 * import pandas as pd
 * import ctypes             # <<<<<<<<<<<<<<
 * import os
 * import warnings
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_ctypes, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_ctypes, __pyx_t_1) < 0) __PYX_ERR(0, 39, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":40
 * import pandas as pd
 * import ctypes
 * import os             # <<<<<<<<<<<<<<
 * import warnings
 * import time
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_os, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_os, __pyx_t_1) < 0) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":41
 * import ctypes
 * import os
 * import warnings             # <<<<<<<<<<<<<<
 * import time
 * 
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_warnings, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_warnings, __pyx_t_1) < 0) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":42
 * import os
 * import warnings
 * import time             # <<<<<<<<<<<<<<
 * 
 * from libcpp cimport bool
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_time, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_time, __pyx_t_1) < 0) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":46
 * from libcpp cimport bool
 * 
 * import logging             # <<<<<<<<<<<<<<
 * 
 * logging.basicConfig()
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_logging, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_logging, __pyx_t_1) < 0) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":48
 * import logging
 * 
 * logging.basicConfig()             # <<<<<<<<<<<<<<
 * log = logging.getLogger(__name__)
 * log.setLevel(logging.WARNING)
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_logging); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_basicConfig); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":49
 * 
 * logging.basicConfig()
 * log = logging.getLogger(__name__)             # <<<<<<<<<<<<<<
 * log.setLevel(logging.WARNING)
 * 
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_logging); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_getLogger); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_log, __pyx_t_3) < 0) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":50
 * logging.basicConfig()
 * log = logging.getLogger(__name__)
 * log.setLevel(logging.WARNING)             # <<<<<<<<<<<<<<
 * 
 * import atexit
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_log); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_setLevel); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_logging); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_WARNING); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":52
 * log.setLevel(logging.WARNING)
 * 
 * import atexit             # <<<<<<<<<<<<<<
 * 
 * from cpython.pycapsule cimport *
 */
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_atexit, 0, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_atexit, __pyx_t_3) < 0) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":59
 * 
 * 
 * from VocalTractLab.tract_sequence import Sub_Glottal_Sequence, Supra_Glottal_Sequence, Motor_Sequence             # <<<<<<<<<<<<<<
 * from VocalTractLab.targets import Motor_Score
 * from VocalTractLab.frequency_domain import Transfer_Function
 */
  __pyx_t_3 = PyList_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_n_s_Sub_Glottal_Sequence);
  __Pyx_GIVEREF(__pyx_n_s_Sub_Glottal_Sequence);
  PyList_SET_ITEM(__pyx_t_3, 0, __pyx_n_s_Sub_Glottal_Sequence);
  __Pyx_INCREF(__pyx_n_s_Supra_Glottal_Sequence);
  __Pyx_GIVEREF(__pyx_n_s_Supra_Glottal_Sequence);
  PyList_SET_ITEM(__pyx_t_3, 1, __pyx_n_s_Supra_Glottal_Sequence);
  __Pyx_INCREF(__pyx_n_s_Motor_Sequence);
  __Pyx_GIVEREF(__pyx_n_s_Motor_Sequence);
  PyList_SET_ITEM(__pyx_t_3, 2, __pyx_n_s_Motor_Sequence);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_VocalTractLab_tract_sequence, __pyx_t_3, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_Sub_Glottal_Sequence); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Sub_Glottal_Sequence, __pyx_t_3) < 0) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_Supra_Glottal_Sequence); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Supra_Glottal_Sequence, __pyx_t_3) < 0) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_Motor_Sequence); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Motor_Sequence, __pyx_t_3) < 0) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":60
 * 
 * from VocalTractLab.tract_sequence import Sub_Glottal_Sequence, Supra_Glottal_Sequence, Motor_Sequence
 * from VocalTractLab.targets import Motor_Score             # <<<<<<<<<<<<<<
 * from VocalTractLab.frequency_domain import Transfer_Function
 * from VocalTractLab.function_tools import save, load
 */
  __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_n_s_Motor_Score);
  __Pyx_GIVEREF(__pyx_n_s_Motor_Score);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_Motor_Score);
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_VocalTractLab_targets, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_Motor_Score); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Motor_Score, __pyx_t_2) < 0) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":61
 * from VocalTractLab.tract_sequence import Sub_Glottal_Sequence, Supra_Glottal_Sequence, Motor_Sequence
 * from VocalTractLab.targets import Motor_Score
 * from VocalTractLab.frequency_domain import Transfer_Function             # <<<<<<<<<<<<<<
 * from VocalTractLab.function_tools import save, load
 * from VocalTractLab.tube_states import Tube_State
 */
  __pyx_t_3 = PyList_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_n_s_Transfer_Function);
  __Pyx_GIVEREF(__pyx_n_s_Transfer_Function);
  PyList_SET_ITEM(__pyx_t_3, 0, __pyx_n_s_Transfer_Function);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_VocalTractLab_frequency_domain, __pyx_t_3, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_Transfer_Function); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Transfer_Function, __pyx_t_3) < 0) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":62
 * from VocalTractLab.targets import Motor_Score
 * from VocalTractLab.frequency_domain import Transfer_Function
 * from VocalTractLab.function_tools import save, load             # <<<<<<<<<<<<<<
 * from VocalTractLab.tube_states import Tube_State
 * import VocalTractLab.audio_tools as AT
 */
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 62, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_n_s_save);
  __Pyx_GIVEREF(__pyx_n_s_save);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_save);
  __Pyx_INCREF(__pyx_n_s_load);
  __Pyx_GIVEREF(__pyx_n_s_load);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_n_s_load);
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_VocalTractLab_function_tools, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 62, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_save); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 62, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_save, __pyx_t_2) < 0) __PYX_ERR(0, 62, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_load); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 62, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_load, __pyx_t_2) < 0) __PYX_ERR(0, 62, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":63
 * from VocalTractLab.frequency_domain import Transfer_Function
 * from VocalTractLab.function_tools import save, load
 * from VocalTractLab.tube_states import Tube_State             # <<<<<<<<<<<<<<
 * import VocalTractLab.audio_tools as AT
 * import VocalTractLab.function_tools as FT
 */
  __pyx_t_3 = PyList_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_n_s_Tube_State);
  __Pyx_GIVEREF(__pyx_n_s_Tube_State);
  PyList_SET_ITEM(__pyx_t_3, 0, __pyx_n_s_Tube_State);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_VocalTractLab_tube_states, __pyx_t_3, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_Tube_State); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Tube_State, __pyx_t_3) < 0) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":64
 * from VocalTractLab.function_tools import save, load
 * from VocalTractLab.tube_states import Tube_State
 * import VocalTractLab.audio_tools as AT             # <<<<<<<<<<<<<<
 * import VocalTractLab.function_tools as FT
 * 
 */
  __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_n_s__16);
  __Pyx_GIVEREF(__pyx_n_s__16);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s__16);
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_VocalTractLab_audio_tools, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_AT, __pyx_t_3) < 0) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":65
 * from VocalTractLab.tube_states import Tube_State
 * import VocalTractLab.audio_tools as AT
 * import VocalTractLab.function_tools as FT             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_3 = PyList_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_n_s__16);
  __Pyx_GIVEREF(__pyx_n_s__16);
  PyList_SET_ITEM(__pyx_t_3, 0, __pyx_n_s__16);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_VocalTractLab_function_tools, __pyx_t_3, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_FT, __pyx_t_2) < 0) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":69
 * 
 * 
 * import librosa             # <<<<<<<<<<<<<<
 * import multiprocessing as mp
 * import tqdm
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_librosa, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_librosa, __pyx_t_2) < 0) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":70
 * 
 * import librosa
 * import multiprocessing as mp             # <<<<<<<<<<<<<<
 * import tqdm
 * import itertools
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_multiprocessing, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_mp, __pyx_t_2) < 0) __PYX_ERR(0, 70, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":71
 * import librosa
 * import multiprocessing as mp
 * import tqdm             # <<<<<<<<<<<<<<
 * import itertools
 * from bs4 import BeautifulSoup
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_tqdm, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tqdm, __pyx_t_2) < 0) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":72
 * import multiprocessing as mp
 * import tqdm
 * import itertools             # <<<<<<<<<<<<<<
 * from bs4 import BeautifulSoup
 * #import copy
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_itertools, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_itertools, __pyx_t_2) < 0) __PYX_ERR(0, 72, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":73
 * import tqdm
 * import itertools
 * from bs4 import BeautifulSoup             # <<<<<<<<<<<<<<
 * #import copy
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_n_s_BeautifulSoup);
  __Pyx_GIVEREF(__pyx_n_s_BeautifulSoup);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_BeautifulSoup);
  __pyx_t_3 = __Pyx_Import(__pyx_n_s_bs4, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_BeautifulSoup); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_BeautifulSoup, __pyx_t_2) < 0) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":234
 * # 		Single core functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def automatic_calculation_of_TRX_and_TRY( bool automatic_calculation = True ):             # <<<<<<<<<<<<<<
 * 	cdef bool automaticCalculation = automatic_calculation
 * 	value = vtlCalcTongueRootAutomatically( automaticCalculation )
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_1automatic_calculation_of_TRX_and_TRY, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_automatic_calculation_of_TRX_and, __pyx_t_3) < 0) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":243
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_version():             # <<<<<<<<<<<<<<
 * 	cdef char version[32]
 * 	vtlGetVersion( version )
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_3get_version, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 243, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_version, __pyx_t_3) < 0) __PYX_ERR(0, 243, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":251
 * 	return version.decode()
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_constants():             # <<<<<<<<<<<<<<
 * 	cdef int audioSamplingRate = -1
 * 	cdef int numTubeSections = -1
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_5get_constants, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 251, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_constants, __pyx_t_3) < 0) __PYX_ERR(0, 251, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":277
 * 	return constants
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_param_info( str params ):             # <<<<<<<<<<<<<<
 * 	if params not in [ 'tract', 'glottis' ]:
 * 		log.warning( 'Unknown key in "get_param_info". Key must be "tract" or "glottis". Returning "tract" infos now.' )
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_7get_param_info, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_param_info, __pyx_t_3) < 0) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":304
 * 	return df
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shape( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_9get_shape, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_shape, __pyx_t_3) < 0) __PYX_ERR(0, 304, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":307
 * 	return get_shapes( shape_list,  params, return_motor_sequence )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_shapes( shape_list, str params = None, return_motor_sequence = True ):             # <<<<<<<<<<<<<<
 * 	shape_list = FT.check_if_list_is_valid( shape_list, str )
 * 	constants = get_constants()
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_11get_shapes, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_shapes, __pyx_t_3) < 0) __PYX_ERR(0, 307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":352
 * 		return Sub_Glottal_Sequence( np.array( sub_glottal_shapes ), name = sub_glottal_sequence_name )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_supra_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_13get_supra_glottal_state, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_supra_glottal_state, __pyx_t_3) < 0) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":355
 * 	return get_param_info( 'tract' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_sub_glottal_state( key ):             # <<<<<<<<<<<<<<
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_15get_sub_glottal_state, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_sub_glottal_state, __pyx_t_3) < 0) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":358
 * 	return get_param_info( 'glottis' )[ key ].to_numpy( dtype = float )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def load_speaker_file( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	_close()
 * 	_initialize( speaker_file_path )
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_17load_speaker_file, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 358, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_load_speaker_file, __pyx_t_3) < 0) __PYX_ERR(0, 358, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":369
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def get_gestural_score_audio_duration( str ges_file_path, return_samples = True ):             # <<<<<<<<<<<<<<
 * 	gesFileName = ges_file_path.encode()
 * 	cdef int numAudioSamples = 0
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_19get_gestural_score_audio_duration, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 369, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_gestural_score_audio_duratio, __pyx_t_3) < 0) __PYX_ERR(0, 369, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":385
 * # 		User mp enabled functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def change_gestural_score(             # <<<<<<<<<<<<<<
 * 	in_ges_file_path_list,
 * 	out_ges_file_path_list,
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_21change_gestural_score, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 385, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_change_gestural_score, __pyx_t_3) < 0) __PYX_ERR(0, 385, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":394
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_audio(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 								audio_file_path_list = None,
 * 								save_file: bool = True,
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_23gestural_score_to_audio, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 394, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gestural_score_to_audio_2, __pyx_t_3) < 0) __PYX_ERR(0, 394, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":414
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def gestural_score_to_tract_sequence(	ges_file_path_list,             # <<<<<<<<<<<<<<
 * 										tract_file_path_list = None,
 * 										return_data: bool = False,
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_25gestural_score_to_tract_sequence, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 414, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gestural_score_to_tract_sequence, __pyx_t_3) < 0) __PYX_ERR(0, 414, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":427
 * 	return tract_sequence_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def segment_sequence_to_gestural_score( seg_file_path_list,             # <<<<<<<<<<<<<<
 * 	                                    ges_file_path_list = None,
 * 	                                    workers: int = None,
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_27segment_sequence_to_gestural_score, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 427, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_segment_sequence_to_gestural_sco, __pyx_t_3) < 0) __PYX_ERR(0, 427, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":440
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_audio( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                         audio_file_path_list = None,
 * 	                         save_file: bool = True,
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_29tract_sequence_to_audio, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_audio_2, __pyx_t_3) < 0) __PYX_ERR(0, 440, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":469
 * 	normalize_audio: int = -1,
 * 	sr: int = 16000,
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,             # <<<<<<<<<<<<<<
 * 	return_data: bool = True,
 * 	workers: int = None,
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_AT); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_standard_16kHz_spectrogram_kwarg); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_k__10 = __pyx_t_2;
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":462
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_spectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_31motor_sequence_to_spectrogram, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_motor_sequence_to_spectrogram_2, __pyx_t_2) < 0) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":504
 * 	sr: int = 16000,
 * 	log_scale = True,
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,             # <<<<<<<<<<<<<<
 * 	melspectrogram_kwargs = AT.standard_16kHz_melspectrogram_80_kwargs,
 * 	return_data: bool = True,
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_AT); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_standard_16kHz_spectrogram_kwarg); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_k__11 = __pyx_t_3;
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":505
 * 	log_scale = True,
 * 	spectrogram_kwargs = AT.standard_16kHz_spectrogram_kwargs,
 * 	melspectrogram_kwargs = AT.standard_16kHz_melspectrogram_80_kwargs,             # <<<<<<<<<<<<<<
 * 	return_data: bool = True,
 * 	workers: int = None,
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_AT); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_standard_16kHz_melspectrogram_80); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_k__12 = __pyx_t_2;
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":496
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def motor_sequence_to_melspectrogram(             # <<<<<<<<<<<<<<
 * 	motor_sequence_list,
 * 	audio_file_path_list = None,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_33motor_sequence_to_melspectrogram, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 496, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_motor_sequence_to_melspectrogram, __pyx_t_2) < 0) __PYX_ERR(0, 496, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":534
 * 	return audio_data_list
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_limited_tract_sequence( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                          workers: int = None,
 * 	                                        ):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_35tract_sequence_to_limited_tract_sequence, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_limited_tract, __pyx_t_2) < 0) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":548
 * 		return limited_supra_glottal_sequence
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_svg( motor_sequence_list,             # <<<<<<<<<<<<<<
 * 	                       svg_dir_list = None,
 * 	                       fps: int = 60,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_37tract_sequence_to_svg, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 548, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_svg_2, __pyx_t_2) < 0) __PYX_ERR(0, 548, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":564
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_transfer_functions( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                                      n_spectrum_samples: int = 8192,
 * 	                                      save_magnitude_spectrum: bool = True,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_39tract_sequence_to_transfer_functions, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_transfer_funct, __pyx_t_2) < 0) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":583
 * 	return transfer_functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def tract_sequence_to_tube_states( motor_sequence,             # <<<<<<<<<<<<<<
 * 	                               save_tube_length: bool = True,
 * 	                               save_tube_area: bool = True,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_41tract_sequence_to_tube_states, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 583, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_tube_states, __pyx_t_2) < 0) __PYX_ERR(0, 583, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":629
 * # 		constructor / destructor functions
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _initialize( str speaker_file_path ):             # <<<<<<<<<<<<<<
 * 	speakerFileName = speaker_file_path.encode()
 * 	value = vtlInitialize( speakerFileName )
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_43_initialize, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_initialize, __pyx_t_2) < 0) __PYX_ERR(0, 629, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":637
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _close():             # <<<<<<<<<<<<<<
 * 	value = vtlClose()
 * 	if value != 0:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_45_close, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 637, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_close, __pyx_t_2) < 0) __PYX_ERR(0, 637, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":659
 * #	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _modify_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	in_ges_file_path, out_ges_file_path = args
 * 	ges_file = open( in_ges_file_path ).read()
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_47_modify_gestural_score, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_modify_gestural_score, __pyx_t_2) < 0) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":669
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_voice_quality( args ):             # <<<<<<<<<<<<<<
 * 	gestural_score_soup, voice_quality_new, voice_quality_old = args
 * 	for element in gestural_score_soup.gestural_score.find( 'gesture_sequence', {'type': 'glottal-shape-gestures'} ):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_49_gestural_score_change_voice_quality, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 669, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gestural_score_change_voice_qua, __pyx_t_2) < 0) __PYX_ERR(0, 669, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":679
 * 	return gestural_score_soup
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_change_duration():             # <<<<<<<<<<<<<<
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_51_gestural_score_change_duration, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 679, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gestural_score_change_duration, __pyx_t_2) < 0) __PYX_ERR(0, 679, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":682
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	time_start = time.time()
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_53_gestural_score_to_audio, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gestural_score_to_audio, __pyx_t_2) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":725
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _gestural_score_to_tract_sequence( args ):             # <<<<<<<<<<<<<<
 * 	ges_file_path, tract_file_path, return_sequence = args
 * 	if not os.path.exists( ges_file_path ):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_55_gestural_score_to_tract_sequence, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gestural_score_to_tract_sequenc, __pyx_t_2) < 0) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":742
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _segment_sequence_to_gestural_score( args ):             # <<<<<<<<<<<<<<
 * 	seg_file_path, ges_file_path, verbose = args
 * 	if not os.path.exists( seg_file_path ):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_57_segment_sequence_to_gestural_score, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 742, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_segment_sequence_to_gestural_sc, __pyx_t_2) < 0) __PYX_ERR(0, 742, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":758
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _synth_block( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, state_samples, verbose = args
 * 	if state_samples == None:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_59_synth_block, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 758, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_synth_block, __pyx_t_2) < 0) __PYX_ERR(0, 758, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":774
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_audio( args ):             # <<<<<<<<<<<<<<
 * 	# Note that returning the number of samples via numSamples is deprecated, use getGesturalScoreAudioDuration instead!
 * 	motor_sequence_data, audio_file_path, save_file, normalize_audio, sr, verbose = args
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_61_tract_sequence_to_audio, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 774, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_audio, __pyx_t_2) < 0) __PYX_ERR(0, 774, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":807
 * 	return audio
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_spectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_63_motor_sequence_to_spectrogram, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 807, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_motor_sequence_to_spectrogram, __pyx_t_2) < 0) __PYX_ERR(0, 807, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":826
 * 	return spectrogram
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _motor_sequence_to_melspectrogram( args ):             # <<<<<<<<<<<<<<
 * 	(
 * 		motor_sequence_data,
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_65_motor_sequence_to_melspectrogram, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 826, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_motor_sequence_to_melspectrogra, __pyx_t_2) < 0) __PYX_ERR(0, 826, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":902
 * #	return mfcc
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_limited_tract_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state = args
 * 	constants = get_constants()
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_67_tract_state_to_limited_tract_state, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 902, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_state_to_limited_tract_st, __pyx_t_2) < 0) __PYX_ERR(0, 902, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":910
 * 	return outTractParams
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_sequence_to_svg( args ):             # <<<<<<<<<<<<<<
 * 	motor_sequence, svg_dir, fps = args
 * 	if isinstance( motor_sequence, str ) :
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_69_tract_sequence_to_svg, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 910, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_sequence_to_svg, __pyx_t_2) < 0) __PYX_ERR(0, 910, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":936
 * 	return
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_transfer_function( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, n_spectrum_samples, save_magnitude_spectrum, save_phase_spectrum = args
 * 	magnitude_spectrum = None
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_71_tract_state_to_transfer_function, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_state_to_transfer_functio, __pyx_t_2) < 0) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":956
 * 	return Transfer_Function( magnitude_spectrum, phase_spectrum, n_spectrum_samples )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _tract_state_to_tube_state( args ):             # <<<<<<<<<<<<<<
 * 	tract_state, save_tube_length, save_tube_area, save_tube_articulator, save_incisor_position, save_tongue_tip_side_elevation, save_velum_opening = args
 * 	tube_length = None
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_73_tract_state_to_tube_state, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 956, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_tract_state_to_tube_state, __pyx_t_2) < 0) __PYX_ERR(0, 956, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1001
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _run_multiprocessing( function, args, return_data, workers ):             # <<<<<<<<<<<<<<
 * 	if workers == None:
 * 		workers = mp.cpu_count()
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_75_run_multiprocessing, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1001, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_run_multiprocessing, __pyx_t_2) < 0) __PYX_ERR(0, 1001, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1018
 * 	return data
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * def _worker( args ):             # <<<<<<<<<<<<<<
 * 	function, arg = args
 * 	return function( arg )
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_13VocalTractLab_16VocalTractLabApi_77_worker, NULL, __pyx_n_s_VocalTractLab_VocalTractLabApi); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1018, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_worker, __pyx_t_2) < 0) __PYX_ERR(0, 1018, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1038
 * 
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * atexit.register( _close )             # <<<<<<<<<<<<<<
 * _initialize( os.path.join( os.path.dirname(__file__), 'speaker/JD3.speaker' ) )
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_atexit); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1038, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_register); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1038, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_close); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1038, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1038, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1039
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * atexit.register( _close )
 * _initialize( os.path.join( os.path.dirname(__file__), 'speaker/JD3.speaker' ) )             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * 
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_initialize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_os); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_path); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_join); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_os); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_path); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_dirname); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_file); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_5);
  __Pyx_INCREF(__pyx_kp_s_speaker_JD3_speaker);
  __Pyx_GIVEREF(__pyx_kp_s_speaker_JD3_speaker);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_kp_s_speaker_JD3_speaker);
  __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1039, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "VocalTractLab/VocalTractLabApi.pyx":1
 * #####################################################################################################################################################             # <<<<<<<<<<<<<<
 * #---------------------------------------------------------------------------------------------------------------------------------------------------#
 * #	- This file is a part of the VocalTractLab Python module PyVTL, see https://github.com/paul-krug/VocalTractLab
 */
  __pyx_t_4 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_4) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "../../../anaconda3/lib/site-packages/numpy/__init__.pxd":1014
 * 
 * 
 * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the unit part of the dtype for a numpy datetime64 object.
 */

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init VocalTractLab.VocalTractLabApi", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    Py_CLEAR(__pyx_m);
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init VocalTractLab.VocalTractLabApi");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule(modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, "RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* PyObjectGetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (__Pyx_PyUnicode_GET_LENGTH(**name) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (__Pyx_PyUnicode_GET_LENGTH(**argname) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = Py_TYPE(func)->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyErrFetchRestore */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
#if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* PyDictVersioning */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
    PyObject **dictptr = NULL;
    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
    if (offset) {
#if CYTHON_COMPILING_IN_CPYTHON
        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
#else
        dictptr = _PyObject_GetDictPtr(obj);
#endif
    }
    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
}
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
        return 0;
    return obj_dict_version == __Pyx_get_object_dict_version(obj);
}
#endif

/* GetModuleGlobalName */
#if CYTHON_USE_DICT_VERSIONS
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
#else
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
#endif
{
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1
    result = _PyDict_GetItem_KnownHash(__pyx_d, name, ((PyASCIIObject *) name)->hash);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    } else if (unlikely(PyErr_Occurred())) {
        return NULL;
    }
#else
    result = PyDict_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
#endif
#else
    result = PyObject_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
    PyErr_Clear();
#endif
    return __Pyx_GetBuiltinName(name);
}

/* PyCFunctionFastCall */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)(void*)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)(void*)meth)) (self, args, nargs);
    }
}
#endif

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = __Pyx_PyFrame_GetLocalsplus(f);
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyObjectCall2Args */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2) {
    PyObject *args, *result = NULL;
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(function)) {
        PyObject *args[2] = {arg1, arg2};
        return __Pyx_PyFunction_FastCall(function, args, 2);
    }
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(function)) {
        PyObject *args[2] = {arg1, arg2};
        return __Pyx_PyCFunction_FastCall(function, args, 2);
    }
    #endif
    args = PyTuple_New(2);
    if (unlikely(!args)) goto done;
    Py_INCREF(arg1);
    PyTuple_SET_ITEM(args, 0, arg1);
    Py_INCREF(arg2);
    PyTuple_SET_ITEM(args, 1, arg2);
    Py_INCREF(function);
    result = __Pyx_PyObject_Call(function, args, NULL);
    Py_DECREF(args);
    Py_DECREF(function);
done:
    return result;
}

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
#if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (__Pyx_PyFastCFunction_Check(func)) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* decode_c_string */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    Py_ssize_t length;
    if (unlikely((start < 0) | (stop < 0))) {
        size_t slen = strlen(cstring);
        if (unlikely(slen > (size_t) PY_SSIZE_T_MAX)) {
            PyErr_SetString(PyExc_OverflowError,
                            "c-string too long to convert to Python");
            return NULL;
        }
        length = (Py_ssize_t) slen;
        if (start < 0) {
            start += length;
            if (start < 0)
                start = 0;
        }
        if (stop < 0)
            stop += length;
    }
    if (unlikely(stop <= start))
        return __Pyx_NewRef(__pyx_empty_unicode);
    length = stop - start;
    cstring += start;
    if (decode_func) {
        return decode_func(cstring, length, errors);
    } else {
        return PyUnicode_Decode(cstring, length, encoding, errors);
    }
}

/* ArgTypeTest */
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (exact) {
        #if PY_MAJOR_VERSION == 2
        if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    }
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
    return 0;
}

/* BytesEquals */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result;
#if CYTHON_USE_UNICODE_INTERNALS
            Py_hash_t hash1, hash2;
            hash1 = ((PyBytesObject*)s1)->ob_shash;
            hash2 = ((PyBytesObject*)s2)->ob_shash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                return (equals == Py_NE);
            }
#endif
            result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
#if PY_MAJOR_VERSION < 3
    PyObject* owned_ref = NULL;
#endif
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
#if PY_MAJOR_VERSION < 3
    if ((s1_is_unicode & (!s2_is_unicode)) && PyString_CheckExact(s2)) {
        owned_ref = PyUnicode_FromObject(s2);
        if (unlikely(!owned_ref))
            return -1;
        s2 = owned_ref;
        s2_is_unicode = 1;
    } else if ((s2_is_unicode & (!s1_is_unicode)) && PyString_CheckExact(s1)) {
        owned_ref = PyUnicode_FromObject(s1);
        if (unlikely(!owned_ref))
            return -1;
        s1 = owned_ref;
        s1_is_unicode = 1;
    } else if (((!s2_is_unicode) & (!s1_is_unicode))) {
        return __Pyx_PyBytes_Equals(s1, s2, equals);
    }
#endif
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length;
        int kind;
        void *data1, *data2;
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        if (length != __Pyx_PyUnicode_GET_LENGTH(s2)) {
            goto return_ne;
        }
#if CYTHON_USE_UNICODE_INTERNALS
        {
            Py_hash_t hash1, hash2;
        #if CYTHON_PEP393_ENABLED
            hash1 = ((PyASCIIObject*)s1)->hash;
            hash2 = ((PyASCIIObject*)s2)->hash;
        #else
            hash1 = ((PyUnicodeObject*)s1)->hash;
            hash2 = ((PyUnicodeObject*)s2)->hash;
        #endif
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                goto return_ne;
            }
        }
#endif
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            #if PY_MAJOR_VERSION < 3
            Py_XDECREF(owned_ref);
            #endif
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        #if PY_MAJOR_VERSION < 3
        Py_XDECREF(owned_ref);
        #endif
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_EQ);
return_ne:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_NE);
#endif
}

/* PyObjectCallNoArg */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || __Pyx_CyFunction_Check(func)))
#else
    if (likely(PyCFunction_Check(func)))
#endif
    {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* None */
static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname) {
    PyErr_Format(PyExc_UnboundLocalError, "local variable '%s' referenced before assignment", varname);
}

/* GetItemInt */
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely(__Pyx_is_valid_index(n, PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely(__Pyx_is_valid_index(n, PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* ObjectGetItem */
#if CYTHON_USE_TYPE_SLOTS
static PyObject *__Pyx_PyObject_GetIndex(PyObject *obj, PyObject* index) {
    PyObject *runerr;
    Py_ssize_t key_value;
    PySequenceMethods *m = Py_TYPE(obj)->tp_as_sequence;
    if (unlikely(!(m && m->sq_item))) {
        PyErr_Format(PyExc_TypeError, "'%.200s' object is not subscriptable", Py_TYPE(obj)->tp_name);
        return NULL;
    }
    key_value = __Pyx_PyIndex_AsSsize_t(index);
    if (likely(key_value != -1 || !(runerr = PyErr_Occurred()))) {
        return __Pyx_GetItemInt_Fast(obj, key_value, 0, 1, 1);
    }
    if (PyErr_GivenExceptionMatches(runerr, PyExc_OverflowError)) {
        PyErr_Clear();
        PyErr_Format(PyExc_IndexError, "cannot fit '%.200s' into an index-sized integer", Py_TYPE(index)->tp_name);
    }
    return NULL;
}
static PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject* key) {
    PyMappingMethods *m = Py_TYPE(obj)->tp_as_mapping;
    if (likely(m && m->mp_subscript)) {
        return m->mp_subscript(obj, key);
    }
    return __Pyx_PyObject_GetIndex(obj, key);
}
#endif

/* ExtTypeTest */
static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type) {
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (likely(__Pyx_TypeCheck(obj, type)))
        return 1;
    PyErr_Format(PyExc_TypeError, "Cannot convert %.200s to %.200s",
                 Py_TYPE(obj)->tp_name, type->tp_name);
    return 0;
}

/* IsLittleEndian */
static CYTHON_INLINE int __Pyx_Is_Little_Endian(void)
{
  union {
    uint32_t u32;
    uint8_t u8[4];
  } S;
  S.u32 = 0x01020304;
  return S.u8[0] == 4;
}

/* BufferFormatCheck */
static void __Pyx_BufFmt_Init(__Pyx_BufFmt_Context* ctx,
                              __Pyx_BufFmt_StackElem* stack,
                              __Pyx_TypeInfo* type) {
  stack[0].field = &ctx->root;
  stack[0].parent_offset = 0;
  ctx->root.type = type;
  ctx->root.name = "buffer dtype";
  ctx->root.offset = 0;
  ctx->head = stack;
  ctx->head->field = &ctx->root;
  ctx->fmt_offset = 0;
  ctx->head->parent_offset = 0;
  ctx->new_packmode = '@';
  ctx->enc_packmode = '@';
  ctx->new_count = 1;
  ctx->enc_count = 0;
  ctx->enc_type = 0;
  ctx->is_complex = 0;
  ctx->is_valid_array = 0;
  ctx->struct_alignment = 0;
  while (type->typegroup == 'S') {
    ++ctx->head;
    ctx->head->field = type->fields;
    ctx->head->parent_offset = 0;
    type = type->fields->type;
  }
}
static int __Pyx_BufFmt_ParseNumber(const char** ts) {
    int count;
    const char* t = *ts;
    if (*t < '0' || *t > '9') {
      return -1;
    } else {
        count = *t++ - '0';
        while (*t >= '0' && *t <= '9') {
            count *= 10;
            count += *t++ - '0';
        }
    }
    *ts = t;
    return count;
}
static int __Pyx_BufFmt_ExpectNumber(const char **ts) {
    int number = __Pyx_BufFmt_ParseNumber(ts);
    if (number == -1)
        PyErr_Format(PyExc_ValueError,\
                     "Does not understand character buffer dtype format string ('%c')", **ts);
    return number;
}
static void __Pyx_BufFmt_RaiseUnexpectedChar(char ch) {
  PyErr_Format(PyExc_ValueError,
               "Unexpected format string character: '%c'", ch);
}
static const char* __Pyx_BufFmt_DescribeTypeChar(char ch, int is_complex) {
  switch (ch) {
    case '?': return "'bool'";
    case 'c': return "'char'";
    case 'b': return "'signed char'";
    case 'B': return "'unsigned char'";
    case 'h': return "'short'";
    case 'H': return "'unsigned short'";
    case 'i': return "'int'";
    case 'I': return "'unsigned int'";
    case 'l': return "'long'";
    case 'L': return "'unsigned long'";
    case 'q': return "'long long'";
    case 'Q': return "'unsigned long long'";
    case 'f': return (is_complex ? "'complex float'" : "'float'");
    case 'd': return (is_complex ? "'complex double'" : "'double'");
    case 'g': return (is_complex ? "'complex long double'" : "'long double'");
    case 'T': return "a struct";
    case 'O': return "Python object";
    case 'P': return "a pointer";
    case 's': case 'p': return "a string";
    case 0: return "end";
    default: return "unparseable format string";
  }
}
static size_t __Pyx_BufFmt_TypeCharToStandardSize(char ch, int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return 2;
    case 'i': case 'I': case 'l': case 'L': return 4;
    case 'q': case 'Q': return 8;
    case 'f': return (is_complex ? 8 : 4);
    case 'd': return (is_complex ? 16 : 8);
    case 'g': {
      PyErr_SetString(PyExc_ValueError, "Python does not define a standard format string size for long double ('g')..");
      return 0;
    }
    case 'O': case 'P': return sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
static size_t __Pyx_BufFmt_TypeCharToNativeSize(char ch, int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(short);
    case 'i': case 'I': return sizeof(int);
    case 'l': case 'L': return sizeof(long);
    #ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(PY_LONG_LONG);
    #endif
    case 'f': return sizeof(float) * (is_complex ? 2 : 1);
    case 'd': return sizeof(double) * (is_complex ? 2 : 1);
    case 'g': return sizeof(long double) * (is_complex ? 2 : 1);
    case 'O': case 'P': return sizeof(void*);
    default: {
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
  }
}
typedef struct { char c; short x; } __Pyx_st_short;
typedef struct { char c; int x; } __Pyx_st_int;
typedef struct { char c; long x; } __Pyx_st_long;
typedef struct { char c; float x; } __Pyx_st_float;
typedef struct { char c; double x; } __Pyx_st_double;
typedef struct { char c; long double x; } __Pyx_st_longdouble;
typedef struct { char c; void *x; } __Pyx_st_void_p;
#ifdef HAVE_LONG_LONG
typedef struct { char c; PY_LONG_LONG x; } __Pyx_st_longlong;
#endif
static size_t __Pyx_BufFmt_TypeCharToAlignment(char ch, CYTHON_UNUSED int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(__Pyx_st_short) - sizeof(short);
    case 'i': case 'I': return sizeof(__Pyx_st_int) - sizeof(int);
    case 'l': case 'L': return sizeof(__Pyx_st_long) - sizeof(long);
#ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(__Pyx_st_longlong) - sizeof(PY_LONG_LONG);
#endif
    case 'f': return sizeof(__Pyx_st_float) - sizeof(float);
    case 'd': return sizeof(__Pyx_st_double) - sizeof(double);
    case 'g': return sizeof(__Pyx_st_longdouble) - sizeof(long double);
    case 'P': case 'O': return sizeof(__Pyx_st_void_p) - sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
/* These are for computing the padding at the end of the struct to align
   on the first member of the struct. This will probably the same as above,
   but we don't have any guarantees.
 */
typedef struct { short x; char c; } __Pyx_pad_short;
typedef struct { int x; char c; } __Pyx_pad_int;
typedef struct { long x; char c; } __Pyx_pad_long;
typedef struct { float x; char c; } __Pyx_pad_float;
typedef struct { double x; char c; } __Pyx_pad_double;
typedef struct { long double x; char c; } __Pyx_pad_longdouble;
typedef struct { void *x; char c; } __Pyx_pad_void_p;
#ifdef HAVE_LONG_LONG
typedef struct { PY_LONG_LONG x; char c; } __Pyx_pad_longlong;
#endif
static size_t __Pyx_BufFmt_TypeCharToPadding(char ch, CYTHON_UNUSED int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(__Pyx_pad_short) - sizeof(short);
    case 'i': case 'I': return sizeof(__Pyx_pad_int) - sizeof(int);
    case 'l': case 'L': return sizeof(__Pyx_pad_long) - sizeof(long);
#ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(__Pyx_pad_longlong) - sizeof(PY_LONG_LONG);
#endif
    case 'f': return sizeof(__Pyx_pad_float) - sizeof(float);
    case 'd': return sizeof(__Pyx_pad_double) - sizeof(double);
    case 'g': return sizeof(__Pyx_pad_longdouble) - sizeof(long double);
    case 'P': case 'O': return sizeof(__Pyx_pad_void_p) - sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
static char __Pyx_BufFmt_TypeCharToGroup(char ch, int is_complex) {
  switch (ch) {
    case 'c':
        return 'H';
    case 'b': case 'h': case 'i':
    case 'l': case 'q': case 's': case 'p':
        return 'I';
    case '?': case 'B': case 'H': case 'I': case 'L': case 'Q':
        return 'U';
    case 'f': case 'd': case 'g':
        return (is_complex ? 'C' : 'R');
    case 'O':
        return 'O';
    case 'P':
        return 'P';
    default: {
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
  }
}
static void __Pyx_BufFmt_RaiseExpected(__Pyx_BufFmt_Context* ctx) {
  if (ctx->head == NULL || ctx->head->field == &ctx->root) {
    const char* expected;
    const char* quote;
    if (ctx->head == NULL) {
      expected = "end";
      quote = "";
    } else {
      expected = ctx->head->field->type->name;
      quote = "'";
    }
    PyErr_Format(PyExc_ValueError,
                 "Buffer dtype mismatch, expected %s%s%s but got %s",
                 quote, expected, quote,
                 __Pyx_BufFmt_DescribeTypeChar(ctx->enc_type, ctx->is_complex));
  } else {
    __Pyx_StructField* field = ctx->head->field;
    __Pyx_StructField* parent = (ctx->head - 1)->field;
    PyErr_Format(PyExc_ValueError,
                 "Buffer dtype mismatch, expected '%s' but got %s in '%s.%s'",
                 field->type->name, __Pyx_BufFmt_DescribeTypeChar(ctx->enc_type, ctx->is_complex),
                 parent->type->name, field->name);
  }
}
static int __Pyx_BufFmt_ProcessTypeChunk(__Pyx_BufFmt_Context* ctx) {
  char group;
  size_t size, offset, arraysize = 1;
  if (ctx->enc_type == 0) return 0;
  if (ctx->head->field->type->arraysize[0]) {
    int i, ndim = 0;
    if (ctx->enc_type == 's' || ctx->enc_type == 'p') {
        ctx->is_valid_array = ctx->head->field->type->ndim == 1;
        ndim = 1;
        if (ctx->enc_count != ctx->head->field->type->arraysize[0]) {
            PyErr_Format(PyExc_ValueError,
                         "Expected a dimension of size %zu, got %zu",
                         ctx->head->field->type->arraysize[0], ctx->enc_count);
            return -1;
        }
    }
    if (!ctx->is_valid_array) {
      PyErr_Format(PyExc_ValueError, "Expected %d dimensions, got %d",
                   ctx->head->field->type->ndim, ndim);
      return -1;
    }
    for (i = 0; i < ctx->head->field->type->ndim; i++) {
      arraysize *= ctx->head->field->type->arraysize[i];
    }
    ctx->is_valid_array = 0;
    ctx->enc_count = 1;
  }
  group = __Pyx_BufFmt_TypeCharToGroup(ctx->enc_type, ctx->is_complex);
  do {
    __Pyx_StructField* field = ctx->head->field;
    __Pyx_TypeInfo* type = field->type;
    if (ctx->enc_packmode == '@' || ctx->enc_packmode == '^') {
      size = __Pyx_BufFmt_TypeCharToNativeSize(ctx->enc_type, ctx->is_complex);
    } else {
      size = __Pyx_BufFmt_TypeCharToStandardSize(ctx->enc_type, ctx->is_complex);
    }
    if (ctx->enc_packmode == '@') {
      size_t align_at = __Pyx_BufFmt_TypeCharToAlignment(ctx->enc_type, ctx->is_complex);
      size_t align_mod_offset;
      if (align_at == 0) return -1;
      align_mod_offset = ctx->fmt_offset % align_at;
      if (align_mod_offset > 0) ctx->fmt_offset += align_at - align_mod_offset;
      if (ctx->struct_alignment == 0)
          ctx->struct_alignment = __Pyx_BufFmt_TypeCharToPadding(ctx->enc_type,
                                                                 ctx->is_complex);
    }
    if (type->size != size || type->typegroup != group) {
      if (type->typegroup == 'C' && type->fields != NULL) {
        size_t parent_offset = ctx->head->parent_offset + field->offset;
        ++ctx->head;
        ctx->head->field = type->fields;
        ctx->head->parent_offset = parent_offset;
        continue;
      }
      if ((type->typegroup == 'H' || group == 'H') && type->size == size) {
      } else {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return -1;
      }
    }
    offset = ctx->head->parent_offset + field->offset;
    if (ctx->fmt_offset != offset) {
      PyErr_Format(PyExc_ValueError,
                   "Buffer dtype mismatch; next field is at offset %" CYTHON_FORMAT_SSIZE_T "d but %" CYTHON_FORMAT_SSIZE_T "d expected",
                   (Py_ssize_t)ctx->fmt_offset, (Py_ssize_t)offset);
      return -1;
    }
    ctx->fmt_offset += size;
    if (arraysize)
      ctx->fmt_offset += (arraysize - 1) * size;
    --ctx->enc_count;
    while (1) {
      if (field == &ctx->root) {
        ctx->head = NULL;
        if (ctx->enc_count != 0) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return -1;
        }
        break;
      }
      ctx->head->field = ++field;
      if (field->type == NULL) {
        --ctx->head;
        field = ctx->head->field;
        continue;
      } else if (field->type->typegroup == 'S') {
        size_t parent_offset = ctx->head->parent_offset + field->offset;
        if (field->type->fields->type == NULL) continue;
        field = field->type->fields;
        ++ctx->head;
        ctx->head->field = field;
        ctx->head->parent_offset = parent_offset;
        break;
      } else {
        break;
      }
    }
  } while (ctx->enc_count);
  ctx->enc_type = 0;
  ctx->is_complex = 0;
  return 0;
}
static PyObject *
__pyx_buffmt_parse_array(__Pyx_BufFmt_Context* ctx, const char** tsp)
{
    const char *ts = *tsp;
    int i = 0, number, ndim;
    ++ts;
    if (ctx->new_count != 1) {
        PyErr_SetString(PyExc_ValueError,
                        "Cannot handle repeated arrays in format string");
        return NULL;
    }
    if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
    ndim = ctx->head->field->type->ndim;
    while (*ts && *ts != ')') {
        switch (*ts) {
            case ' ': case '\f': case '\r': case '\n': case '\t': case '\v':  continue;
            default:  break;
        }
        number = __Pyx_BufFmt_ExpectNumber(&ts);
        if (number == -1) return NULL;
        if (i < ndim && (size_t) number != ctx->head->field->type->arraysize[i])
            return PyErr_Format(PyExc_ValueError,
                        "Expected a dimension of size %zu, got %d",
                        ctx->head->field->type->arraysize[i], number);
        if (*ts != ',' && *ts != ')')
            return PyErr_Format(PyExc_ValueError,
                                "Expected a comma in format string, got '%c'", *ts);
        if (*ts == ',') ts++;
        i++;
    }
    if (i != ndim)
        return PyErr_Format(PyExc_ValueError, "Expected %d dimension(s), got %d",
                            ctx->head->field->type->ndim, i);
    if (!*ts) {
        PyErr_SetString(PyExc_ValueError,
                        "Unexpected end of format string, expected ')'");
        return NULL;
    }
    ctx->is_valid_array = 1;
    ctx->new_count = 1;
    *tsp = ++ts;
    return Py_None;
}
static const char* __Pyx_BufFmt_CheckString(__Pyx_BufFmt_Context* ctx, const char* ts) {
  int got_Z = 0;
  while (1) {
    switch(*ts) {
      case 0:
        if (ctx->enc_type != 0 && ctx->head == NULL) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return NULL;
        }
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        if (ctx->head != NULL) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return NULL;
        }
        return ts;
      case ' ':
      case '\r':
      case '\n':
        ++ts;
        break;
      case '<':
        if (!__Pyx_Is_Little_Endian()) {
          PyErr_SetString(PyExc_ValueError, "Little-endian buffer not supported on big-endian compiler");
          return NULL;
        }
        ctx->new_packmode = '=';
        ++ts;
        break;
      case '>':
      case '!':
        if (__Pyx_Is_Little_Endian()) {
          PyErr_SetString(PyExc_ValueError, "Big-endian buffer not supported on little-endian compiler");
          return NULL;
        }
        ctx->new_packmode = '=';
        ++ts;
        break;
      case '=':
      case '@':
      case '^':
        ctx->new_packmode = *ts++;
        break;
      case 'T':
        {
          const char* ts_after_sub;
          size_t i, struct_count = ctx->new_count;
          size_t struct_alignment = ctx->struct_alignment;
          ctx->new_count = 1;
          ++ts;
          if (*ts != '{') {
            PyErr_SetString(PyExc_ValueError, "Buffer acquisition: Expected '{' after 'T'");
            return NULL;
          }
          if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
          ctx->enc_type = 0;
          ctx->enc_count = 0;
          ctx->struct_alignment = 0;
          ++ts;
          ts_after_sub = ts;
          for (i = 0; i != struct_count; ++i) {
            ts_after_sub = __Pyx_BufFmt_CheckString(ctx, ts);
            if (!ts_after_sub) return NULL;
          }
          ts = ts_after_sub;
          if (struct_alignment) ctx->struct_alignment = struct_alignment;
        }
        break;
      case '}':
        {
          size_t alignment = ctx->struct_alignment;
          ++ts;
          if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
          ctx->enc_type = 0;
          if (alignment && ctx->fmt_offset % alignment) {
            ctx->fmt_offset += alignment - (ctx->fmt_offset % alignment);
          }
        }
        return ts;
      case 'x':
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        ctx->fmt_offset += ctx->new_count;
        ctx->new_count = 1;
        ctx->enc_count = 0;
        ctx->enc_type = 0;
        ctx->enc_packmode = ctx->new_packmode;
        ++ts;
        break;
      case 'Z':
        got_Z = 1;
        ++ts;
        if (*ts != 'f' && *ts != 'd' && *ts != 'g') {
          __Pyx_BufFmt_RaiseUnexpectedChar('Z');
          return NULL;
        }
        CYTHON_FALLTHROUGH;
      case '?': case 'c': case 'b': case 'B': case 'h': case 'H': case 'i': case 'I':
      case 'l': case 'L': case 'q': case 'Q':
      case 'f': case 'd': case 'g':
      case 'O': case 'p':
        if ((ctx->enc_type == *ts) && (got_Z == ctx->is_complex) &&
            (ctx->enc_packmode == ctx->new_packmode) && (!ctx->is_valid_array)) {
          ctx->enc_count += ctx->new_count;
          ctx->new_count = 1;
          got_Z = 0;
          ++ts;
          break;
        }
        CYTHON_FALLTHROUGH;
      case 's':
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        ctx->enc_count = ctx->new_count;
        ctx->enc_packmode = ctx->new_packmode;
        ctx->enc_type = *ts;
        ctx->is_complex = got_Z;
        ++ts;
        ctx->new_count = 1;
        got_Z = 0;
        break;
      case ':':
        ++ts;
        while(*ts != ':') ++ts;
        ++ts;
        break;
      case '(':
        if (!__pyx_buffmt_parse_array(ctx, &ts)) return NULL;
        break;
      default:
        {
          int number = __Pyx_BufFmt_ExpectNumber(&ts);
          if (number == -1) return NULL;
          ctx->new_count = (size_t)number;
        }
    }
  }
}

/* BufferGetAndValidate */
  static CYTHON_INLINE void __Pyx_SafeReleaseBuffer(Py_buffer* info) {
  if (unlikely(info->buf == NULL)) return;
  if (info->suboffsets == __Pyx_minusones) info->suboffsets = NULL;
  __Pyx_ReleaseBuffer(info);
}
static void __Pyx_ZeroBuffer(Py_buffer* buf) {
  buf->buf = NULL;
  buf->obj = NULL;
  buf->strides = __Pyx_zeros;
  buf->shape = __Pyx_zeros;
  buf->suboffsets = __Pyx_minusones;
}
static int __Pyx__GetBufferAndValidate(
        Py_buffer* buf, PyObject* obj,  __Pyx_TypeInfo* dtype, int flags,
        int nd, int cast, __Pyx_BufFmt_StackElem* stack)
{
  buf->buf = NULL;
  if (unlikely(__Pyx_GetBuffer(obj, buf, flags) == -1)) {
    __Pyx_ZeroBuffer(buf);
    return -1;
  }
  if (unlikely(buf->ndim != nd)) {
    PyErr_Format(PyExc_ValueError,
                 "Buffer has wrong number of dimensions (expected %d, got %d)",
                 nd, buf->ndim);
    goto fail;
  }
  if (!cast) {
    __Pyx_BufFmt_Context ctx;
    __Pyx_BufFmt_Init(&ctx, stack, dtype);
    if (!__Pyx_BufFmt_CheckString(&ctx, buf->format)) goto fail;
  }
  if (unlikely((size_t)buf->itemsize != dtype->size)) {
    PyErr_Format(PyExc_ValueError,
      "Item size of buffer (%" CYTHON_FORMAT_SSIZE_T "d byte%s) does not match size of '%s' (%" CYTHON_FORMAT_SSIZE_T "d byte%s)",
      buf->itemsize, (buf->itemsize > 1) ? "s" : "",
      dtype->name, (Py_ssize_t)dtype->size, (dtype->size > 1) ? "s" : "");
    goto fail;
  }
  if (buf->suboffsets == NULL) buf->suboffsets = __Pyx_minusones;
  return 0;
fail:;
  __Pyx_SafeReleaseBuffer(buf);
  return -1;
}

/* BufferIndexError */
  static void __Pyx_RaiseBufferIndexError(int axis) {
  PyErr_Format(PyExc_IndexError,
     "Out of bounds on buffer access (axis %d)", axis);
}

/* PyObjectSetAttrStr */
  #if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_setattro))
        return tp->tp_setattro(obj, attr_name, value);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_setattr))
        return tp->tp_setattr(obj, PyString_AS_STRING(attr_name), value);
#endif
    return PyObject_SetAttr(obj, attr_name, value);
}
#endif

/* DictGetItem */
  #if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key) {
    PyObject *value;
    value = PyDict_GetItemWithError(d, key);
    if (unlikely(!value)) {
        if (!PyErr_Occurred()) {
            if (unlikely(PyTuple_Check(key))) {
                PyObject* args = PyTuple_Pack(1, key);
                if (likely(args)) {
                    PyErr_SetObject(PyExc_KeyError, args);
                    Py_DECREF(args);
                }
            } else {
                PyErr_SetObject(PyExc_KeyError, key);
            }
        }
        return NULL;
    }
    Py_INCREF(value);
    return value;
}
#endif

/* StringJoin */
  #if !CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyBytes_Join(PyObject* sep, PyObject* values) {
    return PyObject_CallMethodObjArgs(sep, __pyx_n_s_join, values, NULL);
}
#endif

/* UnpackUnboundCMethod */
  static int __Pyx_TryUnpackUnboundCMethod(__Pyx_CachedCFunction* target) {
    PyObject *method;
    method = __Pyx_PyObject_GetAttrStr(target->type, *target->method_name);
    if (unlikely(!method))
        return -1;
    target->method = method;
#if CYTHON_COMPILING_IN_CPYTHON
    #if PY_MAJOR_VERSION >= 3
    if (likely(__Pyx_TypeCheck(method, &PyMethodDescr_Type)))
    #endif
    {
        PyMethodDescrObject *descr = (PyMethodDescrObject*) method;
        target->func = descr->d_method->ml_meth;
        target->flag = descr->d_method->ml_flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_STACKLESS);
    }
#endif
    return 0;
}

/* CallUnboundCMethod0 */
  static PyObject* __Pyx__CallUnboundCMethod0(__Pyx_CachedCFunction* cfunc, PyObject* self) {
    PyObject *args, *result = NULL;
    if (unlikely(!cfunc->method) && unlikely(__Pyx_TryUnpackUnboundCMethod(cfunc) < 0)) return NULL;
#if CYTHON_ASSUME_SAFE_MACROS
    args = PyTuple_New(1);
    if (unlikely(!args)) goto bad;
    Py_INCREF(self);
    PyTuple_SET_ITEM(args, 0, self);
#else
    args = PyTuple_Pack(1, self);
    if (unlikely(!args)) goto bad;
#endif
    result = __Pyx_PyObject_Call(cfunc->method, args, NULL);
    Py_DECREF(args);
bad:
    return result;
}

/* RaiseTooManyValuesToUnpack */
  static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
  static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* IterFinish */
  static CYTHON_INLINE int __Pyx_IterFinish(void) {
#if CYTHON_FAST_THREAD_STATE
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject* exc_type = tstate->curexc_type;
    if (unlikely(exc_type)) {
        if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) {
            PyObject *exc_value, *exc_tb;
            exc_value = tstate->curexc_value;
            exc_tb = tstate->curexc_traceback;
            tstate->curexc_type = 0;
            tstate->curexc_value = 0;
            tstate->curexc_traceback = 0;
            Py_DECREF(exc_type);
            Py_XDECREF(exc_value);
            Py_XDECREF(exc_tb);
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#else
    if (unlikely(PyErr_Occurred())) {
        if (likely(PyErr_ExceptionMatches(PyExc_StopIteration))) {
            PyErr_Clear();
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#endif
}

/* UnpackItemEndCheck */
  static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
    if (unlikely(retval)) {
        Py_DECREF(retval);
        __Pyx_RaiseTooManyValuesError(expected);
        return -1;
    } else {
        return __Pyx_IterFinish();
    }
    return 0;
}

/* GetTopmostException */
  #if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem *
__Pyx_PyErr_GetTopmostException(PyThreadState *tstate)
{
    _PyErr_StackItem *exc_info = tstate->exc_info;
    while ((exc_info->exc_type == NULL || exc_info->exc_type == Py_None) &&
           exc_info->previous_item != NULL)
    {
        exc_info = exc_info->previous_item;
    }
    return exc_info;
}
#endif

/* SaveResetException */
  #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    *type = exc_info->exc_type;
    *value = exc_info->exc_value;
    *tb = exc_info->exc_traceback;
    #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    #endif
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = type;
    exc_info->exc_value = value;
    exc_info->exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* PyErrExceptionMatches */
  #if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    if (unlikely(PyTuple_Check(err)))
        return __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    return __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* GetException */
  #if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
#endif
{
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if CYTHON_USE_EXC_INFO_STACK
    {
        _PyErr_StackItem *exc_info = tstate->exc_info;
        tmp_type = exc_info->exc_type;
        tmp_value = exc_info->exc_value;
        tmp_tb = exc_info->exc_traceback;
        exc_info->exc_type = local_type;
        exc_info->exc_value = local_value;
        exc_info->exc_traceback = local_tb;
    }
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* BufferFallbackError */
  static void __Pyx_RaiseBufferFallbackError(void) {
  PyErr_SetString(PyExc_ValueError,
     "Buffer acquisition failed on assignment; and then reacquiring the old buffer failed too!");
}

/* PyObjectGetMethod */
  static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method) {
    PyObject *attr;
#if CYTHON_UNPACK_METHODS && CYTHON_COMPILING_IN_CPYTHON && CYTHON_USE_PYTYPE_LOOKUP
    PyTypeObject *tp = Py_TYPE(obj);
    PyObject *descr;
    descrgetfunc f = NULL;
    PyObject **dictptr, *dict;
    int meth_found = 0;
    assert (*method == NULL);
    if (unlikely(tp->tp_getattro != PyObject_GenericGetAttr)) {
        attr = __Pyx_PyObject_GetAttrStr(obj, name);
        goto try_unpack;
    }
    if (unlikely(tp->tp_dict == NULL) && unlikely(PyType_Ready(tp) < 0)) {
        return 0;
    }
    descr = _PyType_Lookup(tp, name);
    if (likely(descr != NULL)) {
        Py_INCREF(descr);
#if PY_MAJOR_VERSION >= 3
        #ifdef __Pyx_CyFunction_USED
        if (likely(PyFunction_Check(descr) || (Py_TYPE(descr) == &PyMethodDescr_Type) || __Pyx_CyFunction_Check(descr)))
        #else
        if (likely(PyFunction_Check(descr) || (Py_TYPE(descr) == &PyMethodDescr_Type)))
        #endif
#else
        #ifdef __Pyx_CyFunction_USED
        if (likely(PyFunction_Check(descr) || __Pyx_CyFunction_Check(descr)))
        #else
        if (likely(PyFunction_Check(descr)))
        #endif
#endif
        {
            meth_found = 1;
        } else {
            f = Py_TYPE(descr)->tp_descr_get;
            if (f != NULL && PyDescr_IsData(descr)) {
                attr = f(descr, obj, (PyObject *)Py_TYPE(obj));
                Py_DECREF(descr);
                goto try_unpack;
            }
        }
    }
    dictptr = _PyObject_GetDictPtr(obj);
    if (dictptr != NULL && (dict = *dictptr) != NULL) {
        Py_INCREF(dict);
        attr = __Pyx_PyDict_GetItemStr(dict, name);
        if (attr != NULL) {
            Py_INCREF(attr);
            Py_DECREF(dict);
            Py_XDECREF(descr);
            goto try_unpack;
        }
        Py_DECREF(dict);
    }
    if (meth_found) {
        *method = descr;
        return 1;
    }
    if (f != NULL) {
        attr = f(descr, obj, (PyObject *)Py_TYPE(obj));
        Py_DECREF(descr);
        goto try_unpack;
    }
    if (descr != NULL) {
        *method = descr;
        return 0;
    }
    PyErr_Format(PyExc_AttributeError,
#if PY_MAJOR_VERSION >= 3
                 "'%.50s' object has no attribute '%U'",
                 tp->tp_name, name);
#else
                 "'%.50s' object has no attribute '%.400s'",
                 tp->tp_name, PyString_AS_STRING(name));
#endif
    return 0;
#else
    attr = __Pyx_PyObject_GetAttrStr(obj, name);
    goto try_unpack;
#endif
try_unpack:
#if CYTHON_UNPACK_METHODS
    if (likely(attr) && PyMethod_Check(attr) && likely(PyMethod_GET_SELF(attr) == obj)) {
        PyObject *function = PyMethod_GET_FUNCTION(attr);
        Py_INCREF(function);
        Py_DECREF(attr);
        *method = function;
        return 1;
    }
#endif
    *method = attr;
    return 0;
}

/* PyObjectCallMethod0 */
  static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name) {
    PyObject *method = NULL, *result = NULL;
    int is_method = __Pyx_PyObject_GetMethod(obj, method_name, &method);
    if (likely(is_method)) {
        result = __Pyx_PyObject_CallOneArg(method, obj);
        Py_DECREF(method);
        return result;
    }
    if (unlikely(!method)) goto bad;
    result = __Pyx_PyObject_CallNoArg(method);
    Py_DECREF(method);
bad:
    return result;
}

/* RaiseNoneIterError */
  static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
}

/* UnpackTupleError */
  static void __Pyx_UnpackTupleError(PyObject *t, Py_ssize_t index) {
    if (t == Py_None) {
      __Pyx_RaiseNoneNotIterableError();
    } else if (PyTuple_GET_SIZE(t) < index) {
      __Pyx_RaiseNeedMoreValuesError(PyTuple_GET_SIZE(t));
    } else {
      __Pyx_RaiseTooManyValuesError(index);
    }
}

/* UnpackTuple2 */
  static CYTHON_INLINE int __Pyx_unpack_tuple2_exact(
        PyObject* tuple, PyObject** pvalue1, PyObject** pvalue2, int decref_tuple) {
    PyObject *value1 = NULL, *value2 = NULL;
#if CYTHON_COMPILING_IN_PYPY
    value1 = PySequence_ITEM(tuple, 0);  if (unlikely(!value1)) goto bad;
    value2 = PySequence_ITEM(tuple, 1);  if (unlikely(!value2)) goto bad;
#else
    value1 = PyTuple_GET_ITEM(tuple, 0);  Py_INCREF(value1);
    value2 = PyTuple_GET_ITEM(tuple, 1);  Py_INCREF(value2);
#endif
    if (decref_tuple) {
        Py_DECREF(tuple);
    }
    *pvalue1 = value1;
    *pvalue2 = value2;
    return 0;
#if CYTHON_COMPILING_IN_PYPY
bad:
    Py_XDECREF(value1);
    Py_XDECREF(value2);
    if (decref_tuple) { Py_XDECREF(tuple); }
    return -1;
#endif
}
static int __Pyx_unpack_tuple2_generic(PyObject* tuple, PyObject** pvalue1, PyObject** pvalue2,
                                       int has_known_size, int decref_tuple) {
    Py_ssize_t index;
    PyObject *value1 = NULL, *value2 = NULL, *iter = NULL;
    iternextfunc iternext;
    iter = PyObject_GetIter(tuple);
    if (unlikely(!iter)) goto bad;
    if (decref_tuple) { Py_DECREF(tuple); tuple = NULL; }
    iternext = Py_TYPE(iter)->tp_iternext;
    value1 = iternext(iter); if (unlikely(!value1)) { index = 0; goto unpacking_failed; }
    value2 = iternext(iter); if (unlikely(!value2)) { index = 1; goto unpacking_failed; }
    if (!has_known_size && unlikely(__Pyx_IternextUnpackEndCheck(iternext(iter), 2))) goto bad;
    Py_DECREF(iter);
    *pvalue1 = value1;
    *pvalue2 = value2;
    return 0;
unpacking_failed:
    if (!has_known_size && __Pyx_IterFinish() == 0)
        __Pyx_RaiseNeedMoreValuesError(index);
bad:
    Py_XDECREF(iter);
    Py_XDECREF(value1);
    Py_XDECREF(value2);
    if (decref_tuple) { Py_XDECREF(tuple); }
    return -1;
}

/* dict_iter */
  static CYTHON_INLINE PyObject* __Pyx_dict_iterator(PyObject* iterable, int is_dict, PyObject* method_name,
                                                   Py_ssize_t* p_orig_length, int* p_source_is_dict) {
    is_dict = is_dict || likely(PyDict_CheckExact(iterable));
    *p_source_is_dict = is_dict;
    if (is_dict) {
#if !CYTHON_COMPILING_IN_PYPY
        *p_orig_length = PyDict_Size(iterable);
        Py_INCREF(iterable);
        return iterable;
#elif PY_MAJOR_VERSION >= 3
        static PyObject *py_items = NULL, *py_keys = NULL, *py_values = NULL;
        PyObject **pp = NULL;
        if (method_name) {
            const char *name = PyUnicode_AsUTF8(method_name);
            if (strcmp(name, "iteritems") == 0) pp = &py_items;
            else if (strcmp(name, "iterkeys") == 0) pp = &py_keys;
            else if (strcmp(name, "itervalues") == 0) pp = &py_values;
            if (pp) {
                if (!*pp) {
                    *pp = PyUnicode_FromString(name + 4);
                    if (!*pp)
                        return NULL;
                }
                method_name = *pp;
            }
        }
#endif
    }
    *p_orig_length = 0;
    if (method_name) {
        PyObject* iter;
        iterable = __Pyx_PyObject_CallMethod0(iterable, method_name);
        if (!iterable)
            return NULL;
#if !CYTHON_COMPILING_IN_PYPY
        if (PyTuple_CheckExact(iterable) || PyList_CheckExact(iterable))
            return iterable;
#endif
        iter = PyObject_GetIter(iterable);
        Py_DECREF(iterable);
        return iter;
    }
    return PyObject_GetIter(iterable);
}
static CYTHON_INLINE int __Pyx_dict_iter_next(
        PyObject* iter_obj, CYTHON_NCP_UNUSED Py_ssize_t orig_length, CYTHON_NCP_UNUSED Py_ssize_t* ppos,
        PyObject** pkey, PyObject** pvalue, PyObject** pitem, int source_is_dict) {
    PyObject* next_item;
#if !CYTHON_COMPILING_IN_PYPY
    if (source_is_dict) {
        PyObject *key, *value;
        if (unlikely(orig_length != PyDict_Size(iter_obj))) {
            PyErr_SetString(PyExc_RuntimeError, "dictionary changed size during iteration");
            return -1;
        }
        if (unlikely(!PyDict_Next(iter_obj, ppos, &key, &value))) {
            return 0;
        }
        if (pitem) {
            PyObject* tuple = PyTuple_New(2);
            if (unlikely(!tuple)) {
                return -1;
            }
            Py_INCREF(key);
            Py_INCREF(value);
            PyTuple_SET_ITEM(tuple, 0, key);
            PyTuple_SET_ITEM(tuple, 1, value);
            *pitem = tuple;
        } else {
            if (pkey) {
                Py_INCREF(key);
                *pkey = key;
            }
            if (pvalue) {
                Py_INCREF(value);
                *pvalue = value;
            }
        }
        return 1;
    } else if (PyTuple_CheckExact(iter_obj)) {
        Py_ssize_t pos = *ppos;
        if (unlikely(pos >= PyTuple_GET_SIZE(iter_obj))) return 0;
        *ppos = pos + 1;
        next_item = PyTuple_GET_ITEM(iter_obj, pos);
        Py_INCREF(next_item);
    } else if (PyList_CheckExact(iter_obj)) {
        Py_ssize_t pos = *ppos;
        if (unlikely(pos >= PyList_GET_SIZE(iter_obj))) return 0;
        *ppos = pos + 1;
        next_item = PyList_GET_ITEM(iter_obj, pos);
        Py_INCREF(next_item);
    } else
#endif
    {
        next_item = PyIter_Next(iter_obj);
        if (unlikely(!next_item)) {
            return __Pyx_IterFinish();
        }
    }
    if (pitem) {
        *pitem = next_item;
    } else if (pkey && pvalue) {
        if (__Pyx_unpack_tuple2(next_item, pkey, pvalue, source_is_dict, source_is_dict, 1))
            return -1;
    } else if (pkey) {
        *pkey = next_item;
    } else {
        *pvalue = next_item;
    }
    return 1;
}

/* MergeKeywords */
  static int __Pyx_MergeKeywords(PyObject *kwdict, PyObject *source_mapping) {
    PyObject *iter, *key = NULL, *value = NULL;
    int source_is_dict, result;
    Py_ssize_t orig_length, ppos = 0;
    iter = __Pyx_dict_iterator(source_mapping, 0, __pyx_n_s_items, &orig_length, &source_is_dict);
    if (unlikely(!iter)) {
        PyObject *args;
        if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
        PyErr_Clear();
        args = PyTuple_Pack(1, source_mapping);
        if (likely(args)) {
            PyObject *fallback = PyObject_Call((PyObject*)&PyDict_Type, args, NULL);
            Py_DECREF(args);
            if (likely(fallback)) {
                iter = __Pyx_dict_iterator(fallback, 1, __pyx_n_s_items, &orig_length, &source_is_dict);
                Py_DECREF(fallback);
            }
        }
        if (unlikely(!iter)) goto bad;
    }
    while (1) {
        result = __Pyx_dict_iter_next(iter, orig_length, &ppos, &key, &value, NULL, source_is_dict);
        if (unlikely(result < 0)) goto bad;
        if (!result) break;
        if (unlikely(PyDict_Contains(kwdict, key))) {
            __Pyx_RaiseDoubleKeywordsError("function", key);
            result = -1;
        } else {
            result = PyDict_SetItem(kwdict, key, value);
        }
        Py_DECREF(key);
        Py_DECREF(value);
        if (unlikely(result < 0)) goto bad;
    }
    Py_XDECREF(iter);
    return 0;
bad:
    Py_XDECREF(iter);
    return -1;
}

/* PyIntBinop */
  #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, int inplace, int zerodivision_check) {
    (void)inplace;
    (void)zerodivision_check;
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a + b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                    CYTHON_FALLTHROUGH;
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                    CYTHON_FALLTHROUGH;
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                    CYTHON_FALLTHROUGH;
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                    CYTHON_FALLTHROUGH;
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                    CYTHON_FALLTHROUGH;
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                    CYTHON_FALLTHROUGH;
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* None */
  static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname) {
    PyErr_Format(PyExc_NameError, "free variable '%s' referenced before assignment in enclosing scope", varname);
}

/* PyObject_GenericGetAttrNoDict */
  #if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject *__Pyx_RaiseGenericGetAttributeError(PyTypeObject *tp, PyObject *attr_name) {
    PyErr_Format(PyExc_AttributeError,
#if PY_MAJOR_VERSION >= 3
                 "'%.50s' object has no attribute '%U'",
                 tp->tp_name, attr_name);
#else
                 "'%.50s' object has no attribute '%.400s'",
                 tp->tp_name, PyString_AS_STRING(attr_name));
#endif
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name) {
    PyObject *descr;
    PyTypeObject *tp = Py_TYPE(obj);
    if (unlikely(!PyString_Check(attr_name))) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    assert(!tp->tp_dictoffset);
    descr = _PyType_Lookup(tp, attr_name);
    if (unlikely(!descr)) {
        return __Pyx_RaiseGenericGetAttributeError(tp, attr_name);
    }
    Py_INCREF(descr);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyType_HasFeature(Py_TYPE(descr), Py_TPFLAGS_HAVE_CLASS)))
    #endif
    {
        descrgetfunc f = Py_TYPE(descr)->tp_descr_get;
        if (unlikely(f)) {
            PyObject *res = f(descr, obj, (PyObject *)tp);
            Py_DECREF(descr);
            return res;
        }
    }
    return descr;
}
#endif

/* TypeImport */
  #ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(PyObject *module, const char *module_name, const char *class_name,
    size_t size, enum __Pyx_ImportType_CheckSize check_size)
{
    PyObject *result = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    result = PyObject_GetAttrString(module, class_name);
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if ((size_t)basicsize < size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        goto bad;
    }
    if (check_size == __Pyx_ImportType_CheckSize_Error && (size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        goto bad;
    }
    else if (check_size == __Pyx_ImportType_CheckSize_Warn && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(result);
    return NULL;
}
#endif

/* Import */
  static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if ((1) && (strchr(__Pyx_MODULE_NAME, '.'))) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, (PyObject *)NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* ImportFrom */
  static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Format(PyExc_ImportError,
        #if PY_MAJOR_VERSION < 3
            "cannot import name %.230s", PyString_AS_STRING(name));
        #else
            "cannot import name %S", name);
        #endif
    }
    return value;
}

/* CLineInTraceback */
  #ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(CYTHON_NCP_UNUSED PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    if (unlikely(!__pyx_cython_runtime)) {
        return c_line;
    }
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
        __PYX_PY_DICT_LOOKUP_IF_MODIFIED(
            use_cline, *cython_runtime_dict,
            __Pyx_PyDict_GetItemStr(*cython_runtime_dict, __pyx_n_s_cline_in_traceback))
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (use_cline == Py_False || (use_cline != Py_True && PyObject_Not(use_cline) != 0)) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
  static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, ((size_t)new_max) * sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
  #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

#if PY_MAJOR_VERSION < 3
static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags) {
    if (PyObject_CheckBuffer(obj)) return PyObject_GetBuffer(obj, view, flags);
    PyErr_Format(PyExc_TypeError, "'%.200s' does not have the buffer interface", Py_TYPE(obj)->tp_name);
    return -1;
}
static void __Pyx_ReleaseBuffer(Py_buffer *view) {
    PyObject *obj = view->obj;
    if (!obj) return;
    if (PyObject_CheckBuffer(obj)) {
        PyBuffer_Release(view);
        return;
    }
    if ((0)) {}
    view->obj = NULL;
    Py_DECREF(obj);
}
#endif


  /* CIntFromPyVerify */
  #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* Declarations */
  #if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      return ::std::complex< float >(x, y);
    }
  #else
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      return x + y*(__pyx_t_float_complex)_Complex_I;
    }
  #endif
#else
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      __pyx_t_float_complex z;
      z.real = x;
      z.imag = y;
      return z;
    }
#endif

/* Arithmetic */
  #if CYTHON_CCOMPLEX
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
       return (a.real == b.real) && (a.imag == b.imag);
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real + b.real;
        z.imag = a.imag + b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real - b.real;
        z.imag = a.imag - b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real * b.real - a.imag * b.imag;
        z.imag = a.real * b.imag + a.imag * b.real;
        return z;
    }
    #if 1
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        if (b.imag == 0) {
            return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else if (fabsf(b.real) >= fabsf(b.imag)) {
            if (b.real == 0 && b.imag == 0) {
                return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.imag);
            } else {
                float r = b.imag / b.real;
                float s = (float)(1.0) / (b.real + b.imag * r);
                return __pyx_t_float_complex_from_parts(
                    (a.real + a.imag * r) * s, (a.imag - a.real * r) * s);
            }
        } else {
            float r = b.real / b.imag;
            float s = (float)(1.0) / (b.imag + b.real * r);
            return __pyx_t_float_complex_from_parts(
                (a.real * r + a.imag) * s, (a.imag * r - a.real) * s);
        }
    }
    #else
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        if (b.imag == 0) {
            return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else {
            float denom = b.real * b.real + b.imag * b.imag;
            return __pyx_t_float_complex_from_parts(
                (a.real * b.real + a.imag * b.imag) / denom,
                (a.imag * b.real - a.real * b.imag) / denom);
        }
    }
    #endif
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex a) {
        __pyx_t_float_complex z;
        z.real = -a.real;
        z.imag = -a.imag;
        return z;
    }
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex a) {
       return (a.real == 0) && (a.imag == 0);
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex a) {
        __pyx_t_float_complex z;
        z.real =  a.real;
        z.imag = -a.imag;
        return z;
    }
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex z) {
          #if !defined(HAVE_HYPOT) || defined(_MSC_VER)
            return sqrtf(z.real*z.real + z.imag*z.imag);
          #else
            return hypotf(z.real, z.imag);
          #endif
        }
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
            __pyx_t_float_complex z;
            float r, lnr, theta, z_r, z_theta;
            if (b.imag == 0 && b.real == (int)b.real) {
                if (b.real < 0) {
                    float denom = a.real * a.real + a.imag * a.imag;
                    a.real = a.real / denom;
                    a.imag = -a.imag / denom;
                    b.real = -b.real;
                }
                switch ((int)b.real) {
                    case 0:
                        z.real = 1;
                        z.imag = 0;
                        return z;
                    case 1:
                        return a;
                    case 2:
                        return __Pyx_c_prod_float(a, a);
                    case 3:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(z, a);
                    case 4:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(z, z);
                }
            }
            if (a.imag == 0) {
                if (a.real == 0) {
                    return a;
                } else if (b.imag == 0) {
                    z.real = powf(a.real, b.real);
                    z.imag = 0;
                    return z;
                } else if (a.real > 0) {
                    r = a.real;
                    theta = 0;
                } else {
                    r = -a.real;
                    theta = atan2f(0.0, -1.0);
                }
            } else {
                r = __Pyx_c_abs_float(a);
                theta = atan2f(a.imag, a.real);
            }
            lnr = logf(r);
            z_r = expf(lnr * b.real - theta * b.imag);
            z_theta = theta * b.real + lnr * b.imag;
            z.real = z_r * cosf(z_theta);
            z.imag = z_r * sinf(z_theta);
            return z;
        }
    #endif
#endif

/* Declarations */
  #if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      return ::std::complex< double >(x, y);
    }
  #else
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      return x + y*(__pyx_t_double_complex)_Complex_I;
    }
  #endif
#else
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      __pyx_t_double_complex z;
      z.real = x;
      z.imag = y;
      return z;
    }
#endif

/* Arithmetic */
  #if CYTHON_CCOMPLEX
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
       return (a.real == b.real) && (a.imag == b.imag);
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real + b.real;
        z.imag = a.imag + b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real - b.real;
        z.imag = a.imag - b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real * b.real - a.imag * b.imag;
        z.imag = a.real * b.imag + a.imag * b.real;
        return z;
    }
    #if 1
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        if (b.imag == 0) {
            return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else if (fabs(b.real) >= fabs(b.imag)) {
            if (b.real == 0 && b.imag == 0) {
                return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.imag);
            } else {
                double r = b.imag / b.real;
                double s = (double)(1.0) / (b.real + b.imag * r);
                return __pyx_t_double_complex_from_parts(
                    (a.real + a.imag * r) * s, (a.imag - a.real * r) * s);
            }
        } else {
            double r = b.real / b.imag;
            double s = (double)(1.0) / (b.imag + b.real * r);
            return __pyx_t_double_complex_from_parts(
                (a.real * r + a.imag) * s, (a.imag * r - a.real) * s);
        }
    }
    #else
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        if (b.imag == 0) {
            return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else {
            double denom = b.real * b.real + b.imag * b.imag;
            return __pyx_t_double_complex_from_parts(
                (a.real * b.real + a.imag * b.imag) / denom,
                (a.imag * b.real - a.real * b.imag) / denom);
        }
    }
    #endif
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex a) {
        __pyx_t_double_complex z;
        z.real = -a.real;
        z.imag = -a.imag;
        return z;
    }
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex a) {
       return (a.real == 0) && (a.imag == 0);
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex a) {
        __pyx_t_double_complex z;
        z.real =  a.real;
        z.imag = -a.imag;
        return z;
    }
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex z) {
          #if !defined(HAVE_HYPOT) || defined(_MSC_VER)
            return sqrt(z.real*z.real + z.imag*z.imag);
          #else
            return hypot(z.real, z.imag);
          #endif
        }
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
            __pyx_t_double_complex z;
            double r, lnr, theta, z_r, z_theta;
            if (b.imag == 0 && b.real == (int)b.real) {
                if (b.real < 0) {
                    double denom = a.real * a.real + a.imag * a.imag;
                    a.real = a.real / denom;
                    a.imag = -a.imag / denom;
                    b.real = -b.real;
                }
                switch ((int)b.real) {
                    case 0:
                        z.real = 1;
                        z.imag = 0;
                        return z;
                    case 1:
                        return a;
                    case 2:
                        return __Pyx_c_prod_double(a, a);
                    case 3:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(z, a);
                    case 4:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(z, z);
                }
            }
            if (a.imag == 0) {
                if (a.real == 0) {
                    return a;
                } else if (b.imag == 0) {
                    z.real = pow(a.real, b.real);
                    z.imag = 0;
                    return z;
                } else if (a.real > 0) {
                    r = a.real;
                    theta = 0;
                } else {
                    r = -a.real;
                    theta = atan2(0.0, -1.0);
                }
            } else {
                r = __Pyx_c_abs_double(a);
                theta = atan2(a.imag, a.real);
            }
            lnr = log(r);
            z_r = exp(lnr * b.real - theta * b.imag);
            z_theta = theta * b.real + lnr * b.imag;
            z.real = z_r * cos(z_theta);
            z.imag = z_r * sin(z_theta);
            return z;
        }
    #endif
#endif

/* CIntToPy */
  static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
  static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* CIntFromPy */
  static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
  static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* FastTypeChecks */
  #if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static int __Pyx_PyErr_GivenExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    assert(PyExceptionClass_Check(exc_type));
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        PyObject *t = PyTuple_GET_ITEM(tuple, i);
        #if PY_MAJOR_VERSION < 3
        if (likely(exc_type == t)) return 1;
        #endif
        if (likely(PyExceptionClass_Check(t))) {
            if (__Pyx_inner_PyErr_GivenExceptionMatches2(exc_type, NULL, t)) return 1;
        } else {
        }
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        if (likely(PyExceptionClass_Check(exc_type))) {
            return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
        } else if (likely(PyTuple_Check(exc_type))) {
            return __Pyx_PyErr_GivenExceptionMatchesTuple(err, exc_type);
        } else {
        }
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    assert(PyExceptionClass_Check(exc_type1));
    assert(PyExceptionClass_Check(exc_type2));
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* FetchCommonType */
  static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type) {
    PyObject* fake_module;
    PyTypeObject* cached_type = NULL;
    fake_module = PyImport_AddModule((char*) "_cython_" CYTHON_ABI);
    if (!fake_module) return NULL;
    Py_INCREF(fake_module);
    cached_type = (PyTypeObject*) PyObject_GetAttrString(fake_module, type->tp_name);
    if (cached_type) {
        if (!PyType_Check((PyObject*)cached_type)) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s is not a type object",
                type->tp_name);
            goto bad;
        }
        if (cached_type->tp_basicsize != type->tp_basicsize) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s has the wrong size, try recompiling",
                type->tp_name);
            goto bad;
        }
    } else {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
        PyErr_Clear();
        if (PyType_Ready(type) < 0) goto bad;
        if (PyObject_SetAttrString(fake_module, type->tp_name, (PyObject*) type) < 0)
            goto bad;
        Py_INCREF(type);
        cached_type = type;
    }
done:
    Py_DECREF(fake_module);
    return cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}

/* SwapException */
  #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = *type;
    exc_info->exc_value = *value;
    exc_info->exc_traceback = *tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* PyObjectCallMethod1 */
  static PyObject* __Pyx__PyObject_CallMethod1(PyObject* method, PyObject* arg) {
    PyObject *result = __Pyx_PyObject_CallOneArg(method, arg);
    Py_DECREF(method);
    return result;
}
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg) {
    PyObject *method = NULL, *result;
    int is_method = __Pyx_PyObject_GetMethod(obj, method_name, &method);
    if (likely(is_method)) {
        result = __Pyx_PyObject_Call2Args(method, obj, arg);
        Py_DECREF(method);
        return result;
    }
    if (unlikely(!method)) return NULL;
    return __Pyx__PyObject_CallMethod1(method, arg);
}

/* CoroutineBase */
  #include <structmember.h>
#include <frameobject.h>
#define __Pyx_Coroutine_Undelegate(gen) Py_CLEAR((gen)->yieldfrom)
static int __Pyx_PyGen__FetchStopIterationValue(CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject **pvalue) {
    PyObject *et, *ev, *tb;
    PyObject *value = NULL;
    __Pyx_ErrFetch(&et, &ev, &tb);
    if (!et) {
        Py_XDECREF(tb);
        Py_XDECREF(ev);
        Py_INCREF(Py_None);
        *pvalue = Py_None;
        return 0;
    }
    if (likely(et == PyExc_StopIteration)) {
        if (!ev) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#if PY_VERSION_HEX >= 0x030300A0
        else if (Py_TYPE(ev) == (PyTypeObject*)PyExc_StopIteration) {
            value = ((PyStopIterationObject *)ev)->value;
            Py_INCREF(value);
            Py_DECREF(ev);
        }
#endif
        else if (unlikely(PyTuple_Check(ev))) {
            if (PyTuple_GET_SIZE(ev) >= 1) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                value = PyTuple_GET_ITEM(ev, 0);
                Py_INCREF(value);
#else
                value = PySequence_ITEM(ev, 0);
#endif
            } else {
                Py_INCREF(Py_None);
                value = Py_None;
            }
            Py_DECREF(ev);
        }
        else if (!__Pyx_TypeCheck(ev, (PyTypeObject*)PyExc_StopIteration)) {
            value = ev;
        }
        if (likely(value)) {
            Py_XDECREF(tb);
            Py_DECREF(et);
            *pvalue = value;
            return 0;
        }
    } else if (!__Pyx_PyErr_GivenExceptionMatches(et, PyExc_StopIteration)) {
        __Pyx_ErrRestore(et, ev, tb);
        return -1;
    }
    PyErr_NormalizeException(&et, &ev, &tb);
    if (unlikely(!PyObject_TypeCheck(ev, (PyTypeObject*)PyExc_StopIteration))) {
        __Pyx_ErrRestore(et, ev, tb);
        return -1;
    }
    Py_XDECREF(tb);
    Py_DECREF(et);
#if PY_VERSION_HEX >= 0x030300A0
    value = ((PyStopIterationObject *)ev)->value;
    Py_INCREF(value);
    Py_DECREF(ev);
#else
    {
        PyObject* args = __Pyx_PyObject_GetAttrStr(ev, __pyx_n_s_args);
        Py_DECREF(ev);
        if (likely(args)) {
            value = PySequence_GetItem(args, 0);
            Py_DECREF(args);
        }
        if (unlikely(!value)) {
            __Pyx_ErrRestore(NULL, NULL, NULL);
            Py_INCREF(Py_None);
            value = Py_None;
        }
    }
#endif
    *pvalue = value;
    return 0;
}
static CYTHON_INLINE
void __Pyx_Coroutine_ExceptionClear(__Pyx_ExcInfoStruct *exc_state) {
    PyObject *t, *v, *tb;
    t = exc_state->exc_type;
    v = exc_state->exc_value;
    tb = exc_state->exc_traceback;
    exc_state->exc_type = NULL;
    exc_state->exc_value = NULL;
    exc_state->exc_traceback = NULL;
    Py_XDECREF(t);
    Py_XDECREF(v);
    Py_XDECREF(tb);
}
#define __Pyx_Coroutine_AlreadyRunningError(gen)  (__Pyx__Coroutine_AlreadyRunningError(gen), (PyObject*)NULL)
static void __Pyx__Coroutine_AlreadyRunningError(CYTHON_UNUSED __pyx_CoroutineObject *gen) {
    const char *msg;
    if ((0)) {
    #ifdef __Pyx_Coroutine_USED
    } else if (__Pyx_Coroutine_Check((PyObject*)gen)) {
        msg = "coroutine already executing";
    #endif
    #ifdef __Pyx_AsyncGen_USED
    } else if (__Pyx_AsyncGen_CheckExact((PyObject*)gen)) {
        msg = "async generator already executing";
    #endif
    } else {
        msg = "generator already executing";
    }
    PyErr_SetString(PyExc_ValueError, msg);
}
#define __Pyx_Coroutine_NotStartedError(gen)  (__Pyx__Coroutine_NotStartedError(gen), (PyObject*)NULL)
static void __Pyx__Coroutine_NotStartedError(CYTHON_UNUSED PyObject *gen) {
    const char *msg;
    if ((0)) {
    #ifdef __Pyx_Coroutine_USED
    } else if (__Pyx_Coroutine_Check(gen)) {
        msg = "can't send non-None value to a just-started coroutine";
    #endif
    #ifdef __Pyx_AsyncGen_USED
    } else if (__Pyx_AsyncGen_CheckExact(gen)) {
        msg = "can't send non-None value to a just-started async generator";
    #endif
    } else {
        msg = "can't send non-None value to a just-started generator";
    }
    PyErr_SetString(PyExc_TypeError, msg);
}
#define __Pyx_Coroutine_AlreadyTerminatedError(gen, value, closing)  (__Pyx__Coroutine_AlreadyTerminatedError(gen, value, closing), (PyObject*)NULL)
static void __Pyx__Coroutine_AlreadyTerminatedError(CYTHON_UNUSED PyObject *gen, PyObject *value, CYTHON_UNUSED int closing) {
    #ifdef __Pyx_Coroutine_USED
    if (!closing && __Pyx_Coroutine_Check(gen)) {
        PyErr_SetString(PyExc_RuntimeError, "cannot reuse already awaited coroutine");
    } else
    #endif
    if (value) {
        #ifdef __Pyx_AsyncGen_USED
        if (__Pyx_AsyncGen_CheckExact(gen))
            PyErr_SetNone(__Pyx_PyExc_StopAsyncIteration);
        else
        #endif
        PyErr_SetNone(PyExc_StopIteration);
    }
}
static
PyObject *__Pyx_Coroutine_SendEx(__pyx_CoroutineObject *self, PyObject *value, int closing) {
    __Pyx_PyThreadState_declare
    PyThreadState *tstate;
    __Pyx_ExcInfoStruct *exc_state;
    PyObject *retval;
    assert(!self->is_running);
    if (unlikely(self->resume_label == 0)) {
        if (unlikely(value && value != Py_None)) {
            return __Pyx_Coroutine_NotStartedError((PyObject*)self);
        }
    }
    if (unlikely(self->resume_label == -1)) {
        return __Pyx_Coroutine_AlreadyTerminatedError((PyObject*)self, value, closing);
    }
#if CYTHON_FAST_THREAD_STATE
    __Pyx_PyThreadState_assign
    tstate = __pyx_tstate;
#else
    tstate = __Pyx_PyThreadState_Current;
#endif
    exc_state = &self->gi_exc_state;
    if (exc_state->exc_type) {
        #if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_PYSTON
        #else
        if (exc_state->exc_traceback) {
            PyTracebackObject *tb = (PyTracebackObject *) exc_state->exc_traceback;
            PyFrameObject *f = tb->tb_frame;
            Py_XINCREF(tstate->frame);
            assert(f->f_back == NULL);
            f->f_back = tstate->frame;
        }
        #endif
    }
#if CYTHON_USE_EXC_INFO_STACK
    exc_state->previous_item = tstate->exc_info;
    tstate->exc_info = exc_state;
#else
    if (exc_state->exc_type) {
        __Pyx_ExceptionSwap(&exc_state->exc_type, &exc_state->exc_value, &exc_state->exc_traceback);
    } else {
        __Pyx_Coroutine_ExceptionClear(exc_state);
        __Pyx_ExceptionSave(&exc_state->exc_type, &exc_state->exc_value, &exc_state->exc_traceback);
    }
#endif
    self->is_running = 1;
    retval = self->body((PyObject *) self, tstate, value);
    self->is_running = 0;
#if CYTHON_USE_EXC_INFO_STACK
    exc_state = &self->gi_exc_state;
    tstate->exc_info = exc_state->previous_item;
    exc_state->previous_item = NULL;
    __Pyx_Coroutine_ResetFrameBackpointer(exc_state);
#endif
    return retval;
}
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__Pyx_ExcInfoStruct *exc_state) {
    PyObject *exc_tb = exc_state->exc_traceback;
    if (likely(exc_tb)) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_PYSTON
#else
        PyTracebackObject *tb = (PyTracebackObject *) exc_tb;
        PyFrameObject *f = tb->tb_frame;
        Py_CLEAR(f->f_back);
#endif
    }
}
static CYTHON_INLINE
PyObject *__Pyx_Coroutine_MethodReturn(CYTHON_UNUSED PyObject* gen, PyObject *retval) {
    if (unlikely(!retval)) {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        if (!__Pyx_PyErr_Occurred()) {
            PyObject *exc = PyExc_StopIteration;
            #ifdef __Pyx_AsyncGen_USED
            if (__Pyx_AsyncGen_CheckExact(gen))
                exc = __Pyx_PyExc_StopAsyncIteration;
            #endif
            __Pyx_PyErr_SetNone(exc);
        }
    }
    return retval;
}
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
static CYTHON_INLINE
PyObject *__Pyx_PyGen_Send(PyGenObject *gen, PyObject *arg) {
#if PY_VERSION_HEX <= 0x030A00A1
    return _PyGen_Send(gen, arg);
#else
    PyObject *result;
    if (PyIter_Send((PyObject*)gen, arg ? arg : Py_None, &result) == PYGEN_RETURN) {
        if (PyAsyncGen_CheckExact(gen)) {
            assert(result == Py_None);
            PyErr_SetNone(PyExc_StopAsyncIteration);
        }
        else if (result == Py_None) {
            PyErr_SetNone(PyExc_StopIteration);
        }
        else {
            _PyGen_SetStopIterationValue(result);
        }
        Py_CLEAR(result);
    }
    return result;
#endif
}
#endif
static CYTHON_INLINE
PyObject *__Pyx_Coroutine_FinishDelegation(__pyx_CoroutineObject *gen) {
    PyObject *ret;
    PyObject *val = NULL;
    __Pyx_Coroutine_Undelegate(gen);
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, &val);
    ret = __Pyx_Coroutine_SendEx(gen, val, 0);
    Py_XDECREF(val);
    return ret;
}
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value) {
    PyObject *retval;
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject*) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        gen->is_running = 1;
        #ifdef __Pyx_Generator_USED
        if (__Pyx_Generator_CheckExact(yf)) {
            ret = __Pyx_Coroutine_Send(yf, value);
        } else
        #endif
        #ifdef __Pyx_Coroutine_USED
        if (__Pyx_Coroutine_Check(yf)) {
            ret = __Pyx_Coroutine_Send(yf, value);
        } else
        #endif
        #ifdef __Pyx_AsyncGen_USED
        if (__pyx_PyAsyncGenASend_CheckExact(yf)) {
            ret = __Pyx_async_gen_asend_send(yf, value);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyGen_CheckExact(yf)) {
            ret = __Pyx_PyGen_Send((PyGenObject*)yf, value == Py_None ? NULL : value);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03050000 && defined(PyCoro_CheckExact) && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyCoro_CheckExact(yf)) {
            ret = __Pyx_PyGen_Send((PyGenObject*)yf, value == Py_None ? NULL : value);
        } else
        #endif
        {
            if (value == Py_None)
                ret = Py_TYPE(yf)->tp_iternext(yf);
            else
                ret = __Pyx_PyObject_CallMethod1(yf, __pyx_n_s_send, value);
        }
        gen->is_running = 0;
        if (likely(ret)) {
            return ret;
        }
        retval = __Pyx_Coroutine_FinishDelegation(gen);
    } else {
        retval = __Pyx_Coroutine_SendEx(gen, value, 0);
    }
    return __Pyx_Coroutine_MethodReturn(self, retval);
}
static int __Pyx_Coroutine_CloseIter(__pyx_CoroutineObject *gen, PyObject *yf) {
    PyObject *retval = NULL;
    int err = 0;
    #ifdef __Pyx_Generator_USED
    if (__Pyx_Generator_CheckExact(yf)) {
        retval = __Pyx_Coroutine_Close(yf);
        if (!retval)
            return -1;
    } else
    #endif
    #ifdef __Pyx_Coroutine_USED
    if (__Pyx_Coroutine_Check(yf)) {
        retval = __Pyx_Coroutine_Close(yf);
        if (!retval)
            return -1;
    } else
    if (__Pyx_CoroutineAwait_CheckExact(yf)) {
        retval = __Pyx_CoroutineAwait_Close((__pyx_CoroutineAwaitObject*)yf, NULL);
        if (!retval)
            return -1;
    } else
    #endif
    #ifdef __Pyx_AsyncGen_USED
    if (__pyx_PyAsyncGenASend_CheckExact(yf)) {
        retval = __Pyx_async_gen_asend_close(yf, NULL);
    } else
    if (__pyx_PyAsyncGenAThrow_CheckExact(yf)) {
        retval = __Pyx_async_gen_athrow_close(yf, NULL);
    } else
    #endif
    {
        PyObject *meth;
        gen->is_running = 1;
        meth = __Pyx_PyObject_GetAttrStr(yf, __pyx_n_s_close_2);
        if (unlikely(!meth)) {
            if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
                PyErr_WriteUnraisable(yf);
            }
            PyErr_Clear();
        } else {
            retval = PyObject_CallFunction(meth, NULL);
            Py_DECREF(meth);
            if (!retval)
                err = -1;
        }
        gen->is_running = 0;
    }
    Py_XDECREF(retval);
    return err;
}
static PyObject *__Pyx_Generator_Next(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject*) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        gen->is_running = 1;
        #ifdef __Pyx_Generator_USED
        if (__Pyx_Generator_CheckExact(yf)) {
            ret = __Pyx_Generator_Next(yf);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyGen_CheckExact(yf)) {
            ret = __Pyx_PyGen_Send((PyGenObject*)yf, NULL);
        } else
        #endif
        #ifdef __Pyx_Coroutine_USED
        if (__Pyx_Coroutine_Check(yf)) {
            ret = __Pyx_Coroutine_Send(yf, Py_None);
        } else
        #endif
            ret = Py_TYPE(yf)->tp_iternext(yf);
        gen->is_running = 0;
        if (likely(ret)) {
            return ret;
        }
        return __Pyx_Coroutine_FinishDelegation(gen);
    }
    return __Pyx_Coroutine_SendEx(gen, Py_None, 0);
}
static PyObject *__Pyx_Coroutine_Close_Method(PyObject *self, CYTHON_UNUSED PyObject *arg) {
    return __Pyx_Coroutine_Close(self);
}
static PyObject *__Pyx_Coroutine_Close(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject *retval, *raised_exception;
    PyObject *yf = gen->yieldfrom;
    int err = 0;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        Py_INCREF(yf);
        err = __Pyx_Coroutine_CloseIter(gen, yf);
        __Pyx_Coroutine_Undelegate(gen);
        Py_DECREF(yf);
    }
    if (err == 0)
        PyErr_SetNone(PyExc_GeneratorExit);
    retval = __Pyx_Coroutine_SendEx(gen, NULL, 1);
    if (unlikely(retval)) {
        const char *msg;
        Py_DECREF(retval);
        if ((0)) {
        #ifdef __Pyx_Coroutine_USED
        } else if (__Pyx_Coroutine_Check(self)) {
            msg = "coroutine ignored GeneratorExit";
        #endif
        #ifdef __Pyx_AsyncGen_USED
        } else if (__Pyx_AsyncGen_CheckExact(self)) {
#if PY_VERSION_HEX < 0x03060000
            msg = "async generator ignored GeneratorExit - might require Python 3.6+ finalisation (PEP 525)";
#else
            msg = "async generator ignored GeneratorExit";
#endif
        #endif
        } else {
            msg = "generator ignored GeneratorExit";
        }
        PyErr_SetString(PyExc_RuntimeError, msg);
        return NULL;
    }
    raised_exception = PyErr_Occurred();
    if (likely(!raised_exception || __Pyx_PyErr_GivenExceptionMatches2(raised_exception, PyExc_GeneratorExit, PyExc_StopIteration))) {
        if (raised_exception) PyErr_Clear();
        Py_INCREF(Py_None);
        return Py_None;
    }
    return NULL;
}
static PyObject *__Pyx__Coroutine_Throw(PyObject *self, PyObject *typ, PyObject *val, PyObject *tb,
                                        PyObject *args, int close_on_genexit) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        Py_INCREF(yf);
        if (__Pyx_PyErr_GivenExceptionMatches(typ, PyExc_GeneratorExit) && close_on_genexit) {
            int err = __Pyx_Coroutine_CloseIter(gen, yf);
            Py_DECREF(yf);
            __Pyx_Coroutine_Undelegate(gen);
            if (err < 0)
                return __Pyx_Coroutine_MethodReturn(self, __Pyx_Coroutine_SendEx(gen, NULL, 0));
            goto throw_here;
        }
        gen->is_running = 1;
        if (0
        #ifdef __Pyx_Generator_USED
            || __Pyx_Generator_CheckExact(yf)
        #endif
        #ifdef __Pyx_Coroutine_USED
            || __Pyx_Coroutine_Check(yf)
        #endif
            ) {
            ret = __Pyx__Coroutine_Throw(yf, typ, val, tb, args, close_on_genexit);
        #ifdef __Pyx_Coroutine_USED
        } else if (__Pyx_CoroutineAwait_CheckExact(yf)) {
            ret = __Pyx__Coroutine_Throw(((__pyx_CoroutineAwaitObject*)yf)->coroutine, typ, val, tb, args, close_on_genexit);
        #endif
        } else {
            PyObject *meth = __Pyx_PyObject_GetAttrStr(yf, __pyx_n_s_throw);
            if (unlikely(!meth)) {
                Py_DECREF(yf);
                if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
                    gen->is_running = 0;
                    return NULL;
                }
                PyErr_Clear();
                __Pyx_Coroutine_Undelegate(gen);
                gen->is_running = 0;
                goto throw_here;
            }
            if (likely(args)) {
                ret = PyObject_CallObject(meth, args);
            } else {
                ret = PyObject_CallFunctionObjArgs(meth, typ, val, tb, NULL);
            }
            Py_DECREF(meth);
        }
        gen->is_running = 0;
        Py_DECREF(yf);
        if (!ret) {
            ret = __Pyx_Coroutine_FinishDelegation(gen);
        }
        return __Pyx_Coroutine_MethodReturn(self, ret);
    }
throw_here:
    __Pyx_Raise(typ, val, tb, NULL);
    return __Pyx_Coroutine_MethodReturn(self, __Pyx_Coroutine_SendEx(gen, NULL, 0));
}
static PyObject *__Pyx_Coroutine_Throw(PyObject *self, PyObject *args) {
    PyObject *typ;
    PyObject *val = NULL;
    PyObject *tb = NULL;
    if (!PyArg_UnpackTuple(args, (char *)"throw", 1, 3, &typ, &val, &tb))
        return NULL;
    return __Pyx__Coroutine_Throw(self, typ, val, tb, args, 1);
}
static CYTHON_INLINE int __Pyx_Coroutine_traverse_excstate(__Pyx_ExcInfoStruct *exc_state, visitproc visit, void *arg) {
    Py_VISIT(exc_state->exc_type);
    Py_VISIT(exc_state->exc_value);
    Py_VISIT(exc_state->exc_traceback);
    return 0;
}
static int __Pyx_Coroutine_traverse(__pyx_CoroutineObject *gen, visitproc visit, void *arg) {
    Py_VISIT(gen->closure);
    Py_VISIT(gen->classobj);
    Py_VISIT(gen->yieldfrom);
    return __Pyx_Coroutine_traverse_excstate(&gen->gi_exc_state, visit, arg);
}
static int __Pyx_Coroutine_clear(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    Py_CLEAR(gen->closure);
    Py_CLEAR(gen->classobj);
    Py_CLEAR(gen->yieldfrom);
    __Pyx_Coroutine_ExceptionClear(&gen->gi_exc_state);
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        Py_CLEAR(((__pyx_PyAsyncGenObject*)gen)->ag_finalizer);
    }
#endif
    Py_CLEAR(gen->gi_code);
    Py_CLEAR(gen->gi_frame);
    Py_CLEAR(gen->gi_name);
    Py_CLEAR(gen->gi_qualname);
    Py_CLEAR(gen->gi_modulename);
    return 0;
}
static void __Pyx_Coroutine_dealloc(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject_GC_UnTrack(gen);
    if (gen->gi_weakreflist != NULL)
        PyObject_ClearWeakRefs(self);
    if (gen->resume_label >= 0) {
        PyObject_GC_Track(self);
#if PY_VERSION_HEX >= 0x030400a1 && CYTHON_USE_TP_FINALIZE
        if (PyObject_CallFinalizerFromDealloc(self))
#else
        Py_TYPE(gen)->tp_del(self);
        if (Py_REFCNT(self) > 0)
#endif
        {
            return;
        }
        PyObject_GC_UnTrack(self);
    }
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        /* We have to handle this case for asynchronous generators
           right here, because this code has to be between UNTRACK
           and GC_Del. */
        Py_CLEAR(((__pyx_PyAsyncGenObject*)self)->ag_finalizer);
    }
#endif
    __Pyx_Coroutine_clear(self);
    PyObject_GC_Del(gen);
}
static void __Pyx_Coroutine_del(PyObject *self) {
    PyObject *error_type, *error_value, *error_traceback;
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    __Pyx_PyThreadState_declare
    if (gen->resume_label < 0) {
        return;
    }
#if !CYTHON_USE_TP_FINALIZE
    assert(self->ob_refcnt == 0);
    __Pyx_SET_REFCNT(self, 1);
#endif
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&error_type, &error_value, &error_traceback);
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        __pyx_PyAsyncGenObject *agen = (__pyx_PyAsyncGenObject*)self;
        PyObject *finalizer = agen->ag_finalizer;
        if (finalizer && !agen->ag_closed) {
            PyObject *res = __Pyx_PyObject_CallOneArg(finalizer, self);
            if (unlikely(!res)) {
                PyErr_WriteUnraisable(self);
            } else {
                Py_DECREF(res);
            }
            __Pyx_ErrRestore(error_type, error_value, error_traceback);
            return;
        }
    }
#endif
    if (unlikely(gen->resume_label == 0 && !error_value)) {
#ifdef __Pyx_Coroutine_USED
#ifdef __Pyx_Generator_USED
    if (!__Pyx_Generator_CheckExact(self))
#endif
        {
        PyObject_GC_UnTrack(self);
#if PY_MAJOR_VERSION >= 3  || defined(PyErr_WarnFormat)
        if (unlikely(PyErr_WarnFormat(PyExc_RuntimeWarning, 1, "coroutine '%.50S' was never awaited", gen->gi_qualname) < 0))
            PyErr_WriteUnraisable(self);
#else
        {PyObject *msg;
        char *cmsg;
        #if CYTHON_COMPILING_IN_PYPY
        msg = NULL;
        cmsg = (char*) "coroutine was never awaited";
        #else
        char *cname;
        PyObject *qualname;
        qualname = gen->gi_qualname;
        cname = PyString_AS_STRING(qualname);
        msg = PyString_FromFormat("coroutine '%.50s' was never awaited", cname);
        if (unlikely(!msg)) {
            PyErr_Clear();
            cmsg = (char*) "coroutine was never awaited";
        } else {
            cmsg = PyString_AS_STRING(msg);
        }
        #endif
        if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning, cmsg, 1) < 0))
            PyErr_WriteUnraisable(self);
        Py_XDECREF(msg);}
#endif
        PyObject_GC_Track(self);
        }
#endif
    } else {
        PyObject *res = __Pyx_Coroutine_Close(self);
        if (unlikely(!res)) {
            if (PyErr_Occurred())
                PyErr_WriteUnraisable(self);
        } else {
            Py_DECREF(res);
        }
    }
    __Pyx_ErrRestore(error_type, error_value, error_traceback);
#if !CYTHON_USE_TP_FINALIZE
    assert(Py_REFCNT(self) > 0);
    if (--self->ob_refcnt == 0) {
        return;
    }
    {
        Py_ssize_t refcnt = Py_REFCNT(self);
        _Py_NewReference(self);
        __Pyx_SET_REFCNT(self, refcnt);
    }
#if CYTHON_COMPILING_IN_CPYTHON
    assert(PyType_IS_GC(Py_TYPE(self)) &&
           _Py_AS_GC(self)->gc.gc_refs != _PyGC_REFS_UNTRACKED);
    _Py_DEC_REFTOTAL;
#endif
#ifdef COUNT_ALLOCS
    --Py_TYPE(self)->tp_frees;
    --Py_TYPE(self)->tp_allocs;
#endif
#endif
}
static PyObject *
__Pyx_Coroutine_get_name(__pyx_CoroutineObject *self, CYTHON_UNUSED void *context)
{
    PyObject *name = self->gi_name;
    if (unlikely(!name)) name = Py_None;
    Py_INCREF(name);
    return name;
}
static int
__Pyx_Coroutine_set_name(__pyx_CoroutineObject *self, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    tmp = self->gi_name;
    Py_INCREF(value);
    self->gi_name = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_Coroutine_get_qualname(__pyx_CoroutineObject *self, CYTHON_UNUSED void *context)
{
    PyObject *name = self->gi_qualname;
    if (unlikely(!name)) name = Py_None;
    Py_INCREF(name);
    return name;
}
static int
__Pyx_Coroutine_set_qualname(__pyx_CoroutineObject *self, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    tmp = self->gi_qualname;
    Py_INCREF(value);
    self->gi_qualname = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_Coroutine_get_frame(__pyx_CoroutineObject *self, CYTHON_UNUSED void *context)
{
    PyObject *frame = self->gi_frame;
    if (!frame) {
        if (unlikely(!self->gi_code)) {
            Py_RETURN_NONE;
        }
        frame = (PyObject *) PyFrame_New(
            PyThreadState_Get(),            /*PyThreadState *tstate,*/
            (PyCodeObject*) self->gi_code,  /*PyCodeObject *code,*/
            __pyx_d,                 /*PyObject *globals,*/
            0                               /*PyObject *locals*/
        );
        if (unlikely(!frame))
            return NULL;
        self->gi_frame = frame;
    }
    Py_INCREF(frame);
    return frame;
}
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
            PyTypeObject* type, __pyx_coroutine_body_t body, PyObject *code, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name) {
    __pyx_CoroutineObject *gen = PyObject_GC_New(__pyx_CoroutineObject, type);
    if (unlikely(!gen))
        return NULL;
    return __Pyx__Coroutine_NewInit(gen, body, code, closure, name, qualname, module_name);
}
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *code, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name) {
    gen->body = body;
    gen->closure = closure;
    Py_XINCREF(closure);
    gen->is_running = 0;
    gen->resume_label = 0;
    gen->classobj = NULL;
    gen->yieldfrom = NULL;
    gen->gi_exc_state.exc_type = NULL;
    gen->gi_exc_state.exc_value = NULL;
    gen->gi_exc_state.exc_traceback = NULL;
#if CYTHON_USE_EXC_INFO_STACK
    gen->gi_exc_state.previous_item = NULL;
#endif
    gen->gi_weakreflist = NULL;
    Py_XINCREF(qualname);
    gen->gi_qualname = qualname;
    Py_XINCREF(name);
    gen->gi_name = name;
    Py_XINCREF(module_name);
    gen->gi_modulename = module_name;
    Py_XINCREF(code);
    gen->gi_code = code;
    gen->gi_frame = NULL;
    PyObject_GC_Track(gen);
    return gen;
}

/* PatchModuleWithCoroutine */
  static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code) {
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
    int result;
    PyObject *globals, *result_obj;
    globals = PyDict_New();  if (unlikely(!globals)) goto ignore;
    result = PyDict_SetItemString(globals, "_cython_coroutine_type",
    #ifdef __Pyx_Coroutine_USED
        (PyObject*)__pyx_CoroutineType);
    #else
        Py_None);
    #endif
    if (unlikely(result < 0)) goto ignore;
    result = PyDict_SetItemString(globals, "_cython_generator_type",
    #ifdef __Pyx_Generator_USED
        (PyObject*)__pyx_GeneratorType);
    #else
        Py_None);
    #endif
    if (unlikely(result < 0)) goto ignore;
    if (unlikely(PyDict_SetItemString(globals, "_module", module) < 0)) goto ignore;
    if (unlikely(PyDict_SetItemString(globals, "__builtins__", __pyx_b) < 0)) goto ignore;
    result_obj = PyRun_String(py_code, Py_file_input, globals, globals);
    if (unlikely(!result_obj)) goto ignore;
    Py_DECREF(result_obj);
    Py_DECREF(globals);
    return module;
ignore:
    Py_XDECREF(globals);
    PyErr_WriteUnraisable(module);
    if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning, "Cython module failed to patch module with custom type", 1) < 0)) {
        Py_DECREF(module);
        module = NULL;
    }
#else
    py_code++;
#endif
    return module;
}

/* PatchGeneratorABC */
  #ifndef CYTHON_REGISTER_ABCS
#define CYTHON_REGISTER_ABCS 1
#endif
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
static PyObject* __Pyx_patch_abc_module(PyObject *module);
static PyObject* __Pyx_patch_abc_module(PyObject *module) {
    module = __Pyx_Coroutine_patch_module(
        module, ""
"if _cython_generator_type is not None:\n"
"    try: Generator = _module.Generator\n"
"    except AttributeError: pass\n"
"    else: Generator.register(_cython_generator_type)\n"
"if _cython_coroutine_type is not None:\n"
"    try: Coroutine = _module.Coroutine\n"
"    except AttributeError: pass\n"
"    else: Coroutine.register(_cython_coroutine_type)\n"
    );
    return module;
}
#endif
static int __Pyx_patch_abc(void) {
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
    static int abc_patched = 0;
    if (CYTHON_REGISTER_ABCS && !abc_patched) {
        PyObject *module;
        module = PyImport_ImportModule((PY_MAJOR_VERSION >= 3) ? "collections.abc" : "collections");
        if (!module) {
            PyErr_WriteUnraisable(NULL);
            if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning,
                    ((PY_MAJOR_VERSION >= 3) ?
                        "Cython module failed to register with collections.abc module" :
                        "Cython module failed to register with collections module"), 1) < 0)) {
                return -1;
            }
        } else {
            module = __Pyx_patch_abc_module(module);
            abc_patched = 1;
            if (unlikely(!module))
                return -1;
            Py_DECREF(module);
        }
        module = PyImport_ImportModule("backports_abc");
        if (module) {
            module = __Pyx_patch_abc_module(module);
            Py_XDECREF(module);
        }
        if (!module) {
            PyErr_Clear();
        }
    }
#else
    if ((0)) __Pyx_Coroutine_patch_module(NULL, NULL);
#endif
    return 0;
}

/* Generator */
  static PyMethodDef __pyx_Generator_methods[] = {
    {"send", (PyCFunction) __Pyx_Coroutine_Send, METH_O,
     (char*) PyDoc_STR("send(arg) -> send 'arg' into generator,\nreturn next yielded value or raise StopIteration.")},
    {"throw", (PyCFunction) __Pyx_Coroutine_Throw, METH_VARARGS,
     (char*) PyDoc_STR("throw(typ[,val[,tb]]) -> raise exception in generator,\nreturn next yielded value or raise StopIteration.")},
    {"close", (PyCFunction) __Pyx_Coroutine_Close_Method, METH_NOARGS,
     (char*) PyDoc_STR("close() -> raise GeneratorExit inside generator.")},
    {0, 0, 0, 0}
};
static PyMemberDef __pyx_Generator_memberlist[] = {
    {(char *) "gi_running", T_BOOL, offsetof(__pyx_CoroutineObject, is_running), READONLY, NULL},
    {(char*) "gi_yieldfrom", T_OBJECT, offsetof(__pyx_CoroutineObject, yieldfrom), READONLY,
     (char*) PyDoc_STR("object being iterated by 'yield from', or None")},
    {(char*) "gi_code", T_OBJECT, offsetof(__pyx_CoroutineObject, gi_code), READONLY, NULL},
    {0, 0, 0, 0, 0}
};
static PyGetSetDef __pyx_Generator_getsets[] = {
    {(char *) "__name__", (getter)__Pyx_Coroutine_get_name, (setter)__Pyx_Coroutine_set_name,
     (char*) PyDoc_STR("name of the generator"), 0},
    {(char *) "__qualname__", (getter)__Pyx_Coroutine_get_qualname, (setter)__Pyx_Coroutine_set_qualname,
     (char*) PyDoc_STR("qualified name of the generator"), 0},
    {(char *) "gi_frame", (getter)__Pyx_Coroutine_get_frame, NULL,
     (char*) PyDoc_STR("Frame of the generator"), 0},
    {0, 0, 0, 0, 0}
};
static PyTypeObject __pyx_GeneratorType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    "generator",
    sizeof(__pyx_CoroutineObject),
    0,
    (destructor) __Pyx_Coroutine_dealloc,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_HAVE_FINALIZE,
    0,
    (traverseproc) __Pyx_Coroutine_traverse,
    0,
    0,
    offsetof(__pyx_CoroutineObject, gi_weakreflist),
    0,
    (iternextfunc) __Pyx_Generator_Next,
    __pyx_Generator_methods,
    __pyx_Generator_memberlist,
    __pyx_Generator_getsets,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if CYTHON_USE_TP_FINALIZE
    0,
#else
    __Pyx_Coroutine_del,
#endif
    0,
#if CYTHON_USE_TP_FINALIZE
    __Pyx_Coroutine_del,
#elif PY_VERSION_HEX >= 0x030400a1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
    0,
#endif
};
static int __pyx_Generator_init(void) {
    __pyx_GeneratorType_type.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
    __pyx_GeneratorType_type.tp_iter = PyObject_SelfIter;
    __pyx_GeneratorType = __Pyx_FetchCommonType(&__pyx_GeneratorType_type);
    if (unlikely(!__pyx_GeneratorType)) {
        return -1;
    }
    return 0;
}

/* CheckBinaryVersion */
  static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* InitStrings */
  static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            return -1;
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject* x) {
    int retval;
    if (unlikely(!x)) return -1;
    retval = __Pyx_PyObject_IsTrue(x);
    Py_DECREF(x);
    return retval;
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(b);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b) {
  return b ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False);
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
